"""This module implements LeJepa training procedure with three predictors and two input modalities."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/05b_trainers.findgoal_trainer.ipynb.

# %% auto 0
__all__ = ['CHECKPOINT_FREQ', 'WMTrainer']

# %% ../../nbs/05b_trainers.findgoal_trainer.ipynb 3
from fastcore import *
from fastcore.utils import *
from torchvision.utils import save_image
import torch
import os
from torch import nn
import pandas as pd

# %% ../../nbs/05b_trainers.findgoal_trainer.ipynb 5
from ..models.utils import save_checkpoint
from ..loggers.base import AverageMeter
from ..losses.sigreg import SIGReg, SIGRegDistributed
from ..models.utils import flatten_conv_output
from einops import rearrange

class WMTrainer:
    def __init__(self, cfg, model, train_loader, sampler,
                 optimizer=None, device=None,earlystopping=None, 
                 scheduler=None, writer= None, verbose= None, logger= None):
        
        self.cfg = cfg
        self.device = device

        self.train_loader = train_loader
        self.sampler = sampler

        self.model = model['jepa']
        self.msg_enc = model['msg_enc']
        self.comm_module = model['comm_module']
        self.proj = model['proj']

        self.optimizer = optimizer
        self.earlystopping = earlystopping
        self.scheduler = scheduler

        self.writer = writer
        self.verbose = verbose
        self.logger = logger

        self.sigreg = SIGReg().to(self.device)
        self.disSigReg = SIGRegDistributed().to(self.device)
        self.cross_entropy = nn.CrossEntropyLoss()

        # self.anchor_head = nn.Linear(self.cfg.model.jepa.latent_dim, 2).to(self.device)
        self.lambda_ = self.cfg.loss.lambda_
        self.W_H_PRED = self.cfg.loss.W_H_PRED
        self.W_SIM_T = self.cfg.loss.W_SIM_T

        self.agents = [f"agent_{i}" for i in range(len(self.cfg.env.agents))]

        self.dmpc_dir = os.path.join(self.cfg.log_dir, self.cfg.log_subdir, self.cfg.now)
        if not os.path.exists(self.dmpc_dir):
            os.makedirs(self.dmpc_dir , exist_ok=True)

    

# %% ../../nbs/05b_trainers.findgoal_trainer.ipynb 9
@patch
def criterion(
    self: WMTrainer,
    global_step,
    Z0,            # encoded latents [T, B, C, H, W] (stop-grad)
    Z_hat,         # predicted latents [T, B, C, H, W]
    msg_target,
    msg_hat,
    proj_h,
    proj_z,
    mask_t,
    actions=None,          # [T-1, B, A]  (for action-sep)
    anchor_target=None     # optional (dx, dy) or moved flag
):
    """
    Combined JEPA loss with:
    - delta dynamics (B)
    - action separation (A)
    - weak control anchor (C)
    """

    losses = {}

    # ---------------------------------------------------------
    # 1. SIGReg on image / message / obs (UNCHANGED)
    # ---------------------------------------------------------
    flat_encodings = flatten_conv_output(Z0)  # [T, B, d]
    losses['sigreg_img'] = self.disSigReg(flat_encodings[:1], global_step)
    losses['sigreg_msg'] = self.disSigReg(proj_h, global_step)
    losses['sigreg_obs'] = self.disSigReg(proj_z, global_step)

    # ---------------------------------------------------------
    # 2. Transition mask
    # ---------------------------------------------------------
    transition_mask = mask_t[1:] * mask_t[:-1]   # [T-1, B]

    # ---------------------------------------------------------
    # 3. DELTA DYNAMICS LOSS (Option B)
    # ---------------------------------------------------------
    delta_hat = Z_hat[1:] - Z_hat[:-1]
    delta_true = Z0[1:] - Z0[:-1]

    diff_delta = (delta_hat - delta_true).pow(2).mean(dim=(2, 3, 4))
    losses['sim_loss_dynamics'] = (
        (diff_delta * transition_mask).sum()
        / transition_mask.sum().clamp_min(1)
    )

    # ---------------------------------------------------------
    # 4. GATED TIME-SMOOTHNESS (important!)
    # ---------------------------------------------------------
    if self.cfg.loss.vicreg.sim_coeff_t:
        # penalize only unexplained change
        resid = (Z0[1:] - Z0[:-1]) - delta_hat.detach()
        diff_t = resid.pow(2).mean(dim=(2, 3, 4))

        losses['sim_loss_t'] = (
            (diff_t * transition_mask).sum()
            / transition_mask.sum().clamp_min(1)
        )
    else:
        losses['sim_loss_t'] = torch.zeros(1, device=self.device)

    # ---------------------------------------------------------
    # 5. MESSAGE PREDICTION (UNCHANGED)
    # ---------------------------------------------------------
    losses['msg_pred_loss'] = self.cross_entropy(
        msg_hat.flatten(0, 1),
        msg_target.flatten(0, 1)
    )

    # ---------------------------------------------------------
    # 6. SENDER / RECEIVER INVARIANCE (UNCHANGED)
    # ---------------------------------------------------------
    inv_loss_sender = (proj_z - proj_h).square().mean(dim=-1)
    losses['inv_loss_sender'] = (
        (inv_loss_sender * transition_mask).sum()
        / transition_mask.sum().clamp_min(1)
    )

    # ---------------------------------------------------------
    # # 7. ACTION SEPARATION LOSS (Option A)
    # # ---------------------------------------------------------
    # if actions is not None:
    #     # sample a second action (shuffle within batch)
    #     perm = torch.randperm(actions.shape[1])
    #     actions_alt = actions[:, perm]

    #     delta_a1 = self.predict_delta(Z_hat[:-1], actions)
    #     delta_a2 = self.predict_delta(Z_hat[:-1], actions_alt)

    #     act_sep = (delta_a1 - delta_a2).pow(2).mean(dim=(2, 3, 4))
    #     losses['action_separation'] = -(
    #         (act_sep * transition_mask).sum()
    #         / transition_mask.sum().clamp_min(1)
    #     )
    # else:
    #     losses['action_separation'] = torch.zeros(1, device=self.device)

    # ---------------------------------------------------------
    # 8. WEAK CONTROL ANCHOR (Option C)
    # ---------------------------------------------------------
    # if anchor_target is not None:
    #     latents= flatten_conv_output(Z0)  # [T, B, d]
    #     latents = rearrange(latents, 't b d -> (t b) d')  # [(T*B), d]
    #     anchor_pred = self.anchor_head(latents[:-1])
    #     anchor_loss = self.anchor_loss(anchor_pred, anchor_target)

    #     losses['anchor_loss'] = (
    #         (anchor_loss * transition_mask).sum()
    #         / transition_mask.sum().clamp_min(1)
    #     )
    # else:
    #     losses['anchor_loss'] = torch.zeros(1, device=self.device)

    return losses


# %% ../../nbs/05b_trainers.findgoal_trainer.ipynb 10
from ..models.utils import flatten_conv_output
from einops import rearrange
@patch
def train_epoch(self: WMTrainer, epoch):
    self.model.train()
    self.msg_enc.train()
    self.comm_module.train()
    self.proj.train()
    
    total_running_loss = 0.0
    total_valid_steps = 0

    self.logger.info(f"Device used: {self.device}")
    self.sampler.set_epoch(epoch)
    for batch_idx, data in enumerate(self.train_loader):
        global_step = epoch * len(self.train_loader) + batch_idx
        self.optimizer.zero_grad()
        batch_loss = 0

        ## Receiver End
        for agent_id in self.agents:
            obs, pos, _, _, act, _, dones = data[agent_id].values()
            mask = (~dones.bool()).float().to(self.device) # [B, T, d=1]
            mask = rearrange(mask, 'b t d-> b (t d)', d=1)
            mask_t = rearrange(mask, 'b t -> t b')
            
            agent_loss = 0

            if mask.sum() == 0:
                continue 

            obs = obs.to(self.device)
            pos = pos.to(self.device)
            act = act.to(self.device)

            self.logger.info(f"device used for main agent data: {mask_t.device} {obs.device}, {act.device}")

            #### SENDER End
            for sender in self.agents:
                if sender != agent_id:
                    obs_sender, pos_sender, msg, msg_target, _,_, _ = data[sender].values()

                    obs_sender = obs_sender.to(self.device)
                    pos_sender = pos_sender.to(self.device)
                    msg = msg.to(self.device)
                    msg_target = msg_target.to(self.device)

                    self.logger.info(f"device used for other agent data: {obs_sender.device}, {msg.device}")
            
            ### Reciever JEPA
            h = self.msg_enc(msg) # [B, T, C, H, W] => [B, T, dim=32]
            Z0, Z = self.model(x= obs, #[B, T, c, h, w] =>  [T, B, c, h, w]
                               pos= pos, 
                               actions= act, 
                               msgs= h, 
                               T= act.size(1)-1)
            
            # delta_a1 = self.model.dynamics
            
            ## Sender JEPA
            if hasattr(self.model, 'module'):
                z_sender = self.model.module.backbone(obs_sender, position = pos_sender)  #[B, T, c, h, w] => [B, T, c`, h`, w`]
            else:
                z_sender = self.model.backbone(obs_sender, position = pos_sender)  #[B, T, c, h, w] => [B, T, c`, h`, w`]
                
            proj_z, proj_h = self.proj(z_sender, h) #[B, T, c`, h`, w`],[B, T, dim=32] => [T, B, d= 128], [T, B, d= 128]
            msg_hat = self.comm_module(z_sender)  # [B, T, c`, h`, w`] => [B, T, C=5, H=7, W=7]
            
            
            losses = self.criterion(global_step, Z0, Z, msg_target, msg_hat, proj_h, proj_z, mask_t, mask)
          
            if self.verbose:
                self.writer.write({
                    f'{agent_id}/train/sigreg_img': losses['sigreg_img'].item(),
                    f'{agent_id}/train/sigreg_msg': losses['sigreg_msg'].item(),
                    f'{agent_id}/train/sigreg_obs': losses['sigreg_obs'].item(),
                    f'{agent_id}/train/sim_loss': losses['sim_loss_dynamics'].item(),
                    f'{agent_id}/train/sim_loss_t': losses['sim_loss_t'].item(),
                    f'{agent_id}/train/msg_pred_loss': losses['msg_pred_loss'].item(),
                    f'{agent_id}/train/inv_loss_sender': losses['inv_loss_sender'].item(),
                })
    #             with torch.no_grad():
    # dz = (Z[1:] - Z[:-1]).pow(2).mean(dim=(2,3,4))
    # print(dz.mean(), dz.std())

                
            self.logger.info("Losses: %s" % str({k: v.item() for k, v in losses.items()}))
            
            sender_jepa_loss = self.lambda_ * (losses['sigreg_obs'] + losses['sigreg_msg']) + 25.0 * losses['inv_loss_sender']
            rec_jepa_loss = self.lambda_ * losses['sim_loss_dynamics'] + 5.0 * losses['sigreg_img']
            comm_mod_loss = self.W_H_PRED * losses['msg_pred_loss']
            smothness_loss = self.W_SIM_T * losses['sim_loss_t']

            self.logger.info(f"JEPA Losses: sender_jepa_loss: {sender_jepa_loss.item():.4f}, rec_jepa_loss: {rec_jepa_loss.item():.4f}, sim_loss_t: {losses['sim_loss_t'].item():.4f}")

            agent_loss = sender_jepa_loss + rec_jepa_loss + smothness_loss + comm_mod_loss
            scaled_loss = agent_loss / len(self.agents)
            scaled_loss.backward()
            self.logger.info(f"Agent: {agent_id}, agent_loss: {agent_loss.item():.4f}")
            
            batch_loss += scaled_loss

            num_valid = mask.sum().item()
            total_running_loss += agent_loss.item() * num_valid
            total_valid_steps += num_valid
            
        loss = batch_loss
        # loss.backward()
        self.optimizer.step()

        if batch_idx % 20 == 0:
            self.logger.info(f'Train Epoch: {epoch} [{batch_idx * len(obs)}/{len(self.train_loader.dataset)} '
                  f'({100. * batch_idx / len(self.train_loader):.0f}%)]\tLoss: {loss.item():.6f}')

    final_epoch_loss = (total_running_loss / total_valid_steps) / len(self.agents) if total_valid_steps > 0 else 0.0
    self.logger.info(f'====> Epoch: {epoch} Average loss: {final_epoch_loss:.4f}')

    return final_epoch_loss
       

# %% ../../nbs/05b_trainers.findgoal_trainer.ipynb 11
import wandb
CHECKPOINT_FREQ = 1
@patch
def fit(self: WMTrainer):

    latest_file = "latest.pt"
    folder = self.dmpc_dir
    latest_path = os.path.join(folder, latest_file)
    
    loss_meter = AverageMeter()
    lst_dfs = []

    for epoch in range(1, self.cfg.epochs + 1):
        self.logger.info("Epoch %d" % (epoch))
        lr = self.scheduler.adjust_learning_rate(epoch)
        train_loss = self.train_epoch(epoch)
        loss_meter.update(train_loss)
        
        def save_checkpoint(epoch, path):
            if not self.verbose:
                return
            
            def get_state(m):
                return m.module.state_dict() if hasattr(m, 'module') else m.state_dict()
            
            save_dict = {
                'epoch': epoch,
                'jepa': self.model.state_dict(),#get_state(self.model),
                'msg_enc':self.msg_enc.state_dict(),#get_state(self.msg_enc),
                'comm_module': self.comm_module.state_dict(),#get_state(self.comm_module),
                'proj': self.proj.state_dict(),#get_state(self.proj),
                'train_loss': train_loss,
                'optimizer': self.optimizer.state_dict(),
                "lr": lr,
            }
            try:
                torch.save(save_dict, path)
                self.logger.info(f"Successfully saved checkpoint to {path}")
            except Exception as e:
                self.logger.info(f"Encountered exception when saving checkpoint: {e}")
        
        self.logger.info("avg. loss %.3f" % loss_meter.avg)

        df = pd.DataFrame.from_records([{"epoch": epoch ,"train_loss": train_loss}], index= "epoch")
        lst_dfs.append(df)

        if epoch % CHECKPOINT_FREQ == 0 or epoch == (self.cfg.epochs - 1):
            save_checkpoint(epoch + 1, latest_path)
            if self.cfg.save_every_freq > 0 and epoch % self.cfg.save_every_freq == 0:
                save_every_file = f"e{epoch}.pt"
                save_every_path = os.path.join(folder, save_every_file)
                save_checkpoint(epoch + 1, save_every_path)

        to_log = {
            "train_loss": train_loss, 
        }

        if self.verbose:
            self.writer.write(to_log)

    df_res = pd.concat(lst_dfs)
    df_reset = df_res.reset_index()
    if self.verbose:
        self.writer.write({'Train Loss Table': wandb.Table(dataframe= df_reset)})
        self.writer.finish()
    return df_reset
