"""Different architectures for predictors."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/02c_models.dynamics.ipynb.

# %% auto 0
__all__ = ['ConvPredictorConfig', 'ConvPredictor']

# %% ../../nbs/02c_models.dynamics.ipynb 3
from fastcore import *
from fastcore.utils import *

# %% ../../nbs/02c_models.dynamics.ipynb 4
import torch
import torch.nn as nn

# %% ../../nbs/02c_models.dynamics.ipynb 5
from typing import Optional, Union

import torch
from torch import nn
from torch.nn import functional as F
from torch.distributions.normal import Normal
import numpy as np

from .misc import build_mlp
from .utils import *


# %% ../../nbs/02c_models.dynamics.ipynb 15
from .utils import Expander2D
ConvPredictorConfig = {
    "a": [(18, 32, 3, 1, 1), (32, 32, 3, 1, 1), (32, 16, 3, 1, 1)],
    "b": [(18, 32, 5, 1, 2), (32, 32, 5, 1, 2), (32, 16, 5, 1, 2)],
    "c": [(18, 32, 7, 1, 3), (32, 32, 7, 1, 3), (32, 16, 7, 1, 3)],
    "a_propio": [(20, 32, 3, 1, 1), (32, 32, 3, 1, 1), (32, 18, 3, 1, 1)],
    "d4rl_b_p": [(20, 32, 3, 1, 1), (32, 64, 3, 1, 1), (64, 32, 3, 1, 1)],
    "d4rl_c_p": [(36, 32, 3, 1, 1), (32, 32, 3, 1, 1), (32, 34, 3, 1, 1)],
}

class ConvPredictor(nn.Module):
      def __init__(
        self,
        config,
        repr_dim,
        action_dim=5,
        msg_dim=32,
        pred_pos_dim=0,
        pred_obs_dim=0,
        predictor_subclass="a",
        num_groups=4,
    ):
        super().__init__()
        self.config = config
        self.repr_dim = repr_dim
        self.action_dim = action_dim
        self.pred_pos_dim = pred_pos_dim
        self.pred_obs_dim = pred_obs_dim
        self.predictor_subclass = predictor_subclass if not config.predictor_subclass else config.predictor_subclass
        self.num_groups = num_groups
        self.msg_dim = msg_dim

        # Define convolutional layers
        layers = []
        layers_config = ConvPredictorConfig[self.predictor_subclass]
        in_channels, out_channels, k, s, p = layers_config[0]

        if self.config.action_encoder_arch != "id":
            action_inp_dim = int(self.config.action_encoder_arch.split("-")[-1])
        else:
            action_inp_dim = self.action_dim

        actual_in_channels = repr_dim[0] + action_inp_dim + self.msg_dim
        for i in range(len(layers_config) - 1):
            in_channels, out_channels, kernel_size, stride, padding = layers_config[i]

            if i == 0:
                # in_channels = repr_dim[0] + action_dim
                in_channels = actual_in_channels

            layers.append(
                nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)
            )
            layers.append(nn.GroupNorm(4, out_channels))
            layers.append(nn.ReLU())

        # last layer
        in_channels, out_channels, kernel_size, stride, padding = layers_config[-1]
        layers.append(
            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)
        )

        self.layers = nn.Sequential(*layers)
        # In your Predictor/Dynamics model __init__:
        torch.nn.init.zeros_(self.layers[-1].weight)
        torch.nn.init.zeros_(self.layers[-1].bias)

        self.msg_encoder = Expander2D(w=repr_dim[-2], h=repr_dim[-1])

        # Action encoder
        if self.config.action_encoder_arch and self.config.action_encoder_arch != "id":
            layer_dims = [int(x) for x in self.config.action_encoder_arch.split("-")]
            layers = []
            for i in range(len(layer_dims) - 1):
                layers.append(nn.Linear(layer_dims[i], layer_dims[i + 1]))
                layers.append(nn.ReLU())
            # remove last ReLU
            layers.pop()

            self.action_encoder = nn.Sequential(
                *layers,
                Expander2D(w=repr_dim[-2], h=repr_dim[-1]),
            )
            # self.action_dim = layer_dims[-1]
        else:
            self.action_encoder = Expander2D(w=repr_dim[-2], h=repr_dim[-1])

    

# %% ../../nbs/02c_models.dynamics.ipynb 16
@patch
def forward(self: ConvPredictor, current_state, curr_action, curr_msg):
    bs, _, h, w = current_state.shape
    curr_action = self.action_encoder(curr_action)
    curr_msg = self.msg_encoder(curr_msg)
    x = torch.cat([current_state, curr_action, curr_msg], dim=1)
    x = self.layers(x) 
    if self.config.residual:
        x = x + current_state
    return x

# %% ../../nbs/02c_models.dynamics.ipynb 17
@patch
def forward_multiple(
    self: ConvPredictor,
    z0,
    actions,
    msgs,
    T,
    flatten_output=False,
):
    """
    This does multiple steps
    Parameters:
        z0: (T, BS, input_dim)
        actions: (T-1, BS, action_dim)
        T: timesteps to propagate forward
    Output:
        state_predictions: (T, BS, hidden_dim)
    """
    bs = z0.shape[1]
    current_state = z0[0]
    state_predictions = [current_state]
    
    for i in range(T):
        predictor_input = []
        predictor_input.append(actions[i])

        lst_msgs = []
        lst_msgs.append(msgs[i])
        delta = self.forward(
            current_state, torch.cat(predictor_input, dim=-1), torch.cat(lst_msgs, dim=-1)
        )
        delta = torch.tanh(delta) * 0.1  # Constrain the max movement
        next_state = current_state + delta
        # next_state = self.forward(
        #     current_state, torch.cat(predictor_input, dim=-1), torch.cat(lst_msgs, dim=-1)
        # )
        current_state = next_state

        state_predictions.append(next_state)

    t = len(state_predictions)
    state_predictions = torch.stack(state_predictions)
    if flatten_output:
        state_predictions = state_predictions.view(t, bs, -1)

    if self.pred_pos_dim:
        if isinstance(self.pred_pos_dim, int):
            obs_component = state_predictions[:, :, : -self.pred_pos_dim]
            pos_component = state_predictions[:, :, -self.pred_pos_dim :]
        else:
            pred_pos_channels = self.pred_pos_dim[0]
            obs_component = state_predictions[:, :, :-pred_pos_channels]
            pos_component = state_predictions[:, :, -pred_pos_channels:]
    else:
        obs_component = state_predictions
        pos_component = None

    return obs_component

