"""CNN for image feature extraction."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/02b_models.comm.ipynb.

# %% auto 0
__all__ = ['MSGEnc', 'CommModule']

# %% ../../nbs/02b_models.comm.ipynb 3
import numpy as np
import torch
import torch.distributions as td
import torch.nn as nn
from fastcore.utils import *

from torch import nn
from torch.nn import functional as F

# %% ../../nbs/02b_models.comm.ipynb 6
import torch
import torch.nn as nn
import torch.nn.functional as F
from einops import rearrange

class MSGEnc(nn.Module):
    def __init__(self, num_primitives=5, latent_dim=32):
        super().__init__()
        self.latent_dim = latent_dim
        
        self.net = nn.Sequential(
            # First block: extract spatial patterns
            nn.Conv2d(in_channels= num_primitives, out_channels=32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            
            # Second block: downsample
            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1), # Result: 4x4
            nn.BatchNorm2d(64),
            nn.ReLU(),
            
            # Global Average Pool is often better than Flatten + Dense
            # because it makes the encoder more robust to the grid size
            nn.AdaptiveAvgPool2d((1, 1)), 
            nn.Flatten(),
            
            # Final projection to the latent dim
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.Linear(128, latent_dim)
        )
        
    def forward(self, x):
        # Handle B, C, H, W inputs by adding a dummy T=1
        if x.dim() == 4:
            x = x.unsqueeze(1) 
            
        B, T, C, H, W = x.shape
        # Merge B and T for processing
        x = rearrange(x, 'b t c h w -> (b t) c h w')
        
        x = self.net(x)
        
        # Restore T dimension
        return rearrange(x, '(b t) d -> b t d', b=B)

# %% ../../nbs/02b_models.comm.ipynb 10
import torch
import torch.nn as nn
from einops import rearrange

class CommModule(nn.Module):
    def __init__(self, input_channel=32, num_primitives=5):
        super().__init__()
        
        self.network = nn.Sequential(
            # Layer 1: Keep 15x15, increase depth
            nn.Conv2d(input_channel, 64, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            
            # Layer 2: Downsample 15x15 -> 7x7
            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=0),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            
            # Layer 3: Final projection to message primitives
            # We use 3x3 here to give the model a bit more spatial "context" 
            # when deciding the class of a 7x7 cell.
            nn.Conv2d(64, num_primitives, kernel_size=1) 
        )

    def forward(self, x):
        # Handle 5D [B, T, C, H, W]
        is_5d = x.dim() == 5
        if is_5d:
            b, t, c, h, w = x.shape
            x = rearrange(x, 'b t c h w -> (b t) c h w')
        
        logits = self.network(x)
        
        if is_5d:
            logits = rearrange(logits, '(b t) c h w -> b t c h w', b=b, t=t)
            
        return logits # Returns raw logits for CrossEntropyLoss
