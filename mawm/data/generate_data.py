# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/01a_data.generate_data.ipynb.

# %% auto 0
__all__ = ['normalize', 'generate_data_marl_grid_np', 'generate_data_marl_grid_h52', 'collect_one_rollout_h5',
           'collect_one_rollout_ds', 'generate_parallel', 'combine_npz_files', 'concat_arrows']

# %% ../../nbs/01a_data.generate_data.ipynb 4
from fastcore import *
from fastcore.utils import *

# %% ../../nbs/01a_data.generate_data.ipynb 64
def normalize(img):
    return (img - img.min()) / (img.max() - img.min())

# img = obs['agent_0']['pov']


# %% ../../nbs/01a_data.generate_data.ipynb 65
import numpy as np
import os
from ..envs.marl_grid import make_env
from ..envs.marl_grid.cfg import config

def generate_data_marl_grid_np(
    rollouts=3,
    seed_steps=4000,
    data_dir='../marl_grid_data',
    save_metadata=True,      # NEW: save environment metadata
    env_name="marl_grid"
):
    """Generate and save full rollouts from a MarlGrid environment."""
    
    if not os.path.exists(data_dir):
        os.makedirs(data_dir)
    
    def create_env():
        config.env_cfg.seed = np.random.randint(0, 5) # use only small set of envs for training.
        config.env_cfg.max_steps = seed_steps
        env = make_env(config.env_cfg)
        agents = [f'agent_{i}' for i in range(config.env_cfg.num_agents)]
        return env, agents
    
    # Save config metadata once
    if save_metadata:
        meta_path = os.path.join(data_dir, "metadata.npz")
        np.savez_compressed(meta_path, 
                          grid_size=config.env_cfg.grid_size,
                          num_agents=config.env_cfg.num_agents,
                          max_steps=seed_steps,
                          view_size=config.env_cfg.view_size)
    
    for rollout_idx in range(rollouts):
        print(f"\nStarting rollout {rollout_idx}...")
        env, agents = create_env()
        
        # Fresh buffers for each rollout
        agent_data = {
            ag: {
                "obs":  [], 
                "selfpos": [], 
                "orientation": [],
                "sees_goal": [],
                "rew":  [], 
                "act":  [], 
                "done": [],  # Per-agent done status
            } for ag in agents
        }
        
        
        obs = env.reset()
        success = False
        success_at = -1
        goal_pos = obs['global']['goal_pos']
        # import ipdb; ipdb.set_trace()
        goal_obs = np.array([env.get_goal(env.agents[i], goal_pos)[0] for i in range(config.env_cfg.num_agents)])
        
        # Store initial observations
        for idx, ag in enumerate(agents):
            agent_data[ag]["obs"].append(obs[ag]['pov'])
            agent_data[ag]["selfpos"].append(obs[ag]['selfpos'])
            agent_data[ag]["orientation"].append(obs[ag]['orientation'])
            agent_data[ag]["sees_goal"].append(obs["global"]['sees_goal'][idx])
            agent_data[ag]["done"].append(False)  # Initial done status is False
        
        
        
        episode_len = 0
        
        for t in range(seed_steps):
            actions = {ag: env.action_space.sample() for ag in agents}
            obs, rew, done, info = env.step(actions)
            
            for ag in agents:
                agent_data[ag]["obs"].append(obs[ag]['pov'])
                agent_data[ag]["selfpos"].append(obs[ag]['selfpos'])
                agent_data[ag]["orientation"].append(obs[ag]['orientation'])
                agent_data[ag]["sees_goal"].append(info[ag]['sees_goal'])

                agent_data[ag]["rew"].append(rew[ag])
                agent_data[ag]["act"].append(actions[ag])
                agent_data[ag]["done"].append(info[ag]['done'])

                
            
            episode_len += 1
            
            if done['__all__']:
                success = True if all(info[ag]['done'] for ag in agents) else False
                success_at = t if success else -1
                print(f"> Rollout {rollout_idx} ended at step {t} (goal reached or timeout)")
                break
        
        # Save rollout
        save_path = os.path.join(data_dir, f"rollout_{rollout_idx}.npz")
        save_dict = {
            "episode_len": episode_len,
            "rng_state": env.np_random.bit_generator.state['state']['state'],  # Save RNG state for reproducibility
            "seed": config.env_cfg.seed,
            "goal_pos": goal_pos,
            "goal_obs": goal_obs,
            "success": success,
            "success_at": success_at
        }
        final_dict = {
            "global": np.array([save_dict]),
        }

        for agent in agents:
            final_dict[agent] = {
                "obs": np.stack(agent_data[agent]["obs"]),
                "selfpos": np.stack(agent_data[agent]["selfpos"]),
                "orientation": np.stack(agent_data[agent]["orientation"]),
                "sees_goal": np.stack(agent_data[agent]["sees_goal"]),

                "act": np.stack(agent_data[agent]["act"]),
                "rew": np.stack(agent_data[agent]["rew"]),
                "done": np.stack(agent_data[agent]["done"]),
            }
            print(np.stack(agent_data[agent]["obs"]).shape)
        
        
            
        np.savez_compressed(save_path, **final_dict)
        print(f"> Saved rollout {rollout_idx} ({episode_len} steps) to {save_path}")
        
        env.close()
    
    print(f"\nData generation complete! {rollouts} rollouts saved to {data_dir}")

# %% ../../nbs/01a_data.generate_data.ipynb 66
import numpy as np
import os
import h5py
from ..envs.marl_grid import make_env
from ..envs.marl_grid.cfg import config


def generate_data_marl_grid_h52(
    rollouts=3,
    seed_steps=4000,
    data_dir="../marl_grid_data",
    env_name="marl_grid"
):

    os.makedirs(data_dir, exist_ok=True)

    def create_env():
        config.env_cfg.seed = np.random.randint(0, 5)
        config.env_cfg.max_steps = seed_steps
        env = make_env(config.env_cfg)
        agents = [f"agent_{i}" for i in range(config.env_cfg.num_agents)]
        return env, agents

    # ---- Save metadata ONCE ----
    meta_path = os.path.join(data_dir, "metadata.h5")
    if not os.path.exists(meta_path):
        with h5py.File(meta_path, "w") as f:
            f.attrs["grid_size"] = config.env_cfg.grid_size
            f.attrs["num_agents"] = config.env_cfg.num_agents
            f.attrs["max_steps"] = seed_steps
            f.attrs["view_size"] = config.env_cfg.view_size

    for rollout_idx in range(rollouts):
        print(f"\nStarting rollout {rollout_idx}...")

        env, agents = create_env()
        obs = env.reset()

        goal_pos = obs["global"]["goal_pos"]
        goal_obs = np.array(
            [env.get_goal(env.agents[i], goal_pos)[0]
             for i in range(config.env_cfg.num_agents)]
        )

        agent_data = {
            ag: {k: [] for k in
                 ["obs", "selfpos", "orientation", "sees_goal",
                  "act", "rew", "done"]}
            for ag in agents
        }

        # ---- initial observation ----
        for i, ag in enumerate(agents):
            agent_data[ag]["obs"].append(obs[ag]["pov"])
            agent_data[ag]["selfpos"].append(obs[ag]["selfpos"])
            agent_data[ag]["orientation"].append(obs[ag]["orientation"])
            agent_data[ag]["sees_goal"].append(obs["global"]["sees_goal"][i])
            agent_data[ag]["done"].append(False)

        episode_len = 0
        success = False
        success_at = -1

        for t in range(seed_steps):
            actions = {ag: env.action_space.sample() for ag in agents}
            obs, rew, done, info = env.step(actions)

            for ag in agents:
                agent_data[ag]["obs"].append(obs[ag]["pov"])
                agent_data[ag]["selfpos"].append(obs[ag]["selfpos"])
                agent_data[ag]["orientation"].append(obs[ag]["orientation"])
                agent_data[ag]["sees_goal"].append(info[ag]["sees_goal"])
                agent_data[ag]["act"].append(actions[ag])
                agent_data[ag]["rew"].append(rew[ag])
                agent_data[ag]["done"].append(info[ag]["done"])

            episode_len += 1
            if done["__all__"]:
                success = all(info[ag]["done"] for ag in agents)
                success_at = t if success else -1
                print(f"> Rollout {rollout_idx} ended at step {t} (goal reached or timeout), success: {success}")
                break

        env.close()

        # ---- WRITE HDF5 FILE ----
        save_path = os.path.join(data_dir, f"rollout_{rollout_idx}.h5")

        with h5py.File(save_path, "w") as f:

            # ---- global group ----
            g = f.create_group("global")
            g.create_dataset("episode_len", data=episode_len)
            g.create_dataset("goal_pos", data=goal_pos)
            g.create_dataset("goal_obs", data=goal_obs)
            g.create_dataset("success", data=success)
            g.create_dataset("success_at", data=success_at)
            g.attrs["seed"] = config.env_cfg.seed

            # ---- agents ----
            for ag in agents:
                ag_g = f.create_group(ag)

                for key, seq in agent_data[ag].items():
                    arr = np.stack(seq)
                    ag_g.create_dataset(
                        key,
                        data=arr,
                        compression="gzip",
                        compression_opts=4,
                        chunks=True
                    )

        print(f"> Saved rollout {rollout_idx} ({episode_len} steps) → {save_path}")

    print(f"\nData generation complete: {rollouts} rollouts saved.")


# %% ../../nbs/01a_data.generate_data.ipynb 67
import os
import numpy as np
import h5py
from ..envs.marl_grid import make_env
from ..envs.marl_grid.cfg import config

def collect_one_rollout_h5(args):
    rollout_idx, seed_steps, data_dir = args  

    config.env_cfg.seed = np.random.randint(0, 5)
    config.env_cfg.max_steps = seed_steps

    env = make_env(config.env_cfg)
    agents = [f"agent_{i}" for i in range(config.env_cfg.num_agents)]

    obs = env.reset()
    goal_pos = obs["global"]["goal_pos"]
    goal_obs = np.array(
            [env.get_goal(env.agents[i], goal_pos)[0]
             for i in range(config.env_cfg.num_agents)]
            )
    layout = env.get_layout(render_kwargs={"tile_size":11})

    agent_data = {
        ag: {k: [] for k in
             ["obs", "selfpos", "orientation", "sees_goal",
              "act", "rew", "done"]}
        for ag in agents
    }

    for i, ag in enumerate(agents):
        agent_data[ag]["obs"].append(obs[ag]["pov"])
        agent_data[ag]["selfpos"].append(obs[ag]["selfpos"])
        agent_data[ag]["orientation"].append(obs[ag]["orientation"])
        agent_data[ag]["sees_goal"].append(obs["global"]["sees_goal"][i])
        agent_data[ag]["done"].append(False)

    episode_len = 0
    success = False
    success_at = -1

    for t in range(seed_steps):
        actions = {ag: env.action_space.sample() for ag in agents}
        obs, rew, done, info = env.step(actions)

        for ag in agents:
            agent_data[ag]["obs"].append(obs[ag]["pov"])
            agent_data[ag]["selfpos"].append(obs[ag]["selfpos"])
            agent_data[ag]["orientation"].append(obs[ag]["orientation"])
            agent_data[ag]["sees_goal"].append(info[ag]["sees_goal"])
            agent_data[ag]["act"].append(actions[ag])
            agent_data[ag]["rew"].append(rew[ag])
            agent_data[ag]["done"].append(info[ag]["done"])

        episode_len += 1
        if done["__all__"]:
            success = all(info[ag]["done"] for ag in agents)
            success_at = t if success else -1
            break

    env.close()

    roolout_dir = os.path.join(data_dir, f"rollout_{rollout_idx}")
    os.makedirs(roolout_dir, exist_ok=True)
    save_path = os.path.join(roolout_dir, f"rollout_{rollout_idx}.h5")
    metadata_path = os.path.join(roolout_dir, "metadata.h5")

    with h5py.File(metadata_path, "w") as f:
        g = f.create_group("global")
        g.create_dataset("layout", data=layout)
        g.create_dataset("goal_pos", data=goal_pos)
        g.create_dataset("goal_obs", data=goal_obs)

        g.attrs["episode_len"] = episode_len
        g.attrs["success"] = success
        g.attrs["success_at"] = success_at
        g.attrs["seed"] = config.env_cfg.seed
        g.attrs["rng_state"] = str(env.np_random.bit_generator.state['state']['state'])
        
    f.close()
    with h5py.File(save_path, "w") as f:
        for ag in agents:
            ag_g = f.create_group(ag)
            for k, seq in agent_data[ag].items():
                ag_g.create_dataset(
                    k,
                    data=np.stack(seq),
                    compression="gzip",
                    chunks=True
                )
    f.close()
    
    return rollout_idx


# %% ../../nbs/01a_data.generate_data.ipynb 68
import os
import numpy as np
from datasets import Dataset
from ..envs.marl_grid import make_env
from ..envs.marl_grid.cfg import config
from datasets import Features, Value, Array3D, Image, List
import copy
def collect_one_rollout_ds(args=None):
    rollout_idx, seed, seed_steps, data_dir = args

    cfg = copy.deepcopy(config)
    cfg.env_cfg.seed = seed#np.random.randint(0, 5)
    cfg.env_cfg.max_steps = seed_steps

    env = make_env(cfg.env_cfg)
    agents = [f"agent_{i}" for i in range(cfg.env_cfg.num_agents)]
    obs = env.reset()
    goal_pos = obs["global"]["goal_pos"]
    goal_obs = np.array([
        env.get_goal(env.agents[i], goal_pos)[0]
        for i in range(config.env_cfg.num_agents)
    ])
    
    layout = env.get_layout(render_kwargs={"tile_size":11})

    # Initialize data dictionary
    agent_data = {
        ag: {k: [] for k in ["obs", "next_obs", "selfpos", "orientation", "sees_goal", "act", "rew", "done"]}
        for ag in agents
    }

    episode_len = 0
    success = False
    success_at = -1

    prev_obs = obs
    for t in range(seed_steps):
        actions = {ag: env.action_space.sample() for ag in agents}
        obs, rew, done, info = env.step(actions)

        for ag in agents:
            agent_data[ag]["obs"].append(prev_obs[ag]["pov"])
            agent_data[ag]["next_obs"].append(obs[ag]["pov"])
            agent_data[ag]["selfpos"].append(obs[ag]["selfpos"])
            agent_data[ag]["orientation"].append(obs[ag]["orientation"])
            agent_data[ag]["sees_goal"].append(info[ag]["sees_goal"])
            agent_data[ag]["act"].append(actions[ag])
            agent_data[ag]["rew"].append(rew[ag])
            agent_data[ag]["done"].append(info[ag]["done"])

        prev_obs = obs
        episode_len += 1
        if done["__all__"]:
            success = all(info[ag]["done"] for ag in agents)
            success_at = t if success else -1
            break

    env.close()
 
    rows = []

    T = len(agent_data[agents[0]]["obs"])

    for t in range(T):
        row = {}

        for ag in agents:
            row[f"{ag}_obs"] = agent_data[ag]["obs"][t].astype(np.float32)
            row[f"{ag}_next_obs"] = agent_data[ag]["next_obs"][t].astype(np.float32)
            row[f"{ag}_selfpos"] = agent_data[ag]["selfpos"][t].astype(np.float32)
            row[f"{ag}_orientation"] = int(agent_data[ag]["orientation"][t])
            row[f"{ag}_sees_goal"] = bool(agent_data[ag]["sees_goal"][t])
            row[f"{ag}_act"] = int(agent_data[ag]["act"][t])
            row[f"{ag}_rew"] = float(agent_data[ag]["rew"][t])
            row[f"{ag}_done"] = bool(agent_data[ag]["done"][t])

        row['transition_idx'] = int(t)
        row['rollout_idx'] = int(rollout_idx)
        rows.append(row)


    feat_dict = {}

    for ag in agents:
        feat_dict[f"{ag}_obs"] = Array3D(shape=(42, 42, 3), dtype="float32")
        feat_dict[f"{ag}_next_obs"] = Array3D(shape=(42, 42, 3), dtype="float32")
        feat_dict[f"{ag}_selfpos"] = List(Value('float32'))
        feat_dict[f"{ag}_act"] = Value("int32")
        feat_dict[f"{ag}_rew"] = Value("float32")
        feat_dict[f"{ag}_orientation"] = Value("int32")
        feat_dict[f"{ag}_sees_goal"] = Value("bool")
        feat_dict[f"{ag}_done"] = Value("bool")

    feat_dict.update({
        "transition_idx": Value("int32"),
        "rollout_idx": Value("int32"),
    })

    features = Features(feat_dict)    
    dataset = Dataset.from_list(rows, features=features)
    rollout_save_path = os.path.join(data_dir, f"rollout_{rollout_idx}")
    dataset.save_to_disk(rollout_save_path)
    meta_data_path = os.path.join(rollout_save_path, f"metadata_{rollout_idx}.npz")

    # mata_keys = ['layout', 'goal_pos', 'goal_obs', 'episode_len', 'success', 'success_at', 'seed']
    meta_data = {}
    meta_data['goal_pos'] = goal_pos
    meta_data['episode_len'] = episode_len
    meta_data['success'] = success
    meta_data['success_at'] = success_at
    meta_data['seed'] = config.env_cfg.seed
    # meta_data['rng_state'] = env.np_random.bit_generator.state['state']['state']
    meta_data['layout'] = layout
    meta_data['goal_obs'] = goal_obs

    np.savez(meta_data_path, **meta_data)
    
    return rollout_idx

# %% ../../nbs/01a_data.generate_data.ipynb 69
from multiprocessing import Pool, cpu_count

def generate_parallel(
    rollouts=100,
    seed_steps=4000,
    data_dir="../datasets/marl_grid_data_v3",
    workers=None,
    num_seeds=5,
):
    os.makedirs(data_dir, exist_ok=True)

    if workers is None:
        workers = min(cpu_count(), rollouts)
   
    seeds = np.tile(np.arange(num_seeds), int(np.ceil(rollouts / num_seeds)))
    seeds = seeds[:rollouts]
    np.random.shuffle(seeds)
    
    args = [
        (i, seeds[i], seed_steps, data_dir)
        for i in range(rollouts)
    ]

    with Pool(processes=workers) as p:
        for idx in p.imap_unordered(collect_one_rollout_ds, args):
            print(f"✓ rollout {idx} done")


# %% ../../nbs/01a_data.generate_data.ipynb 71
import numpy as np
from pathlib import Path

def combine_npz_files(meta_files, output_file="meta_data_merged.npz"):
    master_dict = {}

    for i, file_path in enumerate(meta_files):
        with np.load(file_path, allow_pickle=True) as data:
            for key in data.files:
                new_key = f"rollout_{i}_{key}"
                master_dict[new_key] = data[key]

    np.savez_compressed(output_file, **master_dict)

# %% ../../nbs/01a_data.generate_data.ipynb 72
from datasets import load_from_disk, concatenate_datasets
import shutil
def concat_arrows(paths):

    ds = concatenate_datasets([load_from_disk(p) for p in paths])

    merged_dir = os.path.join(os.path.dirname(paths[0]), "merged_dataset")
    os.makedirs(merged_dir, exist_ok=True)

    ds.save_to_disk(merged_dir)
    print(f"Merged dataset saved to {merged_dir}")

    paths = sorted(paths, key=lambda x: int(x.split('_')[-1]))

    meta_paths = [os.path.join(p, f"metadata_{i}.npz") for i, p in enumerate(paths)]
    meta_paths = sorted(meta_paths, key=lambda x: int(x.split('_')[-1].split('.')[0]))
    print(meta_paths)
    os.makedirs(os.path.join(merged_dir), exist_ok=True)

    
    combine_npz_files(meta_paths, output_file=os.path.join(merged_dir, "metadata_merged.npz"))
    print(f"Copied metadata files to {os.path.join(merged_dir)}")

    
