"""Contain various loss functions used for optimization."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/03c_losses.sigreg.ipynb.

# %% auto 0
__all__ = ['SIGReg']

# %% ../../nbs/03c_losses.sigreg.ipynb 3
from fastcore import *
from fastcore.utils import *

# %% ../../nbs/03c_losses.sigreg.ipynb 4
import torch
import torch.nn as nn
import torch.nn.functional as F

# %% ../../nbs/03c_losses.sigreg.ipynb 5
import torch
class SIGReg(torch.nn.Module):
    def __init__(self, knots=17):
        super().__init__()
        t = torch.linspace(0, 3, knots, dtype=torch.float32)
        dt = 3 / (knots - 1)
        weights = torch.full((knots,), 2 * dt, dtype=torch.float32)
        weights[[0, -1]] = dt
        window = torch.exp(-t.square() / 2.0)
        self.register_buffer("t", t)
        self.register_buffer("phi", window)
        self.register_buffer("weights", weights * window)

    def forward(self, proj):
        A = torch.randn(proj.size(-1), 256, device=proj.device)
        A = A.div_(A.norm(p=2, dim=0))
        x_t = (proj @ A).unsqueeze(-1) * self.t
        err = (x_t.cos().mean(-3) - self.phi).square() + x_t.sin().mean(-3).square()
        statistic = (err @ self.weights) * proj.size(-2)
        return statistic.mean()

