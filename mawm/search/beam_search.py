"""This module handles all aspects of the VAE, including encoding, decoding, and latent space representation."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/06a_search.beam_search.ipynb.

# %% auto 0
__all__ = ['neural_guided_beam_search', 'neural_guided_beam_search_batched']

# %% ../../nbs/06a_search.beam_search.ipynb 3
from fastcore import *
from fastcore.utils import *
from torchvision.utils import save_image
import torch
import os
from torch import nn
import torch.nn.functional as F
import pandas as pd

# %% ../../nbs/06a_search.beam_search.ipynb 10
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from ..core import Program, PRIMITIVE_TEMPLATES
# from mawm.models.program_embedder import batchify_programs
from ..models.program_encoder import ProgramEncoder
from ..models.program_synthizer import Proposer

@torch.no_grad()
def neural_guided_beam_search(
    z,
    program_embedder: nn.Module,
    proposer: nn.Module,
    program_encoder: nn.Module,
    score_fn,
    MAX_PARAMS=3,
    beam_width=5,
    topk=6,
    max_prog_len=5,
    grid_size=7,
    lambdas= (0.25, 0.5, 0.25),
    device="cuda"
):
    """
    neural-guided beam search.
    """

    # --- normalize z shape ---
    z = z.to(device)
    if z.dim() == 1:
        z = z.unsqueeze(0)
    lambda_1, lambda_2, lambda_3 = lambdas

    sos_idx = proposer.sos_idx
    EOS_IDX = len(PRIMITIVE_TEMPLATES)
    zero_params = torch.full((MAX_PARAMS,), -1, device=device)

    # initial program: [SOS]
    init_prog = Program(tokens=[(sos_idx, zero_params.tolist())])
    beam = [(init_prog, 0.0)]  # (program, score)

    best_program = init_prog
    best_score = -float("inf")

    # ---- start beam search ----
    for depth in range(1, max_prog_len + 1):
        alive = []
        finished = []

        for prog, score in beam:
            last_prim = prog.tokens[-1][0]
            if last_prim == EOS_IDX:
                finished.append((prog, score))
            else:
                alive.append((prog, score))

        if len(alive) == 0:
            break
        # ---- 1) build batch of prefixes ----
        prefix_programs = [p for (p, _) in alive]
        prev_idx_batch, prev_params_batch = batchify_programs(prefix_programs, seq_len=max_prog_len, max_params=MAX_PARAMS)
        prev_idx_batch = prev_idx_batch.to(torch.long)
        prev_params_batch = prev_params_batch.to(torch.long)
        B = prev_idx_batch.shape[0]

        p_vec = program_embedder(prev_idx_batch.to(device),
                                 prev_params_batch.to(device))

        # replicate z
        z_batch = z.repeat(B, 1)

        # # proposer forward
        prim_logits_batch, param_pred_batch = proposer.forward_step(z_batch, p_vec)

        # ---- 2) expand each beam entry ----
        expansions = []
        for b_i, (prog_parent, parent_score) in enumerate(alive):
            prim_logprobs = F.log_softmax(prim_logits_batch[b_i], dim=-1)
            top_vals, top_idx = torch.topk(prim_logprobs, k=topk)

            for k_i in range(topk):
                prim_idx = int(top_idx[k_i].item())
                prim_logp = float(top_vals[k_i].item())
                if prim_idx == EOS_IDX:
                    # add program as completed (no more expansions)
                    new_prog = prog_parent.extend(prim_idx, [])
                    expansions.append((new_prog, parent_score + prim_logp))
                    # print(f"Beam search found EOS at depth {depth} with program: {new_prog}")
                    continue

                arity = PRIMITIVE_TEMPLATES[prim_idx][1]              

                # ----- parameter instantiation -----
                instantiations = []
                if arity > 0:
                    pred_params = param_pred_batch[b_i][:arity].cpu().numpy()
                    for _ in range(3):
                        if np.random.rand() < 0.7:
                            inst = [
                                float(round(float(p) * (grid_size - 1)))
                                for p in pred_params
                            ]
                        else:
                            inst = [
                                float(np.random.randint(0, grid_size))
                                for _ in range(arity)
                            ]
                        instantiations.append(inst)
                else:
                    instantiations.append([])

                # ----- create new beam children -----
                for inst_params in instantiations:
                    new_prog = prog_parent.extend(prim_idx, inst_params)
                    expansions.append((new_prog, parent_score + prim_logp))

        if not expansions:
            break

        # ---- 3) Score all expanded programs ----
        cand_programs = [p for (p, _) in expansions]
        prim_ids_padded, params_padded = batchify_programs(cand_programs, seq_len=max_prog_len, max_params=MAX_PARAMS)
        # import ipdb; ipdb.set_trace()
        params_padded = params_padded.to(torch.long)
        prim_ids_padded = prim_ids_padded.to(torch.long)

        with torch.no_grad():
            # program_encoder = get_pencoder(prim_ids_padded.shape[-1])
            prog_emb_batch = program_encoder(prim_ids_padded, params_padded)

        scores = score_fn(z, prog_emb_batch)

        # ---- 4) attach scores and prune ----
        candidates = []
        for idx_c, (prog, base_score) in enumerate(expansions):
            total = lambda_1 * base_score + lambda_2 * float(scores[idx_c].item()) - lambda_3 * len(prog.tokens) 
            candidates.append((prog, total))

        candidates.sort(key=lambda x: x[1], reverse=True)
        # best_program, best_score = max(candidates, key=lambda x: x[1])

        topk_from_alive = candidates#[:beam_width]
        beam = topk_from_alive + finished

        filtered_beam = []
        for p in beam:
            if len(p[0].tokens) == 1 and p[0].tokens[0][0] == -1:
                continue
            filtered_beam.append(p)
        if len(filtered_beam) == 0:
            break

        best_program, best_score = max(filtered_beam, key=lambda x: x[1])
        beam = sorted(beam, key=lambda x: x[1], reverse=True)[:beam_width]

        # update alive + finished splits
        alive  = [(p,s) for (p,s) in beam if not p.finished]
        finished = [(p,s) for (p,s) in beam if p.finished]

    return best_program, best_score


# %% ../../nbs/06a_search.beam_search.ipynb 14
@torch.no_grad()
def neural_guided_beam_search_batched(
    z_batch,                      # shape [B, D]
    program_embedder,
    proposer,
    program_encoder,
    score_fn,
    MAX_PARAMS=3,
    beam_width=5,
    topk=6,
    max_prog_len=5,
    grid_size=7,
    lambdas=(0.25, 0.5, 0.25),
    device="cuda",
):
    """
    Batched version: run *one beam search per batch element*.
    Returns:
        list of length B, each entry is (best_program, best_score)
    """

    z_batch = z_batch.to(device)
    if z_batch.dim() == 1:
        z_batch = z_batch.unsqueeze(0)

    B = z_batch.shape[0]
    results = []

    # --- run your SAME beam search per batch element ---
    for b in range(B):
        z_single = z_batch[b]  # shape [D]
        best_prog, best_score = neural_guided_beam_search(
            z_single,
            program_embedder,
            proposer,
            program_encoder,
            score_fn,
            MAX_PARAMS=MAX_PARAMS,
            beam_width=beam_width,
            topk=topk,
            max_prog_len=max_prog_len,
            grid_size=grid_size,
            lambdas=lambdas,
            device=device,
        )
        results.append((best_prog, best_score))

    return results

