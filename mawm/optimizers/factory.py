"""This module handles all aspects of the world model, including state representation, environment dynamics, and prediction."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/04d_optimizers.factory.ipynb.

# %% auto 0
__all__ = ['OptimizerType', 'OptimizerFactory']

# %% ../../nbs/04d_optimizers.factory.ipynb 3
from fastcore import *
from fastcore.utils import *

# %% ../../nbs/04d_optimizers.factory.ipynb 4
from functools import partial
from torch.optim import Optimizer

# %% ../../nbs/04d_optimizers.factory.ipynb 5
import torch
from .lars import LARS, exclude_bias_and_norm
import enum


class OptimizerType(enum.Enum):
    Adam = "sgd"
    LARS = "lars"


class OptimizerFactory:
    def __init__(
        self,
        model: torch.nn.Module,
        optimizer_type: str,
        base_lr: float,
    ):
        self.model = model
        self.optimizer_type = optimizer_type
        self.base_lr = base_lr

    def create_optimizer(self):
        if self.optimizer_type == OptimizerType.LARS:
            optimizer = LARS(
                self.model.parameters(),
                lr=0,
                weight_decay=1e-6,
                weight_decay_filter=exclude_bias_and_norm,
                lars_adaptation_filter=exclude_bias_and_norm,
            )
        elif self.optimizer_type == OptimizerType.Adam:
            params_list = [
                {
                    "params": self.model.parameters(),
                    "lr": self.base_lr,
                }
            ]

            optimizer = torch.optim.Adam(
                params_list,
                weight_decay=1e-6,
            )
        else:
            raise NotImplementedError("Unknown optimizer type")

        return optimizer
