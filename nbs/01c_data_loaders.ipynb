{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52c32977",
   "metadata": {},
   "source": [
    "# data loaders for rollouts \n",
    "\n",
    "> This module handles all communication-related functionalities, including message passing, event handling, and notifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bbc689",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data.loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daacb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1f1157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore import *\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1da2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from bisect import bisect\n",
    "from os import listdir\n",
    "from os.path import join, isdir\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a83b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class _RolloutDataset(torch.utils.data.Dataset): # pylint: disable=too-few-public-methods\n",
    "    def __init__(self, root, transform, buffer_size=200, train=True): # pylint: disable=too-many-arguments\n",
    "        self._transform = transform\n",
    "\n",
    "        self._files = [\n",
    "            join(root, sd, ssd)\n",
    "            for sd in listdir(root) if isdir(join(root, sd))\n",
    "            for ssd in listdir(join(root, sd))]\n",
    "\n",
    "        if train:\n",
    "            self._files = self._files[:-600]\n",
    "        else:\n",
    "            self._files = self._files[-600:]\n",
    "\n",
    "        self._cum_size = None\n",
    "        self._buffer = None\n",
    "        self._buffer_fnames = None\n",
    "        self._buffer_index = 0\n",
    "        self._buffer_size = buffer_size\n",
    "\n",
    "    def load_next_buffer(self):\n",
    "        \"\"\" Loads next buffer \"\"\"\n",
    "        self._buffer_fnames = self._files[self._buffer_index:self._buffer_index + self._buffer_size]\n",
    "        self._buffer_index += self._buffer_size\n",
    "        self._buffer_index = self._buffer_index % len(self._files)\n",
    "        self._buffer = []\n",
    "        self._cum_size = [0]\n",
    "\n",
    "        # progress bar\n",
    "        pbar = tqdm(total=len(self._buffer_fnames),\n",
    "                    bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} {postfix}')\n",
    "        pbar.set_description(\"Loading file buffer ...\")\n",
    "\n",
    "        for f in self._buffer_fnames:\n",
    "            with np.load(f, allow_pickle= True) as data:\n",
    "                self._buffer += [{k: np.copy(v) for k, v in data.items()}]\n",
    "                self._cum_size += [self._cum_size[-1] +\n",
    "                                   self._data_per_sequence(data['player_0_rewards'].shape[0])]\n",
    "            pbar.update(1)\n",
    "        pbar.close()\n",
    "\n",
    "    def __len__(self):\n",
    "        # to have a full sequence, you need self.seq_len + 1 elements, as\n",
    "        # you must produce both an seq_len obs and seq_len next_obs sequences\n",
    "        if not self._cum_size:\n",
    "            self.load_next_buffer()\n",
    "        return self._cum_size[-1]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # binary search through cum_size\n",
    "        file_index = bisect(self._cum_size, i) - 1\n",
    "        seq_index = i - self._cum_size[file_index]\n",
    "        data = self._buffer[file_index]\n",
    "        return self._get_data(data, seq_index)\n",
    "\n",
    "    def _get_data(self, data, seq_index):\n",
    "        pass\n",
    "\n",
    "    def _data_per_sequence(self, data_length):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79921ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RolloutObservationDataset(_RolloutDataset): # pylint: disable=too-few-public-methods\n",
    "    \"\"\" Encapsulates rollouts.\n",
    "\n",
    "    Rollouts should be stored in subdirs of the root directory, in the form of npz files,\n",
    "    each containing a dictionary with the keys:\n",
    "        - observations: (rollout_len, *obs_shape)\n",
    "        - actions: (rollout_len, action_size)\n",
    "        - rewards: (rollout_len,)\n",
    "        - terminals: (rollout_len,), boolean\n",
    "\n",
    "     As the dataset is too big to be entirely stored in rams, only chunks of it\n",
    "     are stored, consisting of a constant number of files (determined by the\n",
    "     buffer_size parameter).  Once built, buffers must be loaded with the\n",
    "     load_next_buffer method.\n",
    "\n",
    "    Data are then provided in the form of images\n",
    "\n",
    "    :args root: root directory of data sequences\n",
    "    :args seq_len: number of timesteps extracted from each rollout\n",
    "    :args transform: transformation of the observations\n",
    "    :args train: if True, train data, else test\n",
    "    \"\"\"\n",
    "    def _data_per_sequence(self, data_length):\n",
    "        return data_length\n",
    "\n",
    "    def _get_data(self, data, seq_index):\n",
    "        return (self._transform(data['player_0_observations'][seq_index]['RGB']), \\\n",
    "            data['player_0_rewards'][seq_index], \\\n",
    "            data['player_0_actions'][seq_index], \\\n",
    "            data['player_0_terminations'][seq_index]), \\\n",
    "            (self._transform(data['player_1_observations'][seq_index]['RGB']), \\\n",
    "            data['player_1_rewards'][seq_index], \\\n",
    "            data['player_1_actions'][seq_index], \\\n",
    "            data['player_1_terminations'][seq_index])\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0378bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RolloutSequenceDataset(_RolloutDataset): # pylint: disable=too-few-public-methods\n",
    "    \"\"\" Encapsulates rollouts.\n",
    "\n",
    "    Rollouts should be stored in subdirs of the root directory, in the form of npz files,\n",
    "    each containing a dictionary with the keys:\n",
    "        - observations: (rollout_len, *obs_shape)\n",
    "        - actions: (rollout_len, action_size)\n",
    "        - rewards: (rollout_len,)\n",
    "        - terminals: (rollout_len,), boolean\n",
    "\n",
    "     As the dataset is too big to be entirely stored in rams, only chunks of it\n",
    "     are stored, consisting of a constant number of files (determined by the\n",
    "     buffer_size parameter).  Once built, buffers must be loaded with the\n",
    "     load_next_buffer method.\n",
    "\n",
    "    Data are then provided in the form of tuples (obs, action, reward, terminal, next_obs):\n",
    "    - obs: (seq_len, *obs_shape)\n",
    "    - actions: (seq_len, action_size)\n",
    "    - reward: (seq_len,)\n",
    "    - terminal: (seq_len,) boolean\n",
    "    - next_obs: (seq_len, *obs_shape)\n",
    "\n",
    "    NOTE: seq_len < rollout_len in moste use cases\n",
    "\n",
    "    :args root: root directory of data sequences\n",
    "    :args seq_len: number of timesteps extracted from each rollout\n",
    "    :args transform: transformation of the observations\n",
    "    :args train: if True, train data, else test\n",
    "    \"\"\"\n",
    "    def __init__(self, root, seq_len, transform, buffer_size=200, train=True): # pylint: disable=too-many-arguments\n",
    "        super().__init__(root, transform, buffer_size, train)\n",
    "        self._seq_len = seq_len\n",
    "\n",
    "    def _get_data(self, data, seq_index):\n",
    "        obs_data = data['observations'][seq_index:seq_index + self._seq_len + 1]\n",
    "        obs_data = self._transform(obs_data.astype(float32))\n",
    "        obs, next_obs = obs_data[:-1], obs_data[1:]\n",
    "        action = data['actions'][seq_index+1:seq_index + self._seq_len + 1]\n",
    "        action = action.astype(float32)\n",
    "        reward, terminal = [data[key][seq_index+1:\n",
    "                                      seq_index + self._seq_len + 1].astype(float32)\n",
    "                            for key in ('rewards', 'terminals')]\n",
    "        # data is given in the form\n",
    "        # (obs, action, reward, terminal, next_obs)\n",
    "        return obs, action, reward, terminal, next_obs\n",
    "\n",
    "    def _data_per_sequence(self, data_length):\n",
    "        return data_length - self._seq_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72414cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
