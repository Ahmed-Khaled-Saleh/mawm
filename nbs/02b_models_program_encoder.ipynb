{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program Encoder\n",
    "\n",
    "> Get program rcontinuous representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.program_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore import *\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from MAWM.models.dense import DenseModel\n",
    "from MAWM.models.program_embedder import ProgramEmbedder\n",
    "from MAWM.core import PRIMITIVE_TEMPLATES\n",
    "\n",
    "class ProgramEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_primitives,\n",
    "        param_cardinalities,   # list: for each slot, how many discrete values possible\n",
    "        max_params_per_primitive,\n",
    "        seq_len=4,\n",
    "        d_name=32,\n",
    "        d_param=32,\n",
    "        output_dim=256,\n",
    "        model_info={ 'layers': 3,'node_size': 128,'activation': nn.ReLU,'dist': None}\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.program_embedder = ProgramEmbedder(\n",
    "            num_primitives= num_primitives,\n",
    "            param_cardinalities= param_cardinalities,\n",
    "            max_params_per_primitive= max_params_per_primitive,\n",
    "            d_name= d_name,\n",
    "            d_param= d_param,\n",
    "        )\n",
    "\n",
    "        self.fuse = nn.Linear(seq_len * (d_name + d_param + d_param), model_info['node_size'])\n",
    "        self.program_mlp = DenseModel(output_shape= (output_dim,), input_size=model_info['node_size'], info= model_info)\n",
    "\n",
    "    def forward(self, primitive_ids, param_ids):\n",
    "        \"\"\"\n",
    "        primitive_ids: LongTensor of shape [B, L]\n",
    "        param_ids: LongTensor of shape [B, L, max_params] with -1 for missing parameters\n",
    "        \"\"\"\n",
    "        combined_B_L_D = self.program_embedder(primitive_ids, param_ids) # shape: [B, L, D]\n",
    "        B, L, D = combined_B_L_D.shape\n",
    "        combined_B_LD = combined_B_L_D.view(B, L * D)  # Flatten to [B, D]\n",
    "        combined_B_LD = self.fuse(combined_B_LD)  # shape: [B, node_size]\n",
    "        primitive_vec = self.program_mlp(combined_B_LD)# shape: [B, output_dim]\n",
    "        \n",
    "        return primitive_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "pe = ProgramEncoder(num_primitives= len(PRIMITIVE_TEMPLATES),\n",
    "                    param_cardinalities= [7, 7],\n",
    "                    seq_len= 3,\n",
    "                    max_params_per_primitive= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProgramEncoder(\n",
       "  (program_embedder): ProgramEmbedder(\n",
       "    (name_embed): Embedding(6, 32)\n",
       "    (param_embeds): ModuleList(\n",
       "      (0-1): 2 x Embedding(7, 32)\n",
       "    )\n",
       "  )\n",
       "  (fuse): Linear(in_features=288, out_features=128, bias=True)\n",
       "  (program_mlp): DenseModel(\n",
       "    (model): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=128, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from MAWM.models.program_embedder import batchify_programs, get_indices\n",
    "from MAWM.core import Program, PRIMITIVE_TEMPLATES\n",
    "batch_programs = [\n",
    "    Program(tokens= [(0, [1.0, 2.0]), (4, []), (1, [3.0, 4.0])]), # L=3\n",
    "    Program(tokens= [(2, [5.0]), (3, [6.0, 5.0])]) # L=2\n",
    "]\n",
    "\n",
    "\n",
    "input_prim, input_params = batchify_programs(batch_programs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  4,  1],\n",
       "         [ 2,  3, -1]]),\n",
       " tensor([[[ 1,  2],\n",
       "          [-1, -1],\n",
       "          [ 3,  4]],\n",
       " \n",
       "         [[ 5, -1],\n",
       "          [ 6,  5],\n",
       "          [-1, -1]]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_prim, input_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe(input_prim, input_params).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from MAWM.models.dense import DenseModel\n",
    "from MAWM.models.program_embedder import ProgramEmbedder\n",
    "from MAWM.core import PRIMITIVE_TEMPLATES\n",
    "\n",
    "class ProgramPredictor(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_dim=32,\n",
    "        model_info={ 'layers': 3,'node_size': 256,'activation': nn.ReLU,'dist': None}\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.predictor = DenseModel(output_shape= (output_dim,), input_size=model_info['node_size'], info= model_info)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        primitive_ids: LongTensor of shape [B, L]\n",
    "        param_ids: LongTensor of shape [B, L, max_params] with -1 for missing parameters\n",
    "        \"\"\"\n",
    "        z_hat = self.predictor(x)# shape: [B, output_dim]\n",
    "        \n",
    "        return z_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
