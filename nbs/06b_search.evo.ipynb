{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fb656fc",
   "metadata": {},
   "source": [
    "# Beam Search Module\n",
    "\n",
    "> This module handles all aspects of the VAE, including encoding, decoding, and latent space representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbb56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp search.evo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd36cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore import *\n",
    "from fastcore.utils import *\n",
    "from torchvision.utils import save_image\n",
    "import torch\n",
    "import os\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd39ebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from MAWM.core import Program, PRIMITIVE_TEMPLATES\n",
    "\n",
    "@torch.no_grad()\n",
    "def neural_guided_beam_search_corrected(\n",
    "    z_obs: torch.FloatTensor,         # Sender's observation (for proposer)\n",
    "    z_receiver: torch.FloatTensor,     # Receiver's current state\n",
    "    z_target: torch.FloatTensor,       # Target next state\n",
    "    a_t: torch.FloatTensor,            # Action taken\n",
    "    r_target: torch.FloatTensor,       # Target reward\n",
    "    proposer,\n",
    "    encoder,\n",
    "    world_model,\n",
    "    reward_model,\n",
    "    score_fn,\n",
    "    batchify_programs,\n",
    "    MAX_PARAMS: int = 3,\n",
    "    beam_width: int = 5,\n",
    "    topk: int = 6,\n",
    "    max_prog_len: int = 5,\n",
    "    grid_size: int = 5,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Neural-guided beam search for program inference.\n",
    "    \n",
    "    Finds program P that best explains: z_receiver + action + P -> z_target, r_target\n",
    "    \"\"\"\n",
    "    # Ensure correct shapes\n",
    "    z_obs = z_obs.to(device).unsqueeze(0) if z_obs.dim() == 1 else z_obs.to(device)\n",
    "    z_receiver = z_receiver.to(device).unsqueeze(0) if z_receiver.dim() == 1 else z_receiver.to(device)\n",
    "    z_target = z_target.to(device).unsqueeze(0) if z_target.dim() == 1 else z_target.to(device)\n",
    "    a_t = a_t.to(device).unsqueeze(0) if a_t.dim() == 1 else a_t.to(device)\n",
    "    r_target = r_target.to(device).unsqueeze(0) if r_target.dim() == 0 else r_target.to(device)\n",
    "\n",
    "    sos_idx = proposer.sos_idx\n",
    "    zero_params = torch.zeros((MAX_PARAMS,), device=device, dtype=torch.float32)\n",
    "\n",
    "    # Beam entries: (Program, prev_prim_idx, prev_params, cumulative_score)\n",
    "    beam = [(Program(), sos_idx, zero_params, 0.0)]\n",
    "    \n",
    "    best_program = Program()\n",
    "    best_energy = float(\"inf\")\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    for depth in range(1, max_prog_len + 1):\n",
    "        all_candidates = []\n",
    "        \n",
    "        # Batch proposer forward pass across beam\n",
    "        Bbeam = len(beam)\n",
    "        prev_idx_batch = torch.tensor(\n",
    "            [entry[1] for entry in beam], dtype=torch.long, device=device\n",
    "        )\n",
    "        prev_params_batch = torch.stack([entry[2] for entry in beam], dim=0)\n",
    "        z_obs_batch = z_obs.repeat(Bbeam, 1)\n",
    "        \n",
    "        prim_logits_batch, param_pred_batch = proposer.forward_step(\n",
    "            z_obs_batch, prev_idx_batch, prev_params_batch\n",
    "        )\n",
    "        \n",
    "        # Expand top-k primitives for each beam entry\n",
    "        expansions = []\n",
    "        for parent_i, (prog_parent, prev_idx, prev_params, parent_score) in enumerate(beam):\n",
    "            probs = F.softmax(prim_logits_batch[parent_i], dim=-1)\n",
    "            top_vals, top_idx = torch.topk(probs, k=min(topk, probs.size(0)), dim=-1)\n",
    "            \n",
    "            # In beam search expansion:\n",
    "            for k_i in range(top_idx.size(0)):\n",
    "                prim_idx = int(top_idx[k_i].item())\n",
    "                arity = PRIMITIVE_TEMPLATES[prim_idx][1]\n",
    "                \n",
    "                if arity > 0:\n",
    "                    pred_params = param_pred_batch[parent_i][:arity].cpu().numpy()\n",
    "                    \n",
    "                    # Sample K different parameter instantiations\n",
    "                    for _ in range(3):  # Try 3 different parameter settings\n",
    "                        if np.random.rand() < 0.7:  # 70% use prediction\n",
    "                            inst_params = []\n",
    "                            for pval in pred_params:\n",
    "                                scaled = float(pval) * (grid_size - 1)\n",
    "                                inst_params.append(float(round(scaled)))\n",
    "                        else:  # 30% random\n",
    "                            inst_params = [float(np.random.randint(0, grid_size)) \n",
    "                                            for _ in range(arity)]\n",
    "                        \n",
    "                        new_prog = prog_parent.extend(prim_idx, inst_params)\n",
    "                        expansions.append((parent_i, new_prog, prim_idx, inst_params, parent_score))\n",
    "                else:\n",
    "                    new_prog = prog_parent.extend(prim_idx, [])\n",
    "                    expansions.append((parent_i, new_prog, prim_idx, [], parent_score))\n",
    "        \n",
    "        if len(expansions) == 0:\n",
    "            break\n",
    "        \n",
    "        # Batch-encode all expanded programs\n",
    "        cand_programs = [e[1] for e in expansions]\n",
    "        prim_ids_list, param_tensors_list, L_list = [], [], []\n",
    "        \n",
    "        for prog in cand_programs:\n",
    "            prim_ids, param_tensor = batchify_programs(\n",
    "                prog, max_params=MAX_PARAMS, device=device\n",
    "            )\n",
    "            prim_ids_list.append(prim_ids)\n",
    "            param_tensors_list.append(param_tensor)\n",
    "            L_list.append(prim_ids.shape[1])\n",
    "        \n",
    "        L_max = max(L_list) if L_list else 0\n",
    "        Nc = len(cand_programs)\n",
    "        \n",
    "        # Pad to max length\n",
    "        prim_ids_padded = torch.zeros((Nc, L_max), dtype=torch.long, device=device)\n",
    "        param_padded = torch.zeros((Nc, L_max, MAX_PARAMS), dtype=torch.float32, device=device)\n",
    "        \n",
    "        for i_p, (prim_ids, param_t) in enumerate(zip(prim_ids_list, param_tensors_list)):\n",
    "            Li = prim_ids.shape[1]\n",
    "            if Li > 0:\n",
    "                prim_ids_padded[i_p, :Li] = prim_ids.squeeze(0)\n",
    "                param_padded[i_p, :Li, :] = param_t.squeeze(0)\n",
    "        \n",
    "        # Get program embeddings\n",
    "        prog_emb_batch = encoder(prim_ids_padded, param_padded)  # (Nc, MSG_DIM)\n",
    "        \n",
    "        # Repeat receiver state and action\n",
    "        z_b = z_receiver.repeat(Nc, 1)\n",
    "        a_b = a_t.repeat(Nc, 1)\n",
    "        z_target_b = z_target.repeat(Nc, 1)\n",
    "        r_target_b = r_target.repeat(Nc)\n",
    "        \n",
    "        # Evaluate world model\n",
    "        z_pred_b = world_model(z_b, a_b, prog_emb_batch)\n",
    "        reward_dist = reward_model(z_b, a_b)\n",
    "        \n",
    "        # Compute energies\n",
    "        energies = score_fn(\n",
    "            z_pred_b, z_target_b, reward_dist, r_target_b\n",
    "        )\n",
    "        \n",
    "        # Create candidate beam entries\n",
    "        for idx_e, entry in enumerate(expansions):\n",
    "            parent_i, new_prog, prim_idx, inst_params, parent_score = entry\n",
    "            energy = float(energies[idx_e].item())\n",
    "            new_score = parent_score - energy  # Higher is better\n",
    "            \n",
    "            # Prepare prev_params for next step (normalized to [0,1])\n",
    "            prev_params_next = [p / (grid_size - 1) for p in inst_params][:MAX_PARAMS]\n",
    "            if len(prev_params_next) < MAX_PARAMS:\n",
    "                prev_params_next += [0.0] * (MAX_PARAMS - len(prev_params_next))\n",
    "            prev_params_tensor = torch.tensor(\n",
    "                prev_params_next, dtype=torch.float32, device=device\n",
    "            )\n",
    "            \n",
    "            all_candidates.append((new_prog, prim_idx, prev_params_tensor, new_score))\n",
    "        \n",
    "        # Prune to beam width\n",
    "        if len(all_candidates) == 0:\n",
    "            break\n",
    "        \n",
    "        all_candidates.sort(key=lambda x: x[3], reverse=True)\n",
    "        beam = all_candidates[:beam_width]\n",
    "        \n",
    "        # Track best program\n",
    "        for prog_cand, pidx, pparams, sc in beam:\n",
    "            energy_here = -sc\n",
    "            if energy_here < best_energy:\n",
    "                best_energy = energy_here\n",
    "                best_program = prog_cand\n",
    "\n",
    "    return best_program, best_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69feff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
