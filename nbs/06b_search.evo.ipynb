{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fb656fc",
   "metadata": {},
   "source": [
    "# Beam Search Module\n",
    "\n",
    "> This module handles all aspects of the VAE, including encoding, decoding, and latent space representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbb56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp search.evo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd36cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore import *\n",
    "from fastcore.utils import *\n",
    "from torchvision.utils import save_image\n",
    "import torch\n",
    "import os\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dc1274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CellEmpty': 0, 'CellObstacle': 1, 'CellItem': 2, 'CellGoal': 3, 'CellAgent': 4, 'GoalAt': 5, 'ItemAt': 6, 'Near': 7, 'SeeGoal': 8, 'CanMove': 9, 'OtherAgentAt': 10, 'OtherAgentNear': 11, 'OtherAgentDirection': 12}\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from MAWM.core import Program, PRIMITIVE_TEMPLATES\n",
    "from MAWM.models.program_embedder import ProgramEmbedder\n",
    "from MAWM.models.program_encoder import ProgramEncoder\n",
    "from MAWM.models.program_synthizer import Proposer\n",
    "\n",
    "device = 'cpu'\n",
    "grid_size= 7\n",
    "\n",
    "num_primitives = len(PRIMITIVE_TEMPLATES)\n",
    "p_embed = ProgramEmbedder(\n",
    "    num_primitives= num_primitives,\n",
    "    param_cardinalities= [7, 7],\n",
    "    max_params_per_primitive= 2,\n",
    "    d_name= 32,\n",
    "    d_param= 32,\n",
    ").to(device)\n",
    "\n",
    "p_encoder = ProgramEncoder(num_primitives, [grid_size, grid_size],2, seq_len=5)\n",
    "proposer = Proposer(obs_dim= 32,\n",
    "                    num_prims= num_primitives,\n",
    "                    max_params= 2,\n",
    "                    seq_len= 5,\n",
    "                    prog_emb_dim_x= 32,\n",
    "                    prog_emb_dim_y= 32,\n",
    "                    prog_emb_dim_prims= 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4300073",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 5\n",
    "PAD_PRIM = len(PRIMITIVE_TEMPLATES)  # index for padding primitive\n",
    "PAD_PARAM = -1  # value for padding parameters\n",
    "MAX_PARAMS = 2  # maximum number of parameters per primitive\n",
    "\n",
    "def program_to_indices(program):\n",
    "    tokens = program.tokens[:SEQ_LEN]\n",
    "\n",
    "    prims = [t[0] for t in tokens]\n",
    "    params = [list(t[1])[:MAX_PARAMS] for t in tokens]\n",
    "\n",
    "    # pad params\n",
    "    for p in params:\n",
    "        while len(p) < MAX_PARAMS:\n",
    "            p.append(PAD_PARAM)\n",
    "\n",
    "    # pad program length\n",
    "    pad_len = SEQ_LEN - len(tokens)\n",
    "    prims += [PAD_PRIM] * pad_len\n",
    "    params += [[PAD_PARAM]*MAX_PARAMS for _ in range(pad_len)]\n",
    "\n",
    "    return (\n",
    "        torch.tensor(prims).unsqueeze(0),\n",
    "        torch.tensor(params).unsqueeze(0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b471fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify_programs(programs, seq_len=SEQ_LEN, max_params=MAX_PARAMS):\n",
    "    prim_list = []\n",
    "    param_list = []\n",
    "\n",
    "    for p in programs:\n",
    "        prim_ids, param_ids = program_to_indices(p)\n",
    "        prim_list.append(prim_ids[0])       # (SEQ_LEN)\n",
    "        param_list.append(param_ids[0])     # (SEQ_LEN, max_params)\n",
    "\n",
    "    prim_batch = torch.stack(prim_list, dim=0)      # (B, SEQ_LEN)\n",
    "    param_batch = torch.stack(param_list, dim=0)    # (B, SEQ_LEN, max_params)\n",
    "\n",
    "    return prim_batch, param_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd39ebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Callable, Optional\n",
    "from MAWM.core import Program, PRIMITIVE_TEMPLATES\n",
    "# required helper: batchify_programs should exist in your codebase\n",
    "\n",
    "@torch.no_grad()\n",
    "def evolutionary_program_search(\n",
    "    z: torch.Tensor,\n",
    "    program_embedder: nn.Module,\n",
    "    proposer: Optional[nn.Module],\n",
    "    program_encoder: nn.Module,\n",
    "    score_fn: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n",
    "    # evolution hyperparams\n",
    "    pop_size: int = 128,\n",
    "    num_generations: int = 40,\n",
    "    max_params: int = 3,\n",
    "    max_prog_len: int = 5,\n",
    "    grid_size: int = 7,\n",
    "    elite_fraction: float = 0.05,\n",
    "    tournament_k: int = 3,\n",
    "    mutation_rate: float = 0.35,\n",
    "    insertion_prob: float = 0.12,\n",
    "    deletion_prob: float = 0.12,\n",
    "    crossover_rate: float = 0.2,\n",
    "    use_proposer_guidance: bool = False,\n",
    "    proposer_lambda: float = 0.5,   # weight for proposer log-prob in fitness (only primitives)\n",
    "    length_penalty: float = 0.25,   # lambda_3 in your earlier code\n",
    "    device: str = \"cuda\",\n",
    "    seed: Optional[int] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Evolutionary search for programs.\n",
    "    Returns: (best_program: Program, best_fitness: float)\n",
    "\n",
    "    - z: single observation latent (D,) or (1, D)\n",
    "    - program_embedder: used to produce embeddings for proposer guidance if needed (not required here)\n",
    "    - proposer: optional proposer module. If use_proposer_guidance == True, proposer must be not None.\n",
    "    - program_encoder & score_fn: used to compute task score for candidates (batched)\n",
    "    \"\"\"\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    # ensure z shape (1, D)\n",
    "    z = z.to(device)\n",
    "    if z.dim() == 1:\n",
    "        z = z.unsqueeze(0)\n",
    "\n",
    "    num_prims = len(PRIMITIVE_TEMPLATES)\n",
    "    lambda_prop = proposer_lambda\n",
    "    lambda_score = 1.0  # we directly use score_fn output; scale with proposer_lambda if needed\n",
    "    lambda_len = length_penalty\n",
    "\n",
    "    POP_SIZE = pop_size\n",
    "    ELITE_COUNT = max(1, int(np.ceil(POP_SIZE * elite_fraction)))\n",
    "\n",
    "    # ---------------- utilities ----------------\n",
    "    def random_program() -> Program:\n",
    "        L = np.random.randint(1, max_prog_len + 1)\n",
    "        tokens = []\n",
    "        for _ in range(L):\n",
    "            prim = int(np.random.randint(0, num_prims))\n",
    "            arity = PRIMITIVE_TEMPLATES[prim][1]\n",
    "            params = [int(np.random.randint(0, grid_size)) for __ in range(arity)]\n",
    "            tokens.append((prim, params))\n",
    "        return Program(tokens=tokens)\n",
    "\n",
    "    def copy_program(p: Program) -> Program:\n",
    "        return Program(tokens=[(int(t[0]), [int(x) for x in t[1]]) for t in p.tokens])\n",
    "\n",
    "    def mutate_program(program: Program) -> Program:\n",
    "        p = copy_program(program)\n",
    "        if len(p.tokens) == 0:\n",
    "            return random_program()\n",
    "\n",
    "        # pick a position to mutate\n",
    "        i = int(np.random.randint(0, len(p.tokens)))\n",
    "        prim, params = p.tokens[i]\n",
    "\n",
    "        # mutate primitive with some prob\n",
    "        if np.random.rand() < 0.4:\n",
    "            new_prim = int(np.random.randint(0, num_prims))\n",
    "            prim = new_prim\n",
    "            # regenerate params for new arity\n",
    "            arity = PRIMITIVE_TEMPLATES[prim][1]\n",
    "            params = [int(np.random.randint(0, grid_size)) for _ in range(arity)]\n",
    "        else:\n",
    "            # mutate parameters individually\n",
    "            arity = PRIMITIVE_TEMPLATES[prim][1]\n",
    "            new_params = []\n",
    "            for k in range(arity):\n",
    "                if np.random.rand() < 0.35:\n",
    "                    new_params.append(int(np.random.randint(0, grid_size)))\n",
    "                else:\n",
    "                    # keep existing if present, else random\n",
    "                    new_params.append(int(params[k]) if k < len(params) else int(np.random.randint(0, grid_size)))\n",
    "            params = new_params\n",
    "\n",
    "        p.tokens[i] = (prim, params)\n",
    "\n",
    "        # insertion\n",
    "        if np.random.rand() < insertion_prob and len(p.tokens) < max_prog_len:\n",
    "            new_prim = int(np.random.randint(0, num_prims))\n",
    "            new_arity = PRIMITIVE_TEMPLATES[new_prim][1]\n",
    "            new_params = [int(np.random.randint(0, grid_size)) for _ in range(new_arity)]\n",
    "            insert_pos = int(np.random.randint(0, len(p.tokens)+1))\n",
    "            p.tokens.insert(insert_pos, (new_prim, new_params))\n",
    "\n",
    "        # deletion\n",
    "        if np.random.rand() < deletion_prob and len(p.tokens) > 1:\n",
    "            del_pos = int(np.random.randint(0, len(p.tokens)))\n",
    "            p.tokens.pop(del_pos)\n",
    "\n",
    "        return p\n",
    "\n",
    "    def crossover_programs(a: Program, b: Program) -> Program:\n",
    "        pa = copy_program(a)\n",
    "        pb = copy_program(b)\n",
    "        if len(pa.tokens) == 0 or len(pb.tokens) == 0:\n",
    "            return random_program()\n",
    "        # one-point crossover: choose split points (allow 0 to len)\n",
    "        i = int(np.random.randint(0, len(pa.tokens) + 1))\n",
    "        j = int(np.random.randint(0, len(pb.tokens) + 1))\n",
    "        new_tokens = pa.tokens[:i] + pb.tokens[j:]\n",
    "        # clip to max length\n",
    "        new_tokens = new_tokens[:max_prog_len] if len(new_tokens) > max_prog_len else new_tokens\n",
    "        if len(new_tokens) == 0:\n",
    "            return random_program()\n",
    "        return Program(tokens=[(int(t[0]), [int(x) for x in t[1]]) for t in new_tokens])\n",
    "\n",
    "    # proposer's primitive log-prob (autoregressive; only primitives)\n",
    "    def proposer_prim_logprob(program: Program) -> float:\n",
    "        \"\"\"\n",
    "        Compute sum of log-probabilities of primitives under the proposer, evaluated autoregressively.\n",
    "        NOTE: This function only accounts for primitive logits, not parameter probabilities.\n",
    "        It's somewhat expensive if done for many programs individually; we will vectorize when used.\n",
    "        \"\"\"\n",
    "        if proposer is None:\n",
    "            return 0.0\n",
    "\n",
    "        # We'll compute sequentially: for t in [0..len-1], form prefix embedding, call proposer.forward_step(z, p_vec)\n",
    "        # Use program_embedder to build p_vec for each prefix.\n",
    "        # To avoid complexity here, we will generate prim_ids for prefixes and reuse program_embedder.\n",
    "        prim_ids = []\n",
    "        params_ids = []\n",
    "        prefixes = []\n",
    "        for t in range(len(program.tokens)):\n",
    "            prefix = [ (program.tokens[i][0], program.tokens[i][1]) for i in range(t) ]  # prefix before token t\n",
    "            prefixes.append(prefix)\n",
    "\n",
    "        # build Programs for prefixes, then batchify\n",
    "        prefix_programs = []\n",
    "        for pref in prefixes:\n",
    "            if len(pref) == 0:\n",
    "                prefix_programs.append(Program(tokens=[(-1, [-1]*max_params)]))\n",
    "            else:\n",
    "                prefix_programs.append(Program(tokens=pref))\n",
    "\n",
    "        # we rely on batchify_programs to produce prim_ids and param ids\n",
    "        prim_ids_padded, params_padded = batchify_programs(prefix_programs, seq_len=max_prog_len, max_params=max_params)\n",
    "        prim_ids_padded = prim_ids_padded.to(torch.long).to(device)\n",
    "        params_padded = params_padded.to(torch.long).to(device)\n",
    "\n",
    "        # program_embedder -> p_vec\n",
    "        p_vec = program_embedder(prim_ids_padded, params_padded)  # shape (P, L, prog_embed_dim)\n",
    "        # Repeat z for batch\n",
    "        z_batch = z.repeat(p_vec.shape[0], 1)\n",
    "\n",
    "        prim_logits_batch, _ = proposer.forward_step(z_batch, p_vec)\n",
    "        # for each prefix i, the primitive we want is program.tokens[i][0]\n",
    "        logp_sum = 0.0\n",
    "        for i, token in enumerate(program.tokens):\n",
    "            prim_idx = int(token[0])\n",
    "            logits = prim_logits_batch[i]  # shape num_prims+1\n",
    "            logprob = torch.log_softmax(logits, dim=-1)[prim_idx].item()\n",
    "            logp_sum += float(logprob)\n",
    "        return logp_sum\n",
    "\n",
    "    # Vectorized proposer primitive logprobs (for a list of programs)\n",
    "    def proposer_prim_logprob_batch(programs: List[Program]) -> np.ndarray:\n",
    "        if proposer is None:\n",
    "            return np.zeros(len(programs), dtype=float)\n",
    "\n",
    "        # For each program, produce prefixes -> collect all prefixes of all programs\n",
    "        prefixes_all = []\n",
    "        indices = []  # for mapping\n",
    "        for pi, prog in enumerate(programs):\n",
    "            for t in range(len(prog.tokens)):\n",
    "                prefix = prog.tokens[:t]  # prefix tokens\n",
    "                if len(prefix) == 0:\n",
    "                    prefixes_all.append(Program(tokens=[(-1, [-1]*max_params)]))\n",
    "                else:\n",
    "                    prefixes_all.append(Program(tokens=[(int(x[0]), [int(y) for y in x[1]]) for x in prefix]))\n",
    "                indices.append(pi)\n",
    "\n",
    "        if len(prefixes_all) == 0:\n",
    "            return np.zeros(len(programs), dtype=float)\n",
    "\n",
    "        prim_ids_padded, params_padded = batchify_programs(prefixes_all, seq_len=max_prog_len, max_params=max_params)\n",
    "        prim_ids_padded = prim_ids_padded.to(torch.long).to(device)\n",
    "        params_padded = params_padded.to(torch.long).to(device)\n",
    "\n",
    "        p_vec = program_embedder(prim_ids_padded, params_padded)  # (Pfx, L, dim)\n",
    "        z_rep = z.repeat(p_vec.shape[0], 1)\n",
    "        prim_logits_batch, _ = proposer.forward_step(z_rep, p_vec)\n",
    "\n",
    "        # compute log softmax\n",
    "        prim_logprobs = torch.log_softmax(prim_logits_batch, dim=-1).cpu().numpy()  # shape (Pfx, num_prims+1)\n",
    "        # for each prefix entry k, we need the probability of the next primitive in the corresponding program\n",
    "        sums = np.zeros(len(programs), dtype=float)\n",
    "        ptr = 0\n",
    "        for k, prog in enumerate(programs):\n",
    "            # sum log-probs for each token in prog\n",
    "            for t in range(len(prog.tokens)):\n",
    "                # prefix index in flattened prefixes_all is ptr\n",
    "                prim_idx = int(prog.tokens[t][0])\n",
    "                sums[k] += float(prim_logprobs[ptr, prim_idx])\n",
    "                ptr += 1\n",
    "        return sums\n",
    "\n",
    "    # ---------------- initialize population ----------------\n",
    "    population: List[Program] = [random_program() for _ in range(POP_SIZE)]\n",
    "\n",
    "    # ---------------- fitness evaluation ----------------\n",
    "    def evaluate_population(programs: List[Program]) -> np.ndarray:\n",
    "        \"\"\"Return fitness array of shape (len(programs),). Higher = better.\"\"\"\n",
    "        if len(programs) == 0:\n",
    "            return np.array([])\n",
    "\n",
    "        # 1) task score via program_encoder + score_fn (vectorized)\n",
    "        prim_ids_padded, params_padded = batchify_programs(programs, seq_len=max_prog_len, max_params=max_params)\n",
    "        prim_ids_padded = prim_ids_padded.to(torch.long).to(device)\n",
    "        params_padded = params_padded.to(torch.long).to(device)\n",
    "        prog_emb = program_encoder(prim_ids_padded, params_padded)  # shape (P, emb_dim)\n",
    "        scores_tensor = score_fn(z, prog_emb)  # expected shape (1, P) or (P,)\n",
    "        # convert to numpy 1d\n",
    "        scores = scores_tensor.detach().cpu().squeeze()\n",
    "        if scores.ndim == 0:\n",
    "            scores = scores.unsqueeze(0)\n",
    "        scores = scores.cpu().numpy()\n",
    "        # ensure length match\n",
    "        if scores.shape[0] != len(programs):\n",
    "            # if score_fn returned shape (P,) but squeezed weirdly\n",
    "            scores = np.array([float(scores[i]) for i in range(len(programs))])\n",
    "\n",
    "        # 2) length penalty\n",
    "        lengths = np.array([len(p.tokens) for p in programs], dtype=float)\n",
    "        len_pen = - lambda_len * lengths\n",
    "\n",
    "        # 3) optional proposer primitive logprobs\n",
    "        if use_proposer_guidance and proposer is not None:\n",
    "            prop_logp_arr = proposer_prim_logprob_batch(programs)  # shape (P,)\n",
    "            fitness = lambda_score * scores + lambda_prop * prop_logp_arr + len_pen\n",
    "        else:\n",
    "            fitness = lambda_score * scores + len_pen\n",
    "\n",
    "        return fitness\n",
    "\n",
    "    # ---------------- evolutionary loop ----------------\n",
    "    for gen in range(num_generations):\n",
    "        # evaluate\n",
    "        fitness = evaluate_population(population)\n",
    "        # keep elites\n",
    "        elite_idx = np.argsort(fitness)[::-1][:ELITE_COUNT]\n",
    "        elites = [copy_program(population[i]) for i in elite_idx]\n",
    "\n",
    "        # prepare selection probabilities (tournament selection implemented below)\n",
    "        new_population: List[Program] = elites.copy()\n",
    "\n",
    "        # create offspring until population full\n",
    "        while len(new_population) < POP_SIZE:\n",
    "            # tournament selection\n",
    "            contenders = np.random.choice(POP_SIZE, size=tournament_k, replace=False)\n",
    "            winner_idx = int(contenders[np.argmax(fitness[contenders])])\n",
    "            parent = population[winner_idx]\n",
    "\n",
    "            # second parent for crossover (another tournament)\n",
    "            if np.random.rand() < crossover_rate:\n",
    "                contenders2 = np.random.choice(POP_SIZE, size=tournament_k, replace=False)\n",
    "                winner2 = int(contenders2[np.argmax(fitness[contenders2])])\n",
    "                parent2 = population[winner2]\n",
    "                child = crossover_programs(parent, parent2)\n",
    "            else:\n",
    "                child = copy_program(parent)\n",
    "\n",
    "            # mutation\n",
    "            if np.random.rand() < mutation_rate:\n",
    "                child = mutate_program(child)\n",
    "\n",
    "            new_population.append(child)\n",
    "\n",
    "        population = new_population\n",
    "\n",
    "        # (optional) quick tightening: keep population unique by hashing tokens (not strictly necessary)\n",
    "        # We do not remove duplicates to maintain diversity.\n",
    "\n",
    "    # final evaluation and best pick\n",
    "    final_fitness = evaluate_population(population)\n",
    "    best_idx = int(np.argmax(final_fitness))\n",
    "    return population[best_idx], float(final_fitness[best_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe8c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from MAWM.models.program_encoder import ProgramPredictor, ProgramEncoder\n",
    "\n",
    "import torch\n",
    "def loss_fn(z_hat, z, loss_exp= 1):\n",
    "    return torch.mean(torch.abs(z_hat - z) ** loss_exp) / loss_exp\n",
    "\n",
    "def score_fn(z, m, predictor= None):\n",
    "    predictor = ProgramPredictor()\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "    scores = []\n",
    "    with torch.no_grad():\n",
    "        z_hat = predictor(m)\n",
    "    \n",
    "    return torch.tensor([-loss_fn(z_hat[i].unsqueeze(0), z) for i in range(z_hat.size(0))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9794b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_prog, best_score = evolutionary_program_search(\n",
    "#     z=torch.randn(32),  # torch tensor (D,)\n",
    "#     program_embedder=p_embed,\n",
    "#     proposer=proposer,               # or None\n",
    "#     program_encoder=p_encoder,\n",
    "#     score_fn=score_fn,\n",
    "#     pop_size=128,\n",
    "#     num_generations=50,\n",
    "#     max_prog_len=5,\n",
    "#     grid_size=7,\n",
    "#     use_proposer_guidance=True,      # optional\n",
    "#     proposer_lambda=0.5,\n",
    "#     length_penalty=0.25,\n",
    "#     device=\"cpu\",\n",
    "#     seed=42,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e8f214",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m z = torch.randn(\u001b[32m32\u001b[39m).to(device)\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10000\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     res = \u001b[43mevolutionary_program_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m=\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# torch tensor (D,)\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mprogram_embedder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mp_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mproposer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproposer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# or None\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mprogram_encoder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mp_encoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mscore_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscore_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mpop_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mnum_generations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mmax_prog_len\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mgrid_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43muse_proposer_guidance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# optional\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mproposer_lambda\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mlength_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m     lst_res.append(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 266\u001b[39m, in \u001b[36mevolutionary_program_search\u001b[39m\u001b[34m(z, program_embedder, proposer, program_encoder, score_fn, pop_size, num_generations, max_params, max_prog_len, grid_size, elite_fraction, tournament_k, mutation_rate, insertion_prob, deletion_prob, crossover_rate, use_proposer_guidance, proposer_lambda, length_penalty, device, seed)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;66;03m# ---------------- evolutionary loop ----------------\u001b[39;00m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m gen \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_generations):\n\u001b[32m    265\u001b[39m     \u001b[38;5;66;03m# evaluate\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     fitness = \u001b[43mevaluate_population\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m     \u001b[38;5;66;03m# keep elites\u001b[39;00m\n\u001b[32m    268\u001b[39m     elite_idx = np.argsort(fitness)[::-\u001b[32m1\u001b[39m][:ELITE_COUNT]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 256\u001b[39m, in \u001b[36mevolutionary_program_search.<locals>.evaluate_population\u001b[39m\u001b[34m(programs)\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;66;03m# 3) optional proposer primitive logprobs\u001b[39;00m\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_proposer_guidance \u001b[38;5;129;01mand\u001b[39;00m proposer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     prop_logp_arr = \u001b[43mproposer_prim_logprob_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprograms\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shape (P,)\u001b[39;00m\n\u001b[32m    257\u001b[39m     fitness = lambda_score * scores + lambda_prop * prop_logp_arr + len_pen\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 203\u001b[39m, in \u001b[36mevolutionary_program_search.<locals>.proposer_prim_logprob_batch\u001b[39m\u001b[34m(programs)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(prefixes_all) == \u001b[32m0\u001b[39m:\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.zeros(\u001b[38;5;28mlen\u001b[39m(programs), dtype=\u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m prim_ids_padded, params_padded = \u001b[43mbatchify_programs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefixes_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_prog_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m prim_ids_padded = prim_ids_padded.to(torch.long).to(device)\n\u001b[32m    205\u001b[39m params_padded = params_padded.to(torch.long).to(device)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mbatchify_programs\u001b[39m\u001b[34m(programs, seq_len, max_params)\u001b[39m\n\u001b[32m      3\u001b[39m param_list = []\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m programs:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     prim_ids, param_ids = \u001b[43mprogram_to_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     prim_list.append(prim_ids[\u001b[32m0\u001b[39m])       \u001b[38;5;66;03m# (SEQ_LEN)\u001b[39;00m\n\u001b[32m      8\u001b[39m     param_list.append(param_ids[\u001b[32m0\u001b[39m])     \u001b[38;5;66;03m# (SEQ_LEN, max_params)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mprogram_to_indices\u001b[39m\u001b[34m(program)\u001b[39m\n\u001b[32m     19\u001b[39m prims += [PAD_PRIM] * pad_len\n\u001b[32m     20\u001b[39m params += [[PAD_PARAM]*MAX_PARAMS \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(pad_len)]\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprims\u001b[49m\u001b[43m)\u001b[49m.unsqueeze(\u001b[32m0\u001b[39m),\n\u001b[32m     24\u001b[39m     torch.tensor(params).unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m     25\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# lst_res = []\n",
    "# z = torch.randn(32).to(device)\n",
    "# for i in range(10000):\n",
    "#     res = evolutionary_program_search(z=z,  # torch tensor (D,)\n",
    "#                                     program_embedder=p_embed,\n",
    "#                                     proposer=proposer,               # or None\n",
    "#                                     program_encoder=p_encoder,\n",
    "#                                     score_fn=score_fn,\n",
    "#                                     pop_size=128,\n",
    "#                                     num_generations=50,\n",
    "#                                     max_prog_len=5,\n",
    "#                                     grid_size=7,\n",
    "#                                     use_proposer_guidance=True,      # optional\n",
    "#                                     proposer_lambda=0.5,\n",
    "#                                     length_penalty=0.25,\n",
    "#                                     device=\"cpu\",\n",
    "#                                     seed=42,\n",
    "#                                     )\n",
    "#     lst_res.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8c8b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"best:\", best_prog, best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee1d6da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69feff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
