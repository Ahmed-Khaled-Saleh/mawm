{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fb656fc",
   "metadata": {},
   "source": [
    "# Beam Search Module\n",
    "\n",
    "> This module handles all aspects of the VAE, including encoding, decoding, and latent space representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbb56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp search.beam_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd36cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore import *\n",
    "from fastcore.utils import *\n",
    "from torchvision.utils import save_image\n",
    "import torch\n",
    "import os\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af03e05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from mawm.core import Program, PRIMITIVE_TEMPLATES\n",
    "from mawm.models.program_embedder import ProgramEmbedder\n",
    "from mawm.models.program_encoder import ProgramEncoder\n",
    "from mawm.models.program_synthizer import Proposer\n",
    "\n",
    "device = 'cpu'\n",
    "grid_size= 7\n",
    "\n",
    "num_primitives = len(PRIMITIVE_TEMPLATES)\n",
    "p_embed = ProgramEmbedder(\n",
    "    num_primitives= num_primitives,\n",
    "    param_cardinalities= [7, 7],\n",
    "    max_params_per_primitive= 2,\n",
    "    d_name= 32,\n",
    "    d_param= 32,\n",
    ").to(device)\n",
    "\n",
    "p_encoder = ProgramEncoder(num_primitives, [grid_size, grid_size],2, seq_len=5)\n",
    "proposer = Proposer(obs_dim= 32,\n",
    "                    num_prims= num_primitives,\n",
    "                    max_params= 2,\n",
    "                    seq_len= 5,\n",
    "                    prog_emb_dim_x= 32,\n",
    "                    prog_emb_dim_y= 32,\n",
    "                    prog_emb_dim_prims= 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619adb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 5\n",
    "PAD_PRIM = len(PRIMITIVE_TEMPLATES)  # index for padding primitive\n",
    "PAD_PARAM = -1  # value for padding parameters\n",
    "MAX_PARAMS = 2  # maximum number of parameters per primitive\n",
    "\n",
    "def program_to_indices(program):\n",
    "    tokens = program.tokens[:SEQ_LEN]\n",
    "\n",
    "    prims = [t[0] for t in tokens]\n",
    "    params = [list(t[1])[:MAX_PARAMS] for t in tokens]\n",
    "\n",
    "    # pad params\n",
    "    for p in params:\n",
    "        while len(p) < MAX_PARAMS:\n",
    "            p.append(PAD_PARAM)\n",
    "\n",
    "    # pad program length\n",
    "    pad_len = SEQ_LEN - len(tokens)\n",
    "    prims += [PAD_PRIM] * pad_len\n",
    "    params += [[PAD_PARAM]*MAX_PARAMS for _ in range(pad_len)]\n",
    "\n",
    "    return (\n",
    "        torch.tensor(prims).unsqueeze(0),\n",
    "        torch.tensor(params).unsqueeze(0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a03d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify_programs(programs, seq_len=SEQ_LEN, max_params=MAX_PARAMS):\n",
    "    prim_list = []\n",
    "    param_list = []\n",
    "\n",
    "    for p in programs:\n",
    "        prim_ids, param_ids = program_to_indices(p)\n",
    "        prim_list.append(prim_ids[0])       # (SEQ_LEN)\n",
    "        param_list.append(param_ids[0])     # (SEQ_LEN, max_params)\n",
    "\n",
    "    prim_batch = torch.stack(prim_list, dim=0)      # (B, SEQ_LEN)\n",
    "    param_batch = torch.stack(param_list, dim=0)    # (B, SEQ_LEN, max_params)\n",
    "\n",
    "    return prim_batch, param_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea42b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_idx = proposer.sos_idx\n",
    "EOS_IDX = len(PRIMITIVE_TEMPLATES)\n",
    "zero_params = torch.full((MAX_PARAMS,), -1, device=device)\n",
    "\n",
    "init_prog = Program(tokens=[(sos_idx, zero_params.tolist())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34d2394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5]), torch.Size([2, 5, 2]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = batchify_programs([init_prog, init_prog])\n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dab0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fa280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from mawm.core import Program, PRIMITIVE_TEMPLATES\n",
    "# from mawm.models.program_embedder import batchify_programs\n",
    "from mawm.models.program_encoder import ProgramEncoder\n",
    "from mawm.models.program_synthizer import Proposer\n",
    "\n",
    "@torch.no_grad()\n",
    "def neural_guided_beam_search(\n",
    "    z,\n",
    "    program_embedder: nn.Module,\n",
    "    proposer: nn.Module,\n",
    "    program_encoder: nn.Module,\n",
    "    score_fn,\n",
    "    MAX_PARAMS=3,\n",
    "    beam_width=5,\n",
    "    topk=6,\n",
    "    max_prog_len=5,\n",
    "    grid_size=7,\n",
    "    lambdas= (0.25, 0.5, 0.25),\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    \"\"\"\n",
    "    neural-guided beam search.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- normalize z shape ---\n",
    "    z = z.to(device)\n",
    "    if z.dim() == 1:\n",
    "        z = z.unsqueeze(0)\n",
    "    lambda_1, lambda_2, lambda_3 = lambdas\n",
    "\n",
    "    sos_idx = proposer.sos_idx\n",
    "    EOS_IDX = len(PRIMITIVE_TEMPLATES)\n",
    "    zero_params = torch.full((MAX_PARAMS,), -1, device=device)\n",
    "\n",
    "    # initial program: [SOS]\n",
    "    init_prog = Program(tokens=[(sos_idx, zero_params.tolist())])\n",
    "    beam = [(init_prog, 0.0)]  # (program, score)\n",
    "\n",
    "    best_program = init_prog\n",
    "    best_score = -float(\"inf\")\n",
    "\n",
    "    # ---- start beam search ----\n",
    "    for depth in range(1, max_prog_len + 1):\n",
    "        alive = []\n",
    "        finished = []\n",
    "\n",
    "        for prog, score in beam:\n",
    "            last_prim = prog.tokens[-1][0]\n",
    "            if last_prim == EOS_IDX:\n",
    "                finished.append((prog, score))\n",
    "            else:\n",
    "                alive.append((prog, score))\n",
    "\n",
    "        if len(alive) == 0:\n",
    "            break\n",
    "        # ---- 1) build batch of prefixes ----\n",
    "        prefix_programs = [p for (p, _) in alive]\n",
    "        prev_idx_batch, prev_params_batch = batchify_programs(prefix_programs, seq_len=max_prog_len, max_params=MAX_PARAMS)\n",
    "        prev_idx_batch = prev_idx_batch.to(torch.long)\n",
    "        prev_params_batch = prev_params_batch.to(torch.long)\n",
    "        B = prev_idx_batch.shape[0]\n",
    "\n",
    "        p_vec = program_embedder(prev_idx_batch.to(device),\n",
    "                                 prev_params_batch.to(device))\n",
    "\n",
    "        # replicate z\n",
    "        z_batch = z.repeat(B, 1)\n",
    "\n",
    "        # # proposer forward\n",
    "        prim_logits_batch, param_pred_batch = proposer.forward_step(z_batch, p_vec)\n",
    "\n",
    "        # ---- 2) expand each beam entry ----\n",
    "        expansions = []\n",
    "        for b_i, (prog_parent, parent_score) in enumerate(alive):\n",
    "            prim_logprobs = F.log_softmax(prim_logits_batch[b_i], dim=-1)\n",
    "            top_vals, top_idx = torch.topk(prim_logprobs, k=topk)\n",
    "\n",
    "            for k_i in range(topk):\n",
    "                prim_idx = int(top_idx[k_i].item())\n",
    "                prim_logp = float(top_vals[k_i].item())\n",
    "                if prim_idx == EOS_IDX:\n",
    "                    # add program as completed (no more expansions)\n",
    "                    new_prog = prog_parent.extend(prim_idx, [])\n",
    "                    expansions.append((new_prog, parent_score + prim_logp))\n",
    "                    # print(f\"Beam search found EOS at depth {depth} with program: {new_prog}\")\n",
    "                    continue\n",
    "\n",
    "                arity = PRIMITIVE_TEMPLATES[prim_idx][1]              \n",
    "\n",
    "                # ----- parameter instantiation -----\n",
    "                instantiations = []\n",
    "                if arity > 0:\n",
    "                    pred_params = param_pred_batch[b_i][:arity].cpu().numpy()\n",
    "                    for _ in range(3):\n",
    "                        if np.random.rand() < 0.7:\n",
    "                            inst = [\n",
    "                                float(round(float(p) * (grid_size - 1)))\n",
    "                                for p in pred_params\n",
    "                            ]\n",
    "                        else:\n",
    "                            inst = [\n",
    "                                float(np.random.randint(0, grid_size))\n",
    "                                for _ in range(arity)\n",
    "                            ]\n",
    "                        instantiations.append(inst)\n",
    "                else:\n",
    "                    instantiations.append([])\n",
    "\n",
    "                # ----- create new beam children -----\n",
    "                for inst_params in instantiations:\n",
    "                    new_prog = prog_parent.extend(prim_idx, inst_params)\n",
    "                    expansions.append((new_prog, parent_score + prim_logp))\n",
    "\n",
    "        if not expansions:\n",
    "            break\n",
    "\n",
    "        # ---- 3) Score all expanded programs ----\n",
    "        cand_programs = [p for (p, _) in expansions]\n",
    "        prim_ids_padded, params_padded = batchify_programs(cand_programs, seq_len=max_prog_len, max_params=MAX_PARAMS)\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "        params_padded = params_padded.to(torch.long)\n",
    "        prim_ids_padded = prim_ids_padded.to(torch.long)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # program_encoder = get_pencoder(prim_ids_padded.shape[-1])\n",
    "            prog_emb_batch = program_encoder(prim_ids_padded, params_padded)\n",
    "\n",
    "        scores = score_fn(z, prog_emb_batch)\n",
    "\n",
    "        # ---- 4) attach scores and prune ----\n",
    "        candidates = []\n",
    "        for idx_c, (prog, base_score) in enumerate(expansions):\n",
    "            total = lambda_1 * base_score + lambda_2 * float(scores[idx_c].item()) - lambda_3 * len(prog.tokens) \n",
    "            candidates.append((prog, total))\n",
    "\n",
    "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        # best_program, best_score = max(candidates, key=lambda x: x[1])\n",
    "\n",
    "        topk_from_alive = candidates#[:beam_width]\n",
    "        beam = topk_from_alive + finished\n",
    "\n",
    "        filtered_beam = []\n",
    "        for p in beam:\n",
    "            if len(p[0].tokens) == 1 and p[0].tokens[0][0] == -1:\n",
    "                continue\n",
    "            filtered_beam.append(p)\n",
    "        if len(filtered_beam) == 0:\n",
    "            break\n",
    "\n",
    "        best_program, best_score = max(filtered_beam, key=lambda x: x[1])\n",
    "        beam = sorted(beam, key=lambda x: x[1], reverse=True)[:beam_width]\n",
    "\n",
    "        # update alive + finished splits\n",
    "        alive  = [(p,s) for (p,s) in beam if not p.finished]\n",
    "        finished = [(p,s) for (p,s) in beam if p.finished]\n",
    "\n",
    "    return best_program, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99377140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from mawm.models.program_encoder import ProgramPredictor, ProgramEncoder\n",
    "\n",
    "import torch\n",
    "def loss_fn(z_hat, z, loss_exp= 1):\n",
    "    return torch.mean(torch.abs(z_hat - z) ** loss_exp) / loss_exp\n",
    "\n",
    "def score_fn(z, m, predictor= None):\n",
    "    predictor = ProgramPredictor()\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "    scores = []\n",
    "    with torch.no_grad():\n",
    "        z_hat = predictor(m)\n",
    "    \n",
    "    return [-loss_fn(z_hat[i].unsqueeze(0), z) for i in range(z_hat.size(0))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a86b61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ProgramPredictor()\n",
    "# set predictor parameters to stop gradients\n",
    "for param in predictor.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952113fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from mawm.models.program_embedder import ProgramEmbedder, PRIMITIVE_TEMPLATES\n",
    "from mawm.models.program_encoder import ProgramEncoder\n",
    "from mawm.core import *\n",
    "from mawm.models.program_synthizer import Proposer\n",
    "import torch\n",
    "z = torch.randn(1, 32)\n",
    "device = 'cpu'\n",
    "grid_size= 7\n",
    "\n",
    "num_primitives = len(PRIMITIVE_TEMPLATES)\n",
    "p_embed = ProgramEmbedder(\n",
    "    num_primitives= num_primitives,\n",
    "    param_cardinalities= [7, 7],\n",
    "    max_params_per_primitive= 2,\n",
    "    d_name= 32,\n",
    "    d_param= 32,\n",
    ")\n",
    "\n",
    "p_encoder = ProgramEncoder(num_primitives, [grid_size, grid_size],2, seq_len=5)\n",
    "proposer = Proposer(obs_dim= 32,\n",
    "                    num_prims= num_primitives,\n",
    "                    max_params= 2,\n",
    "                    seq_len= 5,\n",
    "                    prog_emb_dim_x= 32,\n",
    "                    prog_emb_dim_y= 32,\n",
    "                    prog_emb_dim_prims= 32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0312690c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@torch.no_grad()\n",
    "def neural_guided_beam_search_batched(\n",
    "    z_batch,                      # shape [B, D]\n",
    "    program_embedder,\n",
    "    proposer,\n",
    "    program_encoder,\n",
    "    score_fn,\n",
    "    MAX_PARAMS=3,\n",
    "    beam_width=5,\n",
    "    topk=6,\n",
    "    max_prog_len=5,\n",
    "    grid_size=7,\n",
    "    lambdas=(0.25, 0.5, 0.25),\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Batched version: run *one beam search per batch element*.\n",
    "    Returns:\n",
    "        list of length B, each entry is (best_program, best_score)\n",
    "    \"\"\"\n",
    "\n",
    "    z_batch = z_batch.to(device)\n",
    "    if z_batch.dim() == 1:\n",
    "        z_batch = z_batch.unsqueeze(0)\n",
    "\n",
    "    B = z_batch.shape[0]\n",
    "    results = []\n",
    "\n",
    "    # --- run your SAME beam search per batch element ---\n",
    "    for b in range(B):\n",
    "        z_single = z_batch[b]  # shape [D]\n",
    "        best_prog, best_score = neural_guided_beam_search(\n",
    "            z_single,\n",
    "            program_embedder,\n",
    "            proposer,\n",
    "            program_encoder,\n",
    "            score_fn,\n",
    "            MAX_PARAMS=MAX_PARAMS,\n",
    "            beam_width=beam_width,\n",
    "            topk=topk,\n",
    "            max_prog_len=max_prog_len,\n",
    "            grid_size=grid_size,\n",
    "            lambdas=lambdas,\n",
    "            device=device,\n",
    "        )\n",
    "        results.append((best_prog, best_score))\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6799b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst_res = []\n",
    "# z = torch.randn(32, 32).to(device)\n",
    "# for i in range(10000):\n",
    "#     res = neural_guided_beam_search_batched(z, p_embed, proposer, p_encoder, score_fn, beam_width=3, topk=4, max_prog_len= 5, lambdas= (0.7, 0.2, 0.01), device= device)\n",
    "#     lst_res.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdfbd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(OtherAgentDirection(-1, -1, -1) | GoalAt(6.0, 0.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0),\n",
       "  -5.453608751927137),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(3.0, 4.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0),\n",
       "  -5.565990809686897),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(6.0, 1.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(4.0, 0.0) | GoalAt(3.0, 3.0),\n",
       "  -5.459200592587708),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(6.0, 1.0) | GoalAt(3.0, 0.0) | GoalAt(1.0, 5.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0),\n",
       "  -5.462237890699624),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(5.0, 0.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0),\n",
       "  -5.422450281898497),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(3.0, 2.0) | GoalAt(3.0, 3.0) | GoalAt(1.0, 3.0) | GoalAt(5.0, 1.0) | GoalAt(3.0, 3.0),\n",
       "  -5.464751803342818),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(0.0, 2.0) | GoalAt(3.0, 2.0) | GoalAt(0.0, 6.0) | GoalAt(5.0, 5.0) | GoalAt(3.0, 1.0),\n",
       "  -5.504338183787583),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(0.0, 3.0) | GoalAt(3.0, 3.0),\n",
       "  -5.445634705450057),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(2.0, 1.0),\n",
       "  -5.374930607144355),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(6.0, 5.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(2.0, 4.0) | GoalAt(4.0, 0.0),\n",
       "  -5.470800990907668),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(2.0, 2.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0),\n",
       "  -5.605001301121234),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(4.0, 5.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 6.0),\n",
       "  -5.518440463966845),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(6.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(0.0, 1.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0),\n",
       "  -5.413969258369922),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(0.0, 0.0) | GoalAt(6.0, 2.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(0.0, 6.0),\n",
       "  -5.428814430279254),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(6.0, 6.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(6.0, 6.0),\n",
       "  -5.519215653492926),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(3.0, 3.0) | GoalAt(1.0, 6.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 4.0) | GoalAt(3.0, 3.0),\n",
       "  -5.532040107140063),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(4.0, 4.0) | GoalAt(3.0, 3.0),\n",
       "  -5.541788456562279),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(6.0, 4.0) | GoalAt(6.0, 4.0) | GoalAt(2.0, 5.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0),\n",
       "  -5.47388149497342),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(2.0, 6.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(6.0, 5.0) | GoalAt(3.0, 3.0),\n",
       "  -5.537707933595894),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(3.0, 4.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(2.0, 1.0) | GoalAt(3.0, 3.0),\n",
       "  -5.550644423650025),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(3.0, 3.0) | GoalAt(3.0, 4.0) | GoalAt(3.0, 3.0) | GoalAt(2.0, 4.0) | GoalAt(3.0, 3.0),\n",
       "  -5.582386040188789),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(3.0, 3.0) | GoalAt(2.0, 2.0) | GoalAt(1.0, 5.0) | GoalAt(6.0, 3.0) | GoalAt(3.0, 3.0),\n",
       "  -5.449011560061692),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(4.0, 0.0) | GoalAt(0.0, 0.0) | GoalAt(4.0, 2.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0),\n",
       "  -5.485381389712808),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(2.0, 2.0) | GoalAt(1.0, 0.0),\n",
       "  -5.49543854318571),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(5.0, 5.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0),\n",
       "  -5.492963693356035),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(5.0, 0.0) | GoalAt(3.0, 3.0) | GoalAt(2.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0),\n",
       "  -5.412990415387868),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0),\n",
       "  -5.484276127851723),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(4.0, 4.0) | GoalAt(3.0, 3.0) | GoalAt(6.0, 1.0) | GoalAt(2.0, 5.0) | GoalAt(3.0, 3.0),\n",
       "  -5.433371660639761),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(1.0, 0.0) | GoalAt(3.0, 3.0) | GoalAt(2.0, 4.0) | GoalAt(2.0, 0.0) | GoalAt(3.0, 3.0),\n",
       "  -5.430231883099793),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(2.0, 0.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0),\n",
       "  -5.463048352972984),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(4.0, 1.0) | GoalAt(3.0, 5.0) | GoalAt(3.0, 3.0),\n",
       "  -5.452552886285304),\n",
       " (OtherAgentDirection(-1, -1, -1) | GoalAt(3.0, 3.0) | GoalAt(6.0, 0.0) | GoalAt(3.0, 3.0) | GoalAt(3.0, 3.0) | GoalAt(4.0, 4.0),\n",
       "  -5.5119936544449315)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lst_res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f50a4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10240000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 32 * 32 * 10000\n",
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537e115e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.466666666666667"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time = 208 / 60\n",
    "total_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db51ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3854166666666667e-07"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_per_sample = total_time / n_samples\n",
    "time_per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f9b9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11,\n",
       " 3,\n",
       " 10,\n",
       " 11,\n",
       " 11,\n",
       " 2,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 2,\n",
       " 6,\n",
       " 11,\n",
       " 11,\n",
       " 3,\n",
       " 4,\n",
       " 11,\n",
       " 4,\n",
       " 5,\n",
       " 11,\n",
       " 11,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 11,\n",
       " 5,\n",
       " 3,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 5,\n",
       " 2]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [lst_res[0][i][0].__len__() for i in range(32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b82cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a, b  = batchify_programs([lst_res[0][i][0] for i in range(32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a5649a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 11]), torch.Size([32, 11, 2]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77685453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OtherAgentDirection(-1, -1, -1) | CellEmpty(1.0, 0.0) | OtherAgentDirection(3.0,) | GoalAt(3.0, 3.0) | ItemAt(0.0, 1.0) | GoalAt(3.0, 3.0) | CellObstacle(3.0, 3.0) | CellGoal(3.0, 3.0) | GoalAt(3.0, 3.0) | CellAgent(2.0, 4.0) | OtherAgentNear()"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# idx = np.random.choice(len(lst_res))\n",
    "# print(idx)\n",
    "# lst_res[idx][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b590d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.716"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum([len(lst_res[idx][0]) for idx in range(len(lst_res))]) / len(lst_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee98474e",
   "metadata": {},
   "source": [
    "i think the formulation of the specification is weak and does not sound natural. The problem of program synthesis is the task of constructing a program that provably satisfies a given high-level formal specification. So, the program should be a way of adhering to the specification. For example, when applied to the input, it should satisfy the output. \n",
    "\n",
    "In our case, you defined the specification with the output as s(x, p), which is ambiguous and does not adhere to the definition of program synthesis. Now, what are other ways we can cast the problem as a program synthesis problem? \n",
    "\n",
    "My data set is structured as (observation, action, reward, next_observation). Can we devise a program that satisfy some specifications from such scenario? ideally the program will be shared with another agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69feff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
