{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "368be84d",
   "metadata": {},
   "source": [
    "# Cross-Entropy Method (CEM) Planner\n",
    "\n",
    "> Planner using the Cross-Entropy Method (CEM) for optimization of discrete action sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ea932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp planners.cem_planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f4e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# from nbdev.showdoc import *  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd474d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "from fastcore.utils import *\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import os\n",
    "from mawm.data.utils import base_tf, msg_tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f9a239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from mawm.envs.marl_grid import make_env\n",
    "from mawm.envs.marl_grid.cfg import config\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "seed = np.random.randint(0, 10000)\n",
    "cfg = copy.deepcopy(config)\n",
    "cfg.env_cfg.seed = int(seed)\n",
    "cfg.env_cfg.max_steps = 512\n",
    "\n",
    "env = make_env(cfg.env_cfg)\n",
    "agents = [f\"agent_{i}\" for i in range(cfg.env_cfg.num_agents)]\n",
    "obs = env.reset()\n",
    "goal_pos = obs[\"global\"][\"goal_pos\"]\n",
    "goal_obs = np.array([\n",
    "    env.get_goal(env.agents[i], goal_pos)[0]\n",
    "    for i in range(config.env_cfg.num_agents)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e174bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, cfg.env_cfg.num_agents)\n",
    "for i in range(cfg.env_cfg.num_agents):\n",
    "    ax[i].imshow(goal_obs[i])\n",
    "    ax[i].set_title(f\"Agent {i} Goal Observation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50d0ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 42, 42, 3)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "goal_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd025d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from mawm.data.utils import base_tf, msg_tf\n",
    "import torch\n",
    "def preprocessor(obs):\n",
    "    obs = torch.stack([base_tf(obs[i].astype(np.uint8)) for i in range(len(obs))])\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669d8799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 42, 42])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "import torch\n",
    "from mawm.data.utils import base_tf, msg_tf\n",
    "goals = torch.stack([base_tf(goal_obs[i].astype(np.uint8)) for i in range(len(goal_obs))])\n",
    "goals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1564f23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CellEmpty': 0, 'CellObstacle': 1, 'CellItem': 2, 'CellGoal': 3, 'CellAgent': 4, 'GoalAt': 5, 'ItemAt': 6, 'Near': 7, 'SeeGoal': 8, 'CanMove': 9, 'OtherAgentAt': 10, 'OtherAgentNear': 11, 'OtherAgentDirection': 12}\n"
     ]
    }
   ],
   "source": [
    "#| hide \n",
    "from mawm.models.jepa import JEPA\n",
    "from omegaconf import OmegaConf\n",
    "cfg = OmegaConf.load(\"../cfgs/MPCJepa/mpc.yaml\")\n",
    "model = JEPA(cfg.model, input_dim=(3, 42, 42), action_dim=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af1a62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 15, 15])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "import torch\n",
    "encoded_goals = model.backbone(goals)\n",
    "encoded_goals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b2771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pov', 'selfpos', 'orientation', 'identity'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "obs['agent_0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5c6cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "obs = env.reset()\n",
    "goal_obs = np.array([\n",
    "    env.get_goal(env.agents[i], goal_pos)[0]\n",
    "    for i in range(config.env_cfg.num_agents)\n",
    "])\n",
    "goals = torch.stack([base_tf(goal_obs[i].astype(np.uint8)) for i in range(len(goal_obs))])\n",
    "encoded_goals = model.backbone(goals)\n",
    "\n",
    "msgs = {agent: msg_tf((obs[agent]['pov'], agent, False)) for agent in agents}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69c2f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42, 42, 3), torch.Size([5, 7, 7]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "obs['agent_0']['pov'].astype(np.uint8).shape,  msgs['agent_0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe034eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "from mawm.data.utils import plot_grid\n",
    "plot_grid(obs['agent_0']['pov'].astype(np.uint8), msgs['agent_0'].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe77daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 15, 15])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "obs_transformed = torch.stack([base_tf(obs[agent]['pov'].astype(np.uint8)) for agent in agents])\n",
    "encoded_obs = model.backbone(obs_transformed)\n",
    "encoded_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43db6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "pos = torch.stack([torch.from_numpy(obs[agent]['selfpos']) for agent in agents])\n",
    "pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04b2c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 15, 15])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "encoded_obs = model.backbone(obs_transformed, position=None)\n",
    "encoded_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db52b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 15, 15)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "model.backbone.repr_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a12a34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 15, 15])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "encoded_goals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2187d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from mawm.models.misc import ObsPred, MsgPred\n",
    "from mawm.models.vision import SemanticEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256af2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "obs_pred = ObsPred(h_dim=32, out_channels=16)\n",
    "msg_pred = MsgPred(h_dim=32, in_channels=16)\n",
    "msg_encoder = SemanticEncoder(latent_dim=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5790dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# from mawm.models.utils import Expander2D\n",
    "# class CEMPlanner:\n",
    "#     def __init__(self, model, msg_enc, msg_pred, obs_pred, \n",
    "#                  action_dim= 5, horizon= 10, num_samples= 1000,\n",
    "#                  num_elites=100, opt_steps=100):\n",
    "        \n",
    "#         self.probs = torch.full((horizon, action_dim), 1.0/action_dim) # Uniform initial distribution of shape [Horizon, Action_Dim]\n",
    "#         self.model = model\n",
    "#         self.msg_enc = msg_enc\n",
    "#         self.msg_pred = msg_pred\n",
    "#         self.obs_pred = obs_pred\n",
    "#         self.action_dim = action_dim\n",
    "#         self.horizon = horizon\n",
    "#         self.num_samples = num_samples\n",
    "#         self.num_elites = num_elites\n",
    "#         self.opt_steps = opt_steps\n",
    "#         self.device = 'cpu'\n",
    "        \n",
    "\n",
    "#     def update_dist(self, probs, samples, costs, num_elites=50):\n",
    "\n",
    "#         values, elite_indices = torch.topk(-costs, num_elites)\n",
    "#         elites = samples[elite_indices] # [num_elites, Horizon]\n",
    "        \n",
    "#         # Update probabilities for the next round\n",
    "#         new_probs = torch.full_like(probs, 0.01 / probs.shape[-1])\n",
    "#         for t in range(probs.shape[0]):\n",
    "#             new_probs[t].scatter_add_(0, elites[:, t], torch.ones(num_elites) * (0.99 / num_elites))\n",
    "        \n",
    "#         best_plan = elites[0]\n",
    "        \n",
    "#         return new_probs, best_plan\n",
    "\n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def plan(self, o_t, pos_t, o_g, m_other, other_actions):\n",
    "#         z_t  = self.model.backbone(o_t.unsqueeze(0)) # [B=1, C, H, W] => [1, 16, 15, 15] #, position= pos_t.unsqueeze(0)\n",
    "#         pos_t = Expander2D(z_t.shape[-1], z_t.shape[-2])(pos_t.unsqueeze(0)) # [1, 2, 15, 15]\n",
    "#         z_t = torch.cat([z_t, pos_t], dim=1) # [1, 18, 15, 15]\n",
    "#         z_g = self.model.backbone(o_g.unsqueeze(0)) # [B=1, C, H, W] => [1, 16, 15, 15]\n",
    "\n",
    "#         a_self = torch.multinomial(self.probs, self.num_samples, replacement=True).T # [num_samples, horizon] \n",
    "        \n",
    "#         h0_other = self.msg_enc(m_other.unsqueeze(0).unsqueeze(1)) # [5, 7, 7] => [1, 1, 32]\n",
    "#         a_other = other_actions.repeat(self.num_samples, 1) # [num_samples, horizon]\n",
    "\n",
    "#         total_costs = self.evolve(z_t, z_g, h0_other, a_self, a_other)\n",
    "#         self.probs, best_plan = self.update_dist(self.probs, a_self, total_costs, self.num_elites)\n",
    "#         return best_plan\n",
    "\n",
    "#     def evolve(self, z_t, z_goal, h0_other, a_self, a_other):\n",
    "#         S = self.num_samples\n",
    "\n",
    "#         curr_z_self = repeat(z_t, 'b c h w -> (b s) t c h w', b= 1, s=S, t= 1) # [s, t= 1, c=18, h=15, w=15]\n",
    "#         curr_h_other = repeat(h0_other, 'b t d -> s t (b d)', s=S) # [s, 1, 32]\n",
    "        \n",
    "#         curr_z_other = self.obs_pred(curr_h_other)#[s, 1, 16, 15, 15]  \n",
    "#         curr_h_self = self.msg_pred(curr_z_self[:, :, :-2]) #[s, 1, 32]\n",
    "\n",
    "#         curr_z_self = rearrange(curr_z_self, \"s t c h w -> (t s) c h w\", t= 1)\n",
    "#         curr_z_other = rearrange(curr_z_other, \"s t c h w -> (t s) c h w\", t= 1)\n",
    "\n",
    "#         total_cost = torch.zeros(S, device=self.device)\n",
    "#         # import pdb; pdb.set_trace()\n",
    "#         for t in range(self.horizon):\n",
    "            \n",
    "#             curr_h_other = rearrange(curr_h_other, \"s t d -> (t s) d\", t= 1)\n",
    "#             curr_h_self = rearrange(curr_h_self, \"s t d -> (t s) d\", t= 1)\n",
    "\n",
    "#             a_self_t = a_self[:, t].unsqueeze(1) # [1 500]\n",
    "#             a_other_t = a_other[:, t].unsqueeze(1) # [1, 500]\n",
    "            \n",
    "\n",
    "#             next_z_self = self.model.dynamics.forward(current_state = curr_z_self, curr_action= a_self_t, curr_msg= curr_h_other)\n",
    "#             next_z_other = self.model.dynamics.forward(current_state = curr_z_other, curr_action= a_other_t, curr_msg= curr_h_self)\n",
    "\n",
    "#             next_h_self = self.msg_pred(rearrange(next_z_self[:, :-2], '(s t) c h w -> s t c h w ', t= 1))\n",
    "#             next_h_other = self.msg_pred(rearrange(next_z_other[:, :-2], '(s t) c h w -> s t c h w ', t= 1))\n",
    "\n",
    "#             total_cost += (next_z_self[:, :-2] - z_goal.unsqueeze(1)).pow(2).mean(dim=(2, 3, 4)).squeeze()\n",
    "\n",
    "#             curr_z_self, curr_z_other = next_z_self, next_z_other\n",
    "#             curr_h_self, curr_h_other = next_h_self, next_h_other\n",
    "\n",
    "#         return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bfe86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# from mawm.models.utils import Expander2D\n",
    "# import torch\n",
    "# from einops import repeat, rearrange\n",
    "\n",
    "# class CEMPlanner:\n",
    "#     def __init__(self, model, msg_enc, msg_pred, obs_pred, \n",
    "#                  action_dim=5, horizon=10, num_samples=1000,\n",
    "#                  num_elites=100, opt_steps=10): # Reduced opt_steps for speed, adjust as needed\n",
    "        \n",
    "#         self.model = model\n",
    "#         self.msg_enc = msg_enc\n",
    "#         self.msg_pred = msg_pred\n",
    "#         self.obs_pred = obs_pred\n",
    "#         self.action_dim = action_dim\n",
    "#         self.horizon = horizon\n",
    "#         self.num_samples = num_samples\n",
    "#         self.num_elites = num_elites\n",
    "#         self.opt_steps = opt_steps\n",
    "#         self.device = 'cpu'\n",
    "        \n",
    "#     def update_dist(self, probs, samples, costs, num_elites):\n",
    "#         # Find indices of samples with the lowest cost\n",
    "#         # topk on negative costs gives us the minimum values\n",
    "#         _, elite_indices = torch.topk(-costs, num_elites)\n",
    "#         elites = samples[elite_indices] # [num_elites, horizon]\n",
    "        \n",
    "#         # Create a fresh probability distribution based on elite actions\n",
    "#         new_probs = torch.zeros_like(probs)\n",
    "#         for t in range(self.horizon):\n",
    "#             # Count how often each action appeared in the elite set at time t\n",
    "#             counts = torch.bincount(elites[:, t], minlength=self.action_dim).float()\n",
    "#             new_probs[t] = counts / num_elites\n",
    "        \n",
    "#         # Apply smoothing (Laplace smoothing) to prevent 0-probability actions\n",
    "#         # This keeps the distribution \"open\" for the next opt_step\n",
    "#         epsilon = 0.01\n",
    "#         new_probs = (1 - epsilon) * new_probs + (epsilon / self.action_dim)\n",
    "        \n",
    "#         best_plan = elites[0]\n",
    "#         return new_probs, best_plan\n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def plan(self, o_t, pos_t, o_g, m_other, other_actions):\n",
    "#         # 1. INITIALIZE: Reset distribution to uniform at the start of every plan call\n",
    "#         # This ensures we don't carry over bias from previous environment steps.\n",
    "#         current_probs = torch.full((self.horizon, self.action_dim), 1.0/self.action_dim, device=self.device)\n",
    "\n",
    "#         # 2. ENCODE: Prepare latent states once\n",
    "#         z_t = self.model.backbone(o_t.unsqueeze(0)) \n",
    "#         pos_t_expanded = Expander2D(z_t.shape[-1], z_t.shape[-2])(pos_t.unsqueeze(0))\n",
    "#         z_t = torch.cat([z_t, pos_t_expanded], dim=1) \n",
    "#         z_g = self.model.backbone(o_g.unsqueeze(0)) \n",
    "        \n",
    "#         h0_other = self.msg_enc(m_other.unsqueeze(0).unsqueeze(1)) \n",
    "#         # The other agent's plan is treated as a fixed anchor for this optimization cycle\n",
    "#         a_other = other_actions.repeat(self.num_samples, 1) \n",
    "\n",
    "#         # 3. OPTIMIZE: The CEM Loop (Step 'f' in your paper)\n",
    "#         best_plan = None\n",
    "#         for _ in range(self.opt_steps):\n",
    "#             # Sample sequences from current distribution\n",
    "#             # Shape: [num_samples, horizon]\n",
    "#             a_self = torch.multinomial(current_probs, self.num_samples, replacement=True).T \n",
    "            \n",
    "#             # Evaluate samples using the world model\n",
    "#             total_costs = self.evolve(z_t, z_g, h0_other, a_self, a_other)\n",
    "            \n",
    "#             # Update the distribution to focus on low-cost regions\n",
    "#             current_probs, best_plan = self.update_dist(current_probs, a_self, total_costs, self.num_elites)\n",
    "\n",
    "#         return best_plan\n",
    "\n",
    "#     def evolve(self, z_t, z_goal, h0_other, a_self, a_other):\n",
    "#         S = self.num_samples\n",
    "#         # ... (Your existing evolve logic remains the same) ...\n",
    "#         curr_z_self = repeat(z_t, 'b c h w -> (b s) t c h w', b= 1, s=S, t= 1)\n",
    "#         curr_h_other = repeat(h0_other, 'b t d -> s t (b d)', s=S)\n",
    "        \n",
    "#         curr_z_other = self.obs_pred(curr_h_other)  \n",
    "#         curr_h_self = self.msg_pred(curr_z_self[:, :, :-2]) \n",
    "\n",
    "#         curr_z_self = rearrange(curr_z_self, \"s t c h w -> (t s) c h w\", t= 1)\n",
    "#         curr_z_other = rearrange(curr_z_other, \"s t c h w -> (t s) c h w\", t= 1)\n",
    "\n",
    "#         total_cost = torch.zeros(S, device=self.device)\n",
    "        \n",
    "#         for t in range(self.horizon):\n",
    "#             curr_h_other = rearrange(curr_h_other, \"s t d -> (t s) d\", t= 1)\n",
    "#             curr_h_self = rearrange(curr_h_self, \"s t d -> (t s) d\", t= 1)\n",
    "\n",
    "#             a_self_t = a_self[:, t].unsqueeze(1) \n",
    "#             a_other_t = a_other[:, t].unsqueeze(1) \n",
    "            \n",
    "#             next_z_self = self.model.dynamics.forward(current_state=curr_z_self, curr_action=a_self_t, curr_msg=curr_h_other)\n",
    "#             next_z_other = self.model.dynamics.forward(current_state=curr_z_other, curr_action=a_other_t, curr_msg=curr_h_self)\n",
    "\n",
    "#             next_h_self = self.msg_pred(rearrange(next_z_self[:, :-2], '(s t) c h w -> s t c h w ', t= 1))\n",
    "#             next_h_other = self.msg_pred(rearrange(next_z_other[:, :-2], '(s t) c h w -> s t c h w ', t= 1))\n",
    "\n",
    "#             # Cost calculation: MSE to goal\n",
    "#             total_cost += (next_z_self[:, :-2] - z_goal).pow(2).mean(dim=(1, 2, 3))\n",
    "\n",
    "#             curr_z_self, curr_z_other = next_z_self, next_z_other\n",
    "#             curr_h_self, curr_h_other = next_h_self, next_h_other\n",
    "\n",
    "#         return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a2811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# from mawm.models.utils import Expander2D\n",
    "# import torch\n",
    "# from einops import repeat, rearrange\n",
    "\n",
    "# class CEMPlanner:\n",
    "#     def __init__(self, model, msg_enc, msg_pred, obs_pred, \n",
    "#                  action_dim=5, horizon=10, num_samples=1000,\n",
    "#                  num_elites=100, opt_steps=10):\n",
    "        \n",
    "#         self.model = model\n",
    "#         self.msg_enc = msg_enc\n",
    "#         self.msg_pred = msg_pred\n",
    "#         self.obs_pred = obs_pred\n",
    "#         self.action_dim = action_dim # Number of discrete choices (0-4)\n",
    "#         self.horizon = horizon\n",
    "#         self.num_samples = num_samples\n",
    "#         self.num_elites = num_elites\n",
    "#         self.opt_steps = opt_steps\n",
    "#         self.device = 'cpu'\n",
    "        \n",
    "#     def update_dist(self, probs, samples, costs, num_elites):\n",
    "#         # We want to MINIMIZE cost, so we take the topk of negative costs\n",
    "#         _, elite_indices = torch.topk(-costs, num_elites)\n",
    "#         elites = samples[elite_indices] # [num_elites, horizon]\n",
    "        \n",
    "#         new_probs = torch.zeros_like(probs)\n",
    "#         for t in range(self.horizon):\n",
    "#             counts = torch.bincount(elites[:, t], minlength=self.action_dim).float()\n",
    "#             new_probs[t] = counts / num_elites\n",
    "        \n",
    "#         # Laplace smoothing to ensure we always have some exploration noise\n",
    "#         epsilon = 0.01\n",
    "#         new_probs = (1 - epsilon) * new_probs + (epsilon / self.action_dim)\n",
    "        \n",
    "#         return new_probs, elites[0]\n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def plan(self, o_t, pos_t, o_g, m_other, other_actions):\n",
    "#         # RESET: Start fresh so we don't get stuck in a local minimum from the last step\n",
    "#         current_probs = torch.full((self.horizon, self.action_dim), 1.0/self.action_dim, device=self.device)\n",
    "\n",
    "#         z_t = self.model.backbone(o_t.unsqueeze(0)) \n",
    "#         pos_t_expanded = Expander2D(z_t.shape[-1], z_t.shape[-2])(pos_t.unsqueeze(0))\n",
    "#         z_t = torch.cat([z_t, pos_t_expanded], dim=1) \n",
    "#         z_g = self.model.backbone(o_g.unsqueeze(0)) \n",
    "        \n",
    "#         h0_other = self.msg_enc(m_other.unsqueeze(0).unsqueeze(1)) \n",
    "#         a_other = other_actions.repeat(self.num_samples, 1) \n",
    "\n",
    "#         best_plan = None\n",
    "#         for i in range(self.opt_steps):\n",
    "#             # Sample sequences: [num_samples, horizon]\n",
    "#             a_self = torch.multinomial(current_probs, self.num_samples, replacement=True).T \n",
    "            \n",
    "#             total_costs = self.evolve(z_t, z_g, h0_other, a_self, a_other)\n",
    "            \n",
    "#             # DEBUG: Uncomment this to see if costs are actually changing\n",
    "#             if i == 0: print(f\"Cost Std: {total_costs.std():.6f}, Min: {total_costs.min():.4f}\")\n",
    "\n",
    "#             current_probs, best_plan = self.update_dist(current_probs, a_self, total_costs, self.num_elites)\n",
    "\n",
    "#         return best_plan\n",
    "\n",
    "#     def evolve(self, z_t, z_goal, h0_other, a_self, a_other):\n",
    "#         S = self.num_samples\n",
    "        \n",
    "#         # Ensure z_goal is ready for broadcasting: [1, C, H, W]\n",
    "#         # We strip the last 2 channels if your goal doesn't include the pos_t expansion\n",
    "#         z_goal_target = z_goal \n",
    "\n",
    "#         curr_z_self = repeat(z_t, 'b c h w -> (b s) c h w', s=S)\n",
    "#         curr_h_other = repeat(h0_other, 'b t d -> (s b t) d', s=S)\n",
    "        \n",
    "#         # Initial imagined states for the other agent\n",
    "#         curr_z_other = rearrange(self.obs_pred(curr_h_other.unsqueeze(1)), \"s t c h w -> (s t) c h w\")\n",
    "#         curr_h_self = self.msg_pred(curr_z_self[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "\n",
    "#         total_cost = torch.zeros(S, device=self.device)\n",
    "        \n",
    "#         for t in range(self.horizon):\n",
    "#             a_self_t = a_self[:, t].unsqueeze(1) # [S, 1]\n",
    "#             a_other_t = a_other[:, t].unsqueeze(1) # [S, 1]\n",
    "            \n",
    "#             # Forward dynamics\n",
    "#             next_z_self = self.model.dynamics.forward(current_state=curr_z_self, curr_action=a_self_t, curr_msg=curr_h_other)\n",
    "#             next_z_other = self.model.dynamics.forward(current_state=curr_z_other, curr_action=a_other_t, curr_msg=curr_h_self)\n",
    "\n",
    "#             # Predict next messages\n",
    "#             curr_h_self = self.msg_pred(next_z_self[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "#             curr_h_other = self.msg_pred(next_z_other[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "\n",
    "#             # --- CRITICAL: Cost calculation ---\n",
    "#             # Compare only the latent state (excluding position channels if necessary)\n",
    "#             # next_z_self[:, :-2] is [S, 16, 15, 15]\n",
    "#             # z_goal_target is [1, 16, 15, 15]\n",
    "#             diff = next_z_self[:, :-2] - z_goal_target\n",
    "            \n",
    "#             # Step-wise cost (MSE)\n",
    "#             total_cost += diff.pow(2).mean(dim=(1, 2, 3))\n",
    "\n",
    "#             curr_z_self, curr_z_other = next_z_self, next_z_other\n",
    "\n",
    "#         return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bf002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# import torch\n",
    "# from einops import repeat, rearrange\n",
    "# from mawm.models.utils import Expander2D\n",
    "\n",
    "# class CEMPlanner:\n",
    "#     def __init__(self, model, msg_enc, msg_pred, obs_pred, \n",
    "#                  action_dim=5, horizon=10, num_samples=1000,\n",
    "#                  num_elites=100, opt_steps=10, device='cpu'):\n",
    "        \n",
    "#         self.model = model\n",
    "#         self.msg_enc = msg_enc\n",
    "#         self.msg_pred = msg_pred\n",
    "#         self.obs_pred = obs_pred\n",
    "#         self.action_dim = action_dim\n",
    "#         self.horizon = horizon\n",
    "#         self.num_samples = num_samples\n",
    "#         self.num_elites = num_elites\n",
    "#         self.opt_steps = opt_steps\n",
    "#         self.device = device\n",
    "        \n",
    "#         # Hyperparameters for improved stability\n",
    "#         self.alpha = 0.3  # Momentum for distribution update\n",
    "#         self.epsilon = 0.01  # Laplace smoothing\n",
    "#         self.temp_start = 1.0  # Initial temperature\n",
    "#         self.temp_end = 0.5  # Final temperature\n",
    "        \n",
    "#     def update_dist(self, probs, samples, costs, num_elites, iteration):\n",
    "#         \"\"\"Update probability distribution using elite samples with momentum.\"\"\"\n",
    "#         # Select elites (minimize cost)\n",
    "#         _, elite_indices = torch.topk(-costs, num_elites)\n",
    "#         elites = samples[elite_indices]\n",
    "        \n",
    "#         # Compute empirical distribution from elites\n",
    "#         empirical_probs = torch.zeros_like(probs)\n",
    "#         for t in range(self.horizon):\n",
    "#             counts = torch.bincount(elites[:, t], minlength=self.action_dim).float()\n",
    "#             empirical_probs[t] = counts / num_elites\n",
    "        \n",
    "#         # Momentum update for stability\n",
    "#         new_probs = self.alpha * empirical_probs + (1 - self.alpha) * probs\n",
    "        \n",
    "#         # Laplace smoothing\n",
    "#         new_probs = (1 - self.epsilon) * new_probs + (self.epsilon / self.action_dim)\n",
    "        \n",
    "#         # Temperature annealing for sharpening\n",
    "#         temp = self.temp_start + (self.temp_end - self.temp_start) * (iteration / self.opt_steps)\n",
    "#         new_probs = new_probs ** (1 / temp)\n",
    "#         new_probs = new_probs / new_probs.sum(dim=1, keepdim=True)\n",
    "        \n",
    "#         return new_probs, elites[0]\n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def plan(self, o_t, o_g, pos_t, m_other, other_actions):\n",
    "#         \"\"\"Plan action sequence using CEM.\"\"\"\n",
    "#         # Move inputs to device\n",
    "#         o_t = o_t.to(self.device)\n",
    "#         o_g = o_g.to(self.device)\n",
    "#         pos_t = pos_t.to(self.device)\n",
    "#         m_other = m_other.to(self.device)\n",
    "#         other_actions = other_actions.to(self.device)\n",
    "        \n",
    "#         # Initialize uniform distribution\n",
    "#         current_probs = torch.full(\n",
    "#             (self.horizon, self.action_dim), \n",
    "#             1.0 / self.action_dim, \n",
    "#             device=self.device\n",
    "#         )\n",
    "\n",
    "#         # Encode current state and goal\n",
    "#         z_t = self.model.backbone(o_t.unsqueeze(0))\n",
    "#         pos_t_expanded = Expander2D(z_t.shape[-1], z_t.shape[-2])(pos_t.unsqueeze(0))\n",
    "#         z_t = torch.cat([z_t, pos_t_expanded], dim=1)\n",
    "        \n",
    "#         z_g = self.model.backbone(o_g.unsqueeze(0))\n",
    "#         # Match dimensions with cost calculation (exclude position channels)\n",
    "#         z_goal_target = z_g#[:, :-2]\n",
    "        \n",
    "#         # Encode other agent's message\n",
    "#         h0_other = self.msg_enc(m_other.unsqueeze(0).unsqueeze(1))\n",
    "#         a_other = other_actions.repeat(self.num_samples, 1)\n",
    "\n",
    "#         best_plan = None\n",
    "#         best_cost = float('inf')\n",
    "        \n",
    "#         for i in range(self.opt_steps):\n",
    "#             # Sample action sequences\n",
    "#             a_self = torch.multinomial(\n",
    "#                 current_probs, \n",
    "#                 self.num_samples, \n",
    "#                 replacement=True\n",
    "#             ).T.to(self.device)\n",
    "            \n",
    "#             # Evaluate sampled sequences\n",
    "#             total_costs = self.evolve(z_t, z_goal_target, h0_other, a_self, a_other)\n",
    "            \n",
    "#             # Track best solution\n",
    "#             min_cost = total_costs.min()\n",
    "#             if min_cost < best_cost:\n",
    "#                 best_cost = min_cost\n",
    "#                 best_idx = total_costs.argmin()\n",
    "#                 best_plan = a_self[best_idx]\n",
    "            \n",
    "#             # Debug info\n",
    "#             if i == 0 or i == self.opt_steps - 1:\n",
    "#                 print(f\"Iter {i}: Cost ={total_costs.mean():.4f}, \"\n",
    "#                       f\"Std={total_costs.std():.4f}, min={min_cost:.4f}\")\n",
    "\n",
    "#             # Update distribution\n",
    "#             current_probs, _ = self.update_dist(\n",
    "#                 current_probs, a_self, total_costs, self.num_elites, i\n",
    "#             )\n",
    "\n",
    "#         return best_plan\n",
    "\n",
    "#     def evolve(self, z_t, z_goal, h0_other, a_self, a_other):\n",
    "#         \"\"\"Roll out trajectories and compute costs.\"\"\"\n",
    "#         S = self.num_samples\n",
    "        \n",
    "#         # Initialize states\n",
    "#         curr_z_self = repeat(z_t, 'b c h w -> (b s) c h w', s=S)\n",
    "#         curr_h_other = repeat(h0_other, 'b t d -> (s b t) d', s=S)\n",
    "        \n",
    "#         curr_z_other = rearrange(\n",
    "#             self.obs_pred(curr_h_other.unsqueeze(1)), \n",
    "#             \"s t c h w -> (s t) c h w\"\n",
    "#         )\n",
    "#         curr_h_self = self.msg_pred(curr_z_self[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "\n",
    "#         total_cost = torch.zeros(S, device=self.device)\n",
    "        \n",
    "#         # Roll out trajectories\n",
    "#         for t in range(self.horizon):\n",
    "#             a_self_t = a_self[:, t].unsqueeze(1)\n",
    "#             a_other_t = a_other[:, t].unsqueeze(1)\n",
    "            \n",
    "#             # Forward dynamics\n",
    "#             next_z_self = self.model.dynamics.forward(\n",
    "#                 current_state=curr_z_self, \n",
    "#                 curr_action=a_self_t, \n",
    "#                 curr_msg=curr_h_other\n",
    "#             )\n",
    "#             next_z_other = self.model.dynamics.forward(\n",
    "#                 current_state=curr_z_other, \n",
    "#                 curr_action=a_other_t, \n",
    "#                 curr_msg=curr_h_self\n",
    "#             )\n",
    "\n",
    "#             # Update messages\n",
    "#             curr_h_self = self.msg_pred(next_z_self[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "#             curr_h_other = self.msg_pred(next_z_other[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "\n",
    "#             # Compute step cost (MSE to goal)\n",
    "#             diff = next_z_self[:, :-2] - z_goal\n",
    "#             step_cost = diff.pow(2).mean(dim=(1, 2, 3))\n",
    "            \n",
    "#             # Weight final timestep more heavily\n",
    "#             weight = 2.0 if t == self.horizon - 1 else 1.0\n",
    "#             total_cost += weight * step_cost\n",
    "\n",
    "#             curr_z_self, curr_z_other = next_z_self, next_z_other\n",
    "\n",
    "#         return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900c5bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from einops import repeat, rearrange\n",
    "from mawm.models.utils import Expander2D\n",
    "\n",
    "class CEMPlanner:\n",
    "    def __init__(self, model, msg_enc, msg_pred, obs_pred, \n",
    "                 action_dim=5, horizon=10, num_samples=1000,\n",
    "                 num_elites=100, opt_steps=10, device='cpu'):\n",
    "        \n",
    "        self.model = model\n",
    "        self.msg_enc = msg_enc\n",
    "        self.msg_pred = msg_pred\n",
    "        self.obs_pred = obs_pred\n",
    "        self.action_dim = action_dim\n",
    "        self.horizon = horizon\n",
    "        self.num_samples = num_samples\n",
    "        self.num_elites = num_elites\n",
    "        self.opt_steps = opt_steps\n",
    "        self.device = device\n",
    "        \n",
    "        # CRITICAL FIXES for premature convergence\n",
    "        self.alpha = 0.7  # HIGH momentum (was implicit 0, now 0.7)\n",
    "        self.epsilon = 0.1  # MUCH higher smoothing (was 0.01)\n",
    "        self.temperature_schedule = torch.linspace(1.5, 0.8, opt_steps)  # Start hot, cool down\n",
    "        \n",
    "    def update_dist(self, probs, samples, costs, num_elites, iteration):\n",
    "        \"\"\"Update with momentum and temperature to prevent collapse.\"\"\"\n",
    "        _, elite_indices = torch.topk(-costs, num_elites)\n",
    "        elites = samples[elite_indices]\n",
    "        \n",
    "        # Compute empirical elite distribution\n",
    "        empirical_probs = torch.zeros_like(probs)\n",
    "        for t in range(self.horizon):\n",
    "            counts = torch.bincount(elites[:, t], minlength=self.action_dim).float()\n",
    "            empirical_probs[t] = counts / num_elites\n",
    "        \n",
    "        # CRITICAL FIX 1: Strong momentum (keep 70% of old distribution)\n",
    "        new_probs = self.alpha * probs + (1 - self.alpha) * empirical_probs\n",
    "        \n",
    "        # CRITICAL FIX 2: Higher exploration noise\n",
    "        new_probs = (1 - self.epsilon) * new_probs + (self.epsilon / self.action_dim)\n",
    "        \n",
    "        # CRITICAL FIX 3: Temperature annealing (starts at 1.5, ends at 0.8)\n",
    "        temperature = self.temperature_schedule[iteration]\n",
    "        new_probs = new_probs ** (1.0 / temperature)\n",
    "        new_probs = new_probs / new_probs.sum(dim=1, keepdim=True)\n",
    "        \n",
    "        return new_probs, elites[0]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def plan(self, o_t, pos_t, o_g, m_other, other_actions):\n",
    "\n",
    "        o_t = o_t.to(self.device)\n",
    "        o_g = o_g.to(self.device)\n",
    "        pos_t = pos_t.to(self.device)\n",
    "        m_other = m_other.to(self.device)\n",
    "        other_actions = other_actions.to(self.device)\n",
    "        # Initialize uniform\n",
    "        current_probs = torch.full(\n",
    "            (self.horizon, self.action_dim), \n",
    "            1.0/self.action_dim, \n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        z_t = self.model.backbone(o_t.unsqueeze(0)) \n",
    "        pos_t_expanded = Expander2D(z_t.shape[-1], z_t.shape[-2])(pos_t.unsqueeze(0))\n",
    "        z_t = torch.cat([z_t, pos_t_expanded], dim=1) \n",
    "        z_g = self.model.backbone(o_g.unsqueeze(0))\n",
    "        \n",
    "        # Match dimensions\n",
    "        z_goal_target = z_g[:, :-2] if z_g.shape[1] > 16 else z_g\n",
    "        \n",
    "        h0_other = self.msg_enc(m_other.unsqueeze(0).unsqueeze(1)) \n",
    "        a_other = other_actions.repeat(self.num_samples, 1) \n",
    "\n",
    "        best_plan = None\n",
    "        best_cost = float('inf')\n",
    "        \n",
    "        for i in range(self.opt_steps):\n",
    "            a_self = torch.multinomial(current_probs, self.num_samples, replacement=True).T \n",
    "            \n",
    "            total_costs = self.evolve(z_t, z_goal_target, h0_other, a_self, a_other)\n",
    "            \n",
    "            # Track best\n",
    "            if total_costs.min() < best_cost:\n",
    "                best_cost = total_costs.min()\n",
    "                best_plan = a_self[total_costs.argmin()]\n",
    "            \n",
    "            # Debug output (keep your existing format)\n",
    "            if i == 0 or i == self.opt_steps - 1:\n",
    "                print(f\"Iter {i}: Cost ={total_costs.mean():.4f}, \"\n",
    "                      f\"Std={total_costs.std():.4f}, min={total_costs.min():.4f}\")\n",
    "            \n",
    "            current_probs, _ = self.update_dist(current_probs, a_self, total_costs, self.num_elites, i)\n",
    "            \n",
    "            # OPTIONAL: Debug action diversity\n",
    "            if i == self.opt_steps - 1:\n",
    "                action_dist = current_probs[0].cpu().numpy()\n",
    "                print(f\"Final action probs: {action_dist.round(3)}\")\n",
    "\n",
    "        return best_plan\n",
    "\n",
    "    def evolve(self, z_t, z_goal, h0_other, a_self, a_other):\n",
    "        S = self.num_samples\n",
    "        z_goal_target = z_goal \n",
    "\n",
    "        curr_z_self = repeat(z_t, 'b c h w -> (b s) c h w', s=S)\n",
    "        curr_h_other = repeat(h0_other, 'b t d -> (s b t) d', s=S)\n",
    "        \n",
    "        curr_z_other = rearrange(self.obs_pred(curr_h_other.unsqueeze(1)), \"s t c h w -> (s t) c h w\")\n",
    "        curr_h_self = self.msg_pred(curr_z_self[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        total_cost = torch.zeros(S, device=self.device)\n",
    "        \n",
    "        for t in range(self.horizon):\n",
    "            a_self_t = a_self[:, t].unsqueeze(1)\n",
    "            a_other_t = a_other[:, t].unsqueeze(1)\n",
    "            \n",
    "            next_z_self = self.model.dynamics.forward(\n",
    "                current_state=curr_z_self, \n",
    "                curr_action=a_self_t, \n",
    "                curr_msg=curr_h_other\n",
    "            )\n",
    "            next_z_other = self.model.dynamics.forward(\n",
    "                current_state=curr_z_other, \n",
    "                curr_action=a_other_t, \n",
    "                curr_msg=curr_h_self\n",
    "            )\n",
    "\n",
    "            curr_h_self = self.msg_pred(next_z_self[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "            curr_h_other = self.msg_pred(next_z_other[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "\n",
    "            diff = next_z_self[:, :-2] - z_goal_target\n",
    "            \n",
    "            # OPTIONAL FIX: Weight final timestep more if you want goal-seeking behavior\n",
    "            weight = 3.0 if t == self.horizon - 1 else 1.0\n",
    "            total_cost += weight * diff.pow(2).mean(dim=(1, 2, 3))\n",
    "\n",
    "            curr_z_self, curr_z_other = next_z_self, next_z_other\n",
    "\n",
    "        return total_cost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33cd258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "planner = CEMPlanner(model=model, msg_enc= msg_encoder, msg_pred=msg_pred, obs_pred=obs_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9672bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "torch.manual_seed(0)\n",
    "probs_j = torch.full((planner.horizon, planner.action_dim), 1.0/planner.action_dim)\n",
    "other_actions = torch.multinomial(probs_j, 1).squeeze(-1)  # [Horizon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa548c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 1, 4, 0, 4, 0, 0, 1, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009357a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T =  0\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "T =  1\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "T =  2\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "T =  3\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "T =  4\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "T =  5\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "T =  6\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "T =  7\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "T =  8\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "T =  9\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 3, 0, 3, 4, 0, 0, 1, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #| hide\n",
    "# from einops import rearrange, repeat\n",
    "# planner.plan(obs_transformed[0], pos[0], o_g=goals[0], m_other=msgs['agent_0'], other_actions=other_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ece34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# ============================================\n",
    "# ALTERNATIVE: Boltzmann/Softmax CEM\n",
    "# ============================================\n",
    "# If the above doesn't work, try this version which uses\n",
    "# cost-weighted sampling instead of hard elite selection\n",
    "\n",
    "class CEMPlannerBoltzmann:\n",
    "    \"\"\"CEM with Boltzmann-weighted updates instead of hard elite selection.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, msg_enc, msg_pred, obs_pred, \n",
    "                 action_dim=5, horizon=10, num_samples=1000,\n",
    "                 opt_steps=10, device='cpu'):\n",
    "        \n",
    "        self.model = model\n",
    "        self.msg_enc = msg_enc\n",
    "        self.msg_pred = msg_pred\n",
    "        self.obs_pred = obs_pred\n",
    "        self.action_dim = action_dim\n",
    "        self.horizon = horizon\n",
    "        self.num_samples = num_samples\n",
    "        self.opt_steps = opt_steps\n",
    "        self.device = device\n",
    "        \n",
    "        self.alpha = 0.5\n",
    "        self.epsilon = 0.05\n",
    "        self.beta_schedule = torch.linspace(0.5, 5.0, opt_steps)  # Inverse temperature\n",
    "        \n",
    "    def update_dist(self, probs, samples, costs, iteration):\n",
    "        \"\"\"Use Boltzmann weighting instead of hard elite selection.\"\"\"\n",
    "        beta = self.beta_schedule[iteration]\n",
    "        \n",
    "        # Convert costs to weights (lower cost = higher weight)\n",
    "        weights = torch.softmax(-beta * costs, dim=0)\n",
    "        \n",
    "        # Weighted histogram\n",
    "        new_probs = torch.zeros_like(probs)\n",
    "        for t in range(self.horizon):\n",
    "            for a in range(self.action_dim):\n",
    "                mask = (samples[:, t] == a).float()\n",
    "                new_probs[t, a] = (weights * mask).sum()\n",
    "        \n",
    "        # Momentum\n",
    "        new_probs = self.alpha * probs + (1 - self.alpha) * new_probs\n",
    "        \n",
    "        # Smoothing\n",
    "        new_probs = (1 - self.epsilon) * new_probs + (self.epsilon / self.action_dim)\n",
    "        new_probs = new_probs / new_probs.sum(dim=1, keepdim=True)\n",
    "        \n",
    "        best_idx = costs.argmin()\n",
    "        return new_probs, samples[best_idx]\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def plan(self, o_t, pos_t, o_g, m_other, other_actions):\n",
    "\n",
    "        o_t = o_t.to(self.device)\n",
    "        o_g = o_g.to(self.device)\n",
    "        pos_t = pos_t.to(self.device)\n",
    "        m_other = m_other.to(self.device)\n",
    "        other_actions = other_actions.to(self.device)\n",
    "        \n",
    "        current_probs = torch.full(\n",
    "            (self.horizon, self.action_dim), \n",
    "            1.0/self.action_dim, \n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        z_t = self.model.backbone(o_t.unsqueeze(0)) \n",
    "        pos_t_expanded = Expander2D(z_t.shape[-1], z_t.shape[-2])(pos_t.unsqueeze(0))\n",
    "        z_t = torch.cat([z_t, pos_t_expanded], dim=1) \n",
    "        z_g = self.model.backbone(o_g.unsqueeze(0))\n",
    "        z_goal_target = z_g[:, :-2] if z_g.shape[1] > 16 else z_g\n",
    "        \n",
    "        h0_other = self.msg_enc(m_other.unsqueeze(0).unsqueeze(1)) \n",
    "        a_other = other_actions.repeat(self.num_samples, 1) \n",
    "\n",
    "        best_plan = None\n",
    "        \n",
    "        for i in range(self.opt_steps):\n",
    "            a_self = torch.multinomial(current_probs, self.num_samples, replacement=True).T \n",
    "            total_costs = self.evolve(z_t, z_goal_target, h0_other, a_self, a_other)\n",
    "            \n",
    "            if i == 0 or i == self.opt_steps - 1:\n",
    "                print(f\"Iter {i}: Cost ={total_costs.mean():.4f}, \"\n",
    "                      f\"Std={total_costs.std():.4f}, min={total_costs.min():.4f}\")\n",
    "            \n",
    "            current_probs, best_plan = self.update_dist(current_probs, a_self, total_costs, i)\n",
    "\n",
    "        return best_plan\n",
    "    \n",
    "    def evolve(self, z_t, z_goal, h0_other, a_self, a_other):\n",
    "        # Same as original\n",
    "        S = self.num_samples\n",
    "        curr_z_self = repeat(z_t, 'b c h w -> (b s) c h w', s=S)\n",
    "        curr_h_other = repeat(h0_other, 'b t d -> (s b t) d', s=S)\n",
    "        curr_z_other = rearrange(self.obs_pred(curr_h_other.unsqueeze(1)), \"s t c h w -> (s t) c h w\")\n",
    "        curr_h_self = self.msg_pred(curr_z_self[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "        total_cost = torch.zeros(S, device=self.device)\n",
    "        \n",
    "        for t in range(self.horizon):\n",
    "            a_self_t = a_self[:, t].unsqueeze(1)\n",
    "            a_other_t = a_other[:, t].unsqueeze(1)\n",
    "            next_z_self = self.model.dynamics.forward(current_state=curr_z_self, curr_action=a_self_t, curr_msg=curr_h_other)\n",
    "            next_z_other = self.model.dynamics.forward(current_state=curr_z_other, curr_action=a_other_t, curr_msg=curr_h_self)\n",
    "            curr_h_self = self.msg_pred(next_z_self[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "            curr_h_other = self.msg_pred(next_z_other[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "            diff = next_z_self[:, :-2] - z_goal\n",
    "            total_cost += diff.pow(2).mean(dim=(1, 2, 3))\n",
    "            curr_z_self, curr_z_other = next_z_self, next_z_other\n",
    "        \n",
    "        return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3f4ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "nbdev.nbdev_export() # type: ignore  # noqa: E702\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
