{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "368be84d",
   "metadata": {},
   "source": [
    "# Cross-Entropy Method (CEM) Planner\n",
    "\n",
    "> Planner using the Cross-Entropy Method (CEM) for optimization of discrete action sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ea932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp planners.cem_planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f4e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd474d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmed/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export \n",
    "from fastcore.utils import *\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import os\n",
    "from mawm.data.utils import base_tf, msg_tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f9a239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmed/Ahmed-home/1- Projects/Research/Journal 2/Code/mawm/mawm/envs/marl_grid/__init__.py:1: SyntaxWarning: invalid escape sequence '\\_'\n",
      "  \"\"\"Acts as module \\__init__ for MarlGrid envs creation\"\"\"\n",
      "/home/ahmed/miniconda3/envs/marlgrid/lib/python3.12/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n",
      "/home/ahmed/Ahmed-home/1- Projects/Research/Journal 2/Code/mawm/mawm/envs/marl_grid/wrappers.py:1: SyntaxWarning: invalid escape sequence '\\_'\n",
      "  \"\"\"Acts as module \\__init__ for MarlGrid envs creation  -->\"\"\"\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "from mawm.envs.marl_grid import make_env\n",
    "from mawm.envs.marl_grid.cfg import config\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "seed = np.random.randint(0, 10000)\n",
    "cfg = copy.deepcopy(config)\n",
    "cfg.env_cfg.seed = int(seed)\n",
    "cfg.env_cfg.max_steps = 512\n",
    "\n",
    "env = make_env(cfg.env_cfg)\n",
    "agents = [f\"agent_{i}\" for i in range(cfg.env_cfg.num_agents)]\n",
    "obs = env.reset()\n",
    "goal_pos = obs[\"global\"][\"goal_pos\"]\n",
    "goal_obs = np.array([\n",
    "    env.get_goal(env.agents[i], goal_pos)[0]\n",
    "    for i in range(config.env_cfg.num_agents)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e174bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, cfg.env_cfg.num_agents)\n",
    "for i in range(cfg.env_cfg.num_agents):\n",
    "    ax[i].imshow(goal_obs[i])\n",
    "    ax[i].set_title(f\"Agent {i} Goal Observation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50d0ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 42, 42, 3)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "goal_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd025d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from mawm.data.utils import base_tf, msg_tf\n",
    "import torch\n",
    "def preprocessor(obs):\n",
    "    obs = torch.stack([base_tf(obs[i].astype(np.uint8)) for i in range(len(obs))])\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669d8799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 42, 42])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "import torch\n",
    "from mawm.data.utils import base_tf, msg_tf\n",
    "goals = torch.stack([base_tf(goal_obs[i].astype(np.uint8)) for i in range(len(goal_obs))])\n",
    "goals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1564f23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "from mawm.models.jepa import JEPA\n",
    "from omegaconf import OmegaConf\n",
    "cfg = OmegaConf.load(\"../cfgs/MPCJepa/mpc.yaml\")\n",
    "model = JEPA(cfg.model, input_dim=(3, 42, 42), action_dim=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af1a62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 15, 15])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "import torch\n",
    "encoded_goals = model.backbone(goals)\n",
    "encoded_goals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b2771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pov', 'selfpos', 'orientation', 'identity'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "obs['agent_0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5c6cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "obs = env.reset()\n",
    "goal_obs = np.array([\n",
    "    env.get_goal(env.agents[i], goal_pos)[0]\n",
    "    for i in range(config.env_cfg.num_agents)\n",
    "])\n",
    "goals = torch.stack([base_tf(goal_obs[i].astype(np.uint8)) for i in range(len(goal_obs))])\n",
    "encoded_goals = model.backbone(goals)\n",
    "\n",
    "msgs = {agent: msg_tf((obs[agent]['pov'], agent, False, True)) for agent in agents}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69c2f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42, 42, 3), torch.Size([5, 7, 7]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "obs['agent_0']['pov'].astype(np.uint8).shape,  msgs['agent_0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe034eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "from mawm.data.utils import plot_grid\n",
    "plot_grid(obs['agent_0']['pov'].astype(np.uint8), msgs['agent_0'].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe77daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 15, 15])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "obs_transformed = torch.stack([base_tf(obs[agent]['pov'].astype(np.uint8)) for agent in agents])\n",
    "encoded_obs = model.backbone(obs_transformed)\n",
    "encoded_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43db6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "pos = torch.stack([torch.from_numpy(obs[agent]['selfpos']) for agent in agents])\n",
    "pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04b2c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 15, 15])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "encoded_obs = model.backbone(obs_transformed, position=None)\n",
    "encoded_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db52b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 15, 15)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "model.backbone.repr_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a12a34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 15, 15])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "encoded_goals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2187d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from mawm.models.misc import ObsPred, MsgPred\n",
    "from mawm.models.comm import MSGEnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256af2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "obs_pred = ObsPred(h_dim=32, out_channels=16)\n",
    "msg_pred = MsgPred(h_dim=32, in_channels=16)\n",
    "msg_encoder = MSGEnc(latent_dim=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5790dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# from mawm.models.utils import Expander2D\n",
    "# class CEMPlanner:\n",
    "#     def __init__(self, model, msg_enc, msg_pred, obs_pred, \n",
    "#                  action_dim= 5, horizon= 10, num_samples= 1000,\n",
    "#                  num_elites=100, opt_steps=100):\n",
    "        \n",
    "#         self.probs = torch.full((horizon, action_dim), 1.0/action_dim) # Uniform initial distribution of shape [Horizon, Action_Dim]\n",
    "#         self.model = model\n",
    "#         self.msg_enc = msg_enc\n",
    "#         self.msg_pred = msg_pred\n",
    "#         self.obs_pred = obs_pred\n",
    "#         self.action_dim = action_dim\n",
    "#         self.horizon = horizon\n",
    "#         self.num_samples = num_samples\n",
    "#         self.num_elites = num_elites\n",
    "#         self.opt_steps = opt_steps\n",
    "#         self.device = 'cpu'\n",
    "        \n",
    "\n",
    "#     def update_dist(self, probs, samples, costs, num_elites=50):\n",
    "\n",
    "#         values, elite_indices = torch.topk(-costs, num_elites)\n",
    "#         elites = samples[elite_indices] # [num_elites, Horizon]\n",
    "        \n",
    "#         # Update probabilities for the next round\n",
    "#         new_probs = torch.full_like(probs, 0.01 / probs.shape[-1])\n",
    "#         for t in range(probs.shape[0]):\n",
    "#             new_probs[t].scatter_add_(0, elites[:, t], torch.ones(num_elites) * (0.99 / num_elites))\n",
    "        \n",
    "#         best_plan = elites[0]\n",
    "        \n",
    "#         return new_probs, best_plan\n",
    "\n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def plan(self, o_t, pos_t, o_g, m_other, other_actions):\n",
    "#         z_t  = self.model.backbone(o_t.unsqueeze(0)) # [B=1, C, H, W] => [1, 16, 15, 15] #, position= pos_t.unsqueeze(0)\n",
    "#         pos_t = Expander2D(z_t.shape[-1], z_t.shape[-2])(pos_t.unsqueeze(0)) # [1, 2, 15, 15]\n",
    "#         z_t = torch.cat([z_t, pos_t], dim=1) # [1, 18, 15, 15]\n",
    "#         z_g = self.model.backbone(o_g.unsqueeze(0)) # [B=1, C, H, W] => [1, 16, 15, 15]\n",
    "\n",
    "#         a_self = torch.multinomial(self.probs, self.num_samples, replacement=True).T # [num_samples, horizon] \n",
    "        \n",
    "#         h0_other = self.msg_enc(m_other.unsqueeze(0).unsqueeze(1)) # [5, 7, 7] => [1, 1, 32]\n",
    "#         a_other = other_actions.repeat(self.num_samples, 1) # [num_samples, horizon]\n",
    "\n",
    "#         total_costs = self.evolve(z_t, z_g, h0_other, a_self, a_other)\n",
    "#         self.probs, best_plan = self.update_dist(self.probs, a_self, total_costs, self.num_elites)\n",
    "#         return best_plan\n",
    "\n",
    "#     def evolve(self, z_t, z_goal, h0_other, a_self, a_other):\n",
    "#         S = self.num_samples\n",
    "\n",
    "#         curr_z_self = repeat(z_t, 'b c h w -> (b s) t c h w', b= 1, s=S, t= 1) # [s, t= 1, c=18, h=15, w=15]\n",
    "#         curr_h_other = repeat(h0_other, 'b t d -> s t (b d)', s=S) # [s, 1, 32]\n",
    "        \n",
    "#         curr_z_other = self.obs_pred(curr_h_other)#[s, 1, 16, 15, 15]  \n",
    "#         curr_h_self = self.msg_pred(curr_z_self[:, :, :-2]) #[s, 1, 32]\n",
    "\n",
    "#         curr_z_self = rearrange(curr_z_self, \"s t c h w -> (t s) c h w\", t= 1)\n",
    "#         curr_z_other = rearrange(curr_z_other, \"s t c h w -> (t s) c h w\", t= 1)\n",
    "\n",
    "#         total_cost = torch.zeros(S, device=self.device)\n",
    "#         # import pdb; pdb.set_trace()\n",
    "#         for t in range(self.horizon):\n",
    "            \n",
    "#             curr_h_other = rearrange(curr_h_other, \"s t d -> (t s) d\", t= 1)\n",
    "#             curr_h_self = rearrange(curr_h_self, \"s t d -> (t s) d\", t= 1)\n",
    "\n",
    "#             a_self_t = a_self[:, t].unsqueeze(1) # [1 500]\n",
    "#             a_other_t = a_other[:, t].unsqueeze(1) # [1, 500]\n",
    "            \n",
    "\n",
    "#             next_z_self = self.model.dynamics.forward(current_state = curr_z_self, curr_action= a_self_t, curr_msg= curr_h_other)\n",
    "#             next_z_other = self.model.dynamics.forward(current_state = curr_z_other, curr_action= a_other_t, curr_msg= curr_h_self)\n",
    "\n",
    "#             next_h_self = self.msg_pred(rearrange(next_z_self[:, :-2], '(s t) c h w -> s t c h w ', t= 1))\n",
    "#             next_h_other = self.msg_pred(rearrange(next_z_other[:, :-2], '(s t) c h w -> s t c h w ', t= 1))\n",
    "\n",
    "#             total_cost += (next_z_self[:, :-2] - z_goal.unsqueeze(1)).pow(2).mean(dim=(2, 3, 4)).squeeze()\n",
    "\n",
    "#             curr_z_self, curr_z_other = next_z_self, next_z_other\n",
    "#             curr_h_self, curr_h_other = next_h_self, next_h_other\n",
    "\n",
    "#         return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bfe86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# from mawm.models.utils import Expander2D\n",
    "# import torch\n",
    "# from einops import repeat, rearrange\n",
    "\n",
    "# class CEMPlanner:\n",
    "#     def __init__(self, model, msg_enc, msg_pred, obs_pred, \n",
    "#                  action_dim=5, horizon=10, num_samples=1000,\n",
    "#                  num_elites=100, opt_steps=10): # Reduced opt_steps for speed, adjust as needed\n",
    "        \n",
    "#         self.model = model\n",
    "#         self.msg_enc = msg_enc\n",
    "#         self.msg_pred = msg_pred\n",
    "#         self.obs_pred = obs_pred\n",
    "#         self.action_dim = action_dim\n",
    "#         self.horizon = horizon\n",
    "#         self.num_samples = num_samples\n",
    "#         self.num_elites = num_elites\n",
    "#         self.opt_steps = opt_steps\n",
    "#         self.device = 'cpu'\n",
    "        \n",
    "#     def update_dist(self, probs, samples, costs, num_elites):\n",
    "#         # Find indices of samples with the lowest cost\n",
    "#         # topk on negative costs gives us the minimum values\n",
    "#         _, elite_indices = torch.topk(-costs, num_elites)\n",
    "#         elites = samples[elite_indices] # [num_elites, horizon]\n",
    "        \n",
    "#         # Create a fresh probability distribution based on elite actions\n",
    "#         new_probs = torch.zeros_like(probs)\n",
    "#         for t in range(self.horizon):\n",
    "#             # Count how often each action appeared in the elite set at time t\n",
    "#             counts = torch.bincount(elites[:, t], minlength=self.action_dim).float()\n",
    "#             new_probs[t] = counts / num_elites\n",
    "        \n",
    "#         # Apply smoothing (Laplace smoothing) to prevent 0-probability actions\n",
    "#         # This keeps the distribution \"open\" for the next opt_step\n",
    "#         epsilon = 0.01\n",
    "#         new_probs = (1 - epsilon) * new_probs + (epsilon / self.action_dim)\n",
    "        \n",
    "#         best_plan = elites[0]\n",
    "#         return new_probs, best_plan\n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def plan(self, o_t, pos_t, o_g, m_other, other_actions):\n",
    "#         # 1. INITIALIZE: Reset distribution to uniform at the start of every plan call\n",
    "#         # This ensures we don't carry over bias from previous environment steps.\n",
    "#         current_probs = torch.full((self.horizon, self.action_dim), 1.0/self.action_dim, device=self.device)\n",
    "\n",
    "#         # 2. ENCODE: Prepare latent states once\n",
    "#         z_t = self.model.backbone(o_t.unsqueeze(0)) \n",
    "#         pos_t_expanded = Expander2D(z_t.shape[-1], z_t.shape[-2])(pos_t.unsqueeze(0))\n",
    "#         z_t = torch.cat([z_t, pos_t_expanded], dim=1) \n",
    "#         z_g = self.model.backbone(o_g.unsqueeze(0)) \n",
    "        \n",
    "#         h0_other = self.msg_enc(m_other.unsqueeze(0).unsqueeze(1)) \n",
    "#         # The other agent's plan is treated as a fixed anchor for this optimization cycle\n",
    "#         a_other = other_actions.repeat(self.num_samples, 1) \n",
    "\n",
    "#         # 3. OPTIMIZE: The CEM Loop (Step 'f' in your paper)\n",
    "#         best_plan = None\n",
    "#         for _ in range(self.opt_steps):\n",
    "#             # Sample sequences from current distribution\n",
    "#             # Shape: [num_samples, horizon]\n",
    "#             a_self = torch.multinomial(current_probs, self.num_samples, replacement=True).T \n",
    "            \n",
    "#             # Evaluate samples using the world model\n",
    "#             total_costs = self.evolve(z_t, z_g, h0_other, a_self, a_other)\n",
    "            \n",
    "#             # Update the distribution to focus on low-cost regions\n",
    "#             current_probs, best_plan = self.update_dist(current_probs, a_self, total_costs, self.num_elites)\n",
    "\n",
    "#         return best_plan\n",
    "\n",
    "#     def evolve(self, z_t, z_goal, h0_other, a_self, a_other):\n",
    "#         S = self.num_samples\n",
    "#         # ... (Your existing evolve logic remains the same) ...\n",
    "#         curr_z_self = repeat(z_t, 'b c h w -> (b s) t c h w', b= 1, s=S, t= 1)\n",
    "#         curr_h_other = repeat(h0_other, 'b t d -> s t (b d)', s=S)\n",
    "        \n",
    "#         curr_z_other = self.obs_pred(curr_h_other)  \n",
    "#         curr_h_self = self.msg_pred(curr_z_self[:, :, :-2]) \n",
    "\n",
    "#         curr_z_self = rearrange(curr_z_self, \"s t c h w -> (t s) c h w\", t= 1)\n",
    "#         curr_z_other = rearrange(curr_z_other, \"s t c h w -> (t s) c h w\", t= 1)\n",
    "\n",
    "#         total_cost = torch.zeros(S, device=self.device)\n",
    "        \n",
    "#         for t in range(self.horizon):\n",
    "#             curr_h_other = rearrange(curr_h_other, \"s t d -> (t s) d\", t= 1)\n",
    "#             curr_h_self = rearrange(curr_h_self, \"s t d -> (t s) d\", t= 1)\n",
    "\n",
    "#             a_self_t = a_self[:, t].unsqueeze(1) \n",
    "#             a_other_t = a_other[:, t].unsqueeze(1) \n",
    "            \n",
    "#             next_z_self = self.model.dynamics.forward(current_state=curr_z_self, curr_action=a_self_t, curr_msg=curr_h_other)\n",
    "#             next_z_other = self.model.dynamics.forward(current_state=curr_z_other, curr_action=a_other_t, curr_msg=curr_h_self)\n",
    "\n",
    "#             next_h_self = self.msg_pred(rearrange(next_z_self[:, :-2], '(s t) c h w -> s t c h w ', t= 1))\n",
    "#             next_h_other = self.msg_pred(rearrange(next_z_other[:, :-2], '(s t) c h w -> s t c h w ', t= 1))\n",
    "\n",
    "#             # Cost calculation: MSE to goal\n",
    "#             total_cost += (next_z_self[:, :-2] - z_goal).pow(2).mean(dim=(1, 2, 3))\n",
    "\n",
    "#             curr_z_self, curr_z_other = next_z_self, next_z_other\n",
    "#             curr_h_self, curr_h_other = next_h_self, next_h_other\n",
    "\n",
    "#         return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a2811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# from mawm.models.utils import Expander2D\n",
    "# import torch\n",
    "# from einops import repeat, rearrange\n",
    "\n",
    "# class CEMPlanner:\n",
    "#     def __init__(self, model, msg_enc, msg_pred, obs_pred, \n",
    "#                  action_dim=5, horizon=10, num_samples=1000,\n",
    "#                  num_elites=100, opt_steps=10):\n",
    "        \n",
    "#         self.model = model\n",
    "#         self.msg_enc = msg_enc\n",
    "#         self.msg_pred = msg_pred\n",
    "#         self.obs_pred = obs_pred\n",
    "#         self.action_dim = action_dim # Number of discrete choices (0-4)\n",
    "#         self.horizon = horizon\n",
    "#         self.num_samples = num_samples\n",
    "#         self.num_elites = num_elites\n",
    "#         self.opt_steps = opt_steps\n",
    "#         self.device = 'cpu'\n",
    "        \n",
    "#     def update_dist(self, probs, samples, costs, num_elites):\n",
    "#         # We want to MINIMIZE cost, so we take the topk of negative costs\n",
    "#         _, elite_indices = torch.topk(-costs, num_elites)\n",
    "#         elites = samples[elite_indices] # [num_elites, horizon]\n",
    "        \n",
    "#         new_probs = torch.zeros_like(probs)\n",
    "#         for t in range(self.horizon):\n",
    "#             counts = torch.bincount(elites[:, t], minlength=self.action_dim).float()\n",
    "#             new_probs[t] = counts / num_elites\n",
    "        \n",
    "#         # Laplace smoothing to ensure we always have some exploration noise\n",
    "#         epsilon = 0.01\n",
    "#         new_probs = (1 - epsilon) * new_probs + (epsilon / self.action_dim)\n",
    "        \n",
    "#         return new_probs, elites[0]\n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def plan(self, o_t, pos_t, o_g, m_other, other_actions):\n",
    "#         # RESET: Start fresh so we don't get stuck in a local minimum from the last step\n",
    "#         current_probs = torch.full((self.horizon, self.action_dim), 1.0/self.action_dim, device=self.device)\n",
    "\n",
    "#         z_t = self.model.backbone(o_t.unsqueeze(0)) \n",
    "#         pos_t_expanded = Expander2D(z_t.shape[-1], z_t.shape[-2])(pos_t.unsqueeze(0))\n",
    "#         z_t = torch.cat([z_t, pos_t_expanded], dim=1) \n",
    "#         z_g = self.model.backbone(o_g.unsqueeze(0)) \n",
    "        \n",
    "#         h0_other = self.msg_enc(m_other.unsqueeze(0).unsqueeze(1)) \n",
    "#         a_other = other_actions.repeat(self.num_samples, 1) \n",
    "\n",
    "#         best_plan = None\n",
    "#         for i in range(self.opt_steps):\n",
    "#             # Sample sequences: [num_samples, horizon]\n",
    "#             a_self = torch.multinomial(current_probs, self.num_samples, replacement=True).T \n",
    "            \n",
    "#             total_costs = self.evolve(z_t, z_g, h0_other, a_self, a_other)\n",
    "            \n",
    "#             # DEBUG: Uncomment this to see if costs are actually changing\n",
    "#             if i == 0: print(f\"Cost Std: {total_costs.std():.6f}, Min: {total_costs.min():.4f}\")\n",
    "\n",
    "#             current_probs, best_plan = self.update_dist(current_probs, a_self, total_costs, self.num_elites)\n",
    "\n",
    "#         return best_plan\n",
    "\n",
    "#     def evolve(self, z_t, z_goal, h0_other, a_self, a_other):\n",
    "#         S = self.num_samples\n",
    "        \n",
    "#         # Ensure z_goal is ready for broadcasting: [1, C, H, W]\n",
    "#         # We strip the last 2 channels if your goal doesn't include the pos_t expansion\n",
    "#         z_goal_target = z_goal \n",
    "\n",
    "#         curr_z_self = repeat(z_t, 'b c h w -> (b s) c h w', s=S)\n",
    "#         curr_h_other = repeat(h0_other, 'b t d -> (s b t) d', s=S)\n",
    "        \n",
    "#         # Initial imagined states for the other agent\n",
    "#         curr_z_other = rearrange(self.obs_pred(curr_h_other.unsqueeze(1)), \"s t c h w -> (s t) c h w\")\n",
    "#         curr_h_self = self.msg_pred(curr_z_self[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "\n",
    "#         total_cost = torch.zeros(S, device=self.device)\n",
    "        \n",
    "#         for t in range(self.horizon):\n",
    "#             a_self_t = a_self[:, t].unsqueeze(1) # [S, 1]\n",
    "#             a_other_t = a_other[:, t].unsqueeze(1) # [S, 1]\n",
    "            \n",
    "#             # Forward dynamics\n",
    "#             next_z_self = self.model.dynamics.forward(current_state=curr_z_self, curr_action=a_self_t, curr_msg=curr_h_other)\n",
    "#             next_z_other = self.model.dynamics.forward(current_state=curr_z_other, curr_action=a_other_t, curr_msg=curr_h_self)\n",
    "\n",
    "#             # Predict next messages\n",
    "#             curr_h_self = self.msg_pred(next_z_self[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "#             curr_h_other = self.msg_pred(next_z_other[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "\n",
    "#             # --- CRITICAL: Cost calculation ---\n",
    "#             # Compare only the latent state (excluding position channels if necessary)\n",
    "#             # next_z_self[:, :-2] is [S, 16, 15, 15]\n",
    "#             # z_goal_target is [1, 16, 15, 15]\n",
    "#             diff = next_z_self[:, :-2] - z_goal_target\n",
    "            \n",
    "#             # Step-wise cost (MSE)\n",
    "#             total_cost += diff.pow(2).mean(dim=(1, 2, 3))\n",
    "\n",
    "#             curr_z_self, curr_z_other = next_z_self, next_z_other\n",
    "\n",
    "#         return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bf002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# import torch\n",
    "# from einops import repeat, rearrange\n",
    "# from mawm.models.utils import Expander2D\n",
    "\n",
    "# class CEMPlanner:\n",
    "#     def __init__(self, model, msg_enc, msg_pred, obs_pred, \n",
    "#                  action_dim=5, horizon=10, num_samples=1000,\n",
    "#                  num_elites=100, opt_steps=10, device='cpu'):\n",
    "        \n",
    "#         self.model = model\n",
    "#         self.msg_enc = msg_enc\n",
    "#         self.msg_pred = msg_pred\n",
    "#         self.obs_pred = obs_pred\n",
    "#         self.action_dim = action_dim\n",
    "#         self.horizon = horizon\n",
    "#         self.num_samples = num_samples\n",
    "#         self.num_elites = num_elites\n",
    "#         self.opt_steps = opt_steps\n",
    "#         self.device = device\n",
    "        \n",
    "#         # Hyperparameters for improved stability\n",
    "#         self.alpha = 0.3  # Momentum for distribution update\n",
    "#         self.epsilon = 0.01  # Laplace smoothing\n",
    "#         self.temp_start = 1.0  # Initial temperature\n",
    "#         self.temp_end = 0.5  # Final temperature\n",
    "        \n",
    "#     def update_dist(self, probs, samples, costs, num_elites, iteration):\n",
    "#         \"\"\"Update probability distribution using elite samples with momentum.\"\"\"\n",
    "#         # Select elites (minimize cost)\n",
    "#         _, elite_indices = torch.topk(-costs, num_elites)\n",
    "#         elites = samples[elite_indices]\n",
    "        \n",
    "#         # Compute empirical distribution from elites\n",
    "#         empirical_probs = torch.zeros_like(probs)\n",
    "#         for t in range(self.horizon):\n",
    "#             counts = torch.bincount(elites[:, t], minlength=self.action_dim).float()\n",
    "#             empirical_probs[t] = counts / num_elites\n",
    "        \n",
    "#         # Momentum update for stability\n",
    "#         new_probs = self.alpha * empirical_probs + (1 - self.alpha) * probs\n",
    "        \n",
    "#         # Laplace smoothing\n",
    "#         new_probs = (1 - self.epsilon) * new_probs + (self.epsilon / self.action_dim)\n",
    "        \n",
    "#         # Temperature annealing for sharpening\n",
    "#         temp = self.temp_start + (self.temp_end - self.temp_start) * (iteration / self.opt_steps)\n",
    "#         new_probs = new_probs ** (1 / temp)\n",
    "#         new_probs = new_probs / new_probs.sum(dim=1, keepdim=True)\n",
    "        \n",
    "#         return new_probs, elites[0]\n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def plan(self, o_t, o_g, pos_t, m_other, other_actions):\n",
    "#         \"\"\"Plan action sequence using CEM.\"\"\"\n",
    "#         # Move inputs to device\n",
    "#         o_t = o_t.to(self.device)\n",
    "#         o_g = o_g.to(self.device)\n",
    "#         pos_t = pos_t.to(self.device)\n",
    "#         m_other = m_other.to(self.device)\n",
    "#         other_actions = other_actions.to(self.device)\n",
    "        \n",
    "#         # Initialize uniform distribution\n",
    "#         current_probs = torch.full(\n",
    "#             (self.horizon, self.action_dim), \n",
    "#             1.0 / self.action_dim, \n",
    "#             device=self.device\n",
    "#         )\n",
    "\n",
    "#         # Encode current state and goal\n",
    "#         z_t = self.model.backbone(o_t.unsqueeze(0))\n",
    "#         pos_t_expanded = Expander2D(z_t.shape[-1], z_t.shape[-2])(pos_t.unsqueeze(0))\n",
    "#         z_t = torch.cat([z_t, pos_t_expanded], dim=1)\n",
    "        \n",
    "#         z_g = self.model.backbone(o_g.unsqueeze(0))\n",
    "#         # Match dimensions with cost calculation (exclude position channels)\n",
    "#         z_goal_target = z_g#[:, :-2]\n",
    "        \n",
    "#         # Encode other agent's message\n",
    "#         h0_other = self.msg_enc(m_other.unsqueeze(0).unsqueeze(1))\n",
    "#         a_other = other_actions.repeat(self.num_samples, 1)\n",
    "\n",
    "#         best_plan = None\n",
    "#         best_cost = float('inf')\n",
    "        \n",
    "#         for i in range(self.opt_steps):\n",
    "#             # Sample action sequences\n",
    "#             a_self = torch.multinomial(\n",
    "#                 current_probs, \n",
    "#                 self.num_samples, \n",
    "#                 replacement=True\n",
    "#             ).T.to(self.device)\n",
    "            \n",
    "#             # Evaluate sampled sequences\n",
    "#             total_costs = self.evolve(z_t, z_goal_target, h0_other, a_self, a_other)\n",
    "            \n",
    "#             # Track best solution\n",
    "#             min_cost = total_costs.min()\n",
    "#             if min_cost < best_cost:\n",
    "#                 best_cost = min_cost\n",
    "#                 best_idx = total_costs.argmin()\n",
    "#                 best_plan = a_self[best_idx]\n",
    "            \n",
    "#             # Debug info\n",
    "#             if i == 0 or i == self.opt_steps - 1:\n",
    "#                 print(f\"Iter {i}: Cost ={total_costs.mean():.4f}, \"\n",
    "#                       f\"Std={total_costs.std():.4f}, min={min_cost:.4f}\")\n",
    "\n",
    "#             # Update distribution\n",
    "#             current_probs, _ = self.update_dist(\n",
    "#                 current_probs, a_self, total_costs, self.num_elites, i\n",
    "#             )\n",
    "\n",
    "#         return best_plan\n",
    "\n",
    "#     def evolve(self, z_t, z_goal, h0_other, a_self, a_other):\n",
    "#         \"\"\"Roll out trajectories and compute costs.\"\"\"\n",
    "#         S = self.num_samples\n",
    "        \n",
    "#         # Initialize states\n",
    "#         curr_z_self = repeat(z_t, 'b c h w -> (b s) c h w', s=S)\n",
    "#         curr_h_other = repeat(h0_other, 'b t d -> (s b t) d', s=S)\n",
    "        \n",
    "#         curr_z_other = rearrange(\n",
    "#             self.obs_pred(curr_h_other.unsqueeze(1)), \n",
    "#             \"s t c h w -> (s t) c h w\"\n",
    "#         )\n",
    "#         curr_h_self = self.msg_pred(curr_z_self[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "\n",
    "#         total_cost = torch.zeros(S, device=self.device)\n",
    "        \n",
    "#         # Roll out trajectories\n",
    "#         for t in range(self.horizon):\n",
    "#             a_self_t = a_self[:, t].unsqueeze(1)\n",
    "#             a_other_t = a_other[:, t].unsqueeze(1)\n",
    "            \n",
    "#             # Forward dynamics\n",
    "#             next_z_self = self.model.dynamics.forward(\n",
    "#                 current_state=curr_z_self, \n",
    "#                 curr_action=a_self_t, \n",
    "#                 curr_msg=curr_h_other\n",
    "#             )\n",
    "#             next_z_other = self.model.dynamics.forward(\n",
    "#                 current_state=curr_z_other, \n",
    "#                 curr_action=a_other_t, \n",
    "#                 curr_msg=curr_h_self\n",
    "#             )\n",
    "\n",
    "#             # Update messages\n",
    "#             curr_h_self = self.msg_pred(next_z_self[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "#             curr_h_other = self.msg_pred(next_z_other[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "\n",
    "#             # Compute step cost (MSE to goal)\n",
    "#             diff = next_z_self[:, :-2] - z_goal\n",
    "#             step_cost = diff.pow(2).mean(dim=(1, 2, 3))\n",
    "            \n",
    "#             # Weight final timestep more heavily\n",
    "#             weight = 2.0 if t == self.horizon - 1 else 1.0\n",
    "#             total_cost += weight * step_cost\n",
    "\n",
    "#             curr_z_self, curr_z_other = next_z_self, next_z_other\n",
    "\n",
    "#         return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900c5bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from einops import repeat, rearrange\n",
    "from mawm.models.utils import Expander2D\n",
    "\n",
    "class CEMPlanner:\n",
    "    def __init__(self, model, msg_enc, msg_pred, obs_pred, \n",
    "                 action_dim=5, horizon=10, num_samples=1000,\n",
    "                 num_elites=100, opt_steps=10, device='cpu'):\n",
    "        \n",
    "        self.model = model\n",
    "        self.msg_enc = msg_enc\n",
    "        self.msg_pred = msg_pred\n",
    "        self.obs_pred = obs_pred\n",
    "        self.action_dim = action_dim\n",
    "        self.horizon = horizon\n",
    "        self.num_samples = num_samples\n",
    "        self.num_elites = num_elites\n",
    "        self.opt_steps = opt_steps\n",
    "        self.device = device\n",
    "        \n",
    "        # CRITICAL FIXES for premature convergence\n",
    "        self.alpha = 0.7  # HIGH momentum (was implicit 0, now 0.7)\n",
    "        self.epsilon = 0.1  # MUCH higher smoothing (was 0.01)\n",
    "        self.temperature_schedule = torch.linspace(1.5, 0.8, opt_steps)  # Start hot, cool down\n",
    "        \n",
    "    def update_dist(self, probs, samples, costs, num_elites, iteration):\n",
    "        \"\"\"Update with momentum and temperature to prevent collapse.\"\"\"\n",
    "        _, elite_indices = torch.topk(-costs, num_elites)\n",
    "        elites = samples[elite_indices]\n",
    "        \n",
    "        # Compute empirical elite distribution\n",
    "        empirical_probs = torch.zeros_like(probs)\n",
    "        for t in range(self.horizon):\n",
    "            counts = torch.bincount(elites[:, t], minlength=self.action_dim).float()\n",
    "            empirical_probs[t] = counts / num_elites\n",
    "        \n",
    "        # CRITICAL FIX 1: Strong momentum (keep 70% of old distribution)\n",
    "        new_probs = self.alpha * probs + (1 - self.alpha) * empirical_probs\n",
    "        \n",
    "        # CRITICAL FIX 2: Higher exploration noise\n",
    "        new_probs = (1 - self.epsilon) * new_probs + (self.epsilon / self.action_dim)\n",
    "        \n",
    "        # CRITICAL FIX 3: Temperature annealing (starts at 1.5, ends at 0.8)\n",
    "        temperature = self.temperature_schedule[iteration]\n",
    "        new_probs = new_probs ** (1.0 / temperature)\n",
    "        new_probs = new_probs / new_probs.sum(dim=1, keepdim=True)\n",
    "        \n",
    "        return new_probs, elites[0]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def plan(self, o_t, pos_t, o_g, m_other, other_actions):\n",
    "\n",
    "        o_t = o_t.to(self.device)\n",
    "        o_g = o_g.to(self.device)\n",
    "        pos_t = pos_t.to(self.device)\n",
    "        m_other = m_other.to(self.device)\n",
    "        other_actions = other_actions.to(self.device)\n",
    "        # Initialize uniform\n",
    "        current_probs = torch.full(\n",
    "            (self.horizon, self.action_dim), \n",
    "            1.0/self.action_dim, \n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        z_t = self.model.backbone(o_t.unsqueeze(0)) \n",
    "        pos_t_expanded = Expander2D(z_t.shape[-1], z_t.shape[-2])(pos_t.unsqueeze(0))\n",
    "        z_t = torch.cat([z_t, pos_t_expanded], dim=1) \n",
    "        z_g = self.model.backbone(o_g.unsqueeze(0))\n",
    "        \n",
    "        # Match dimensions\n",
    "        z_goal_target = z_g[:, :-2] if z_g.shape[1] > 16 else z_g\n",
    "        \n",
    "        h0_other = self.msg_enc(m_other.unsqueeze(0).unsqueeze(1)) \n",
    "        a_other = other_actions.repeat(self.num_samples, 1) \n",
    "\n",
    "        best_plan = None\n",
    "        best_cost = float('inf')\n",
    "        \n",
    "        for i in range(self.opt_steps):\n",
    "            a_self = torch.multinomial(current_probs, self.num_samples, replacement=True).T \n",
    "            \n",
    "            total_costs = self.evolve(z_t, z_goal_target, h0_other, a_self, a_other)\n",
    "            \n",
    "            # Track best\n",
    "            if total_costs.min() < best_cost:\n",
    "                best_cost = total_costs.min()\n",
    "                best_plan = a_self[total_costs.argmin()]\n",
    "            \n",
    "            # Debug output (keep your existing format)\n",
    "            if i == 0 or i == self.opt_steps - 1:\n",
    "                print(f\"Iter {i}: Cost ={total_costs.mean():.4f}, \"\n",
    "                      f\"Std={total_costs.std():.4f}, min={total_costs.min():.4f}\")\n",
    "            \n",
    "            current_probs, _ = self.update_dist(current_probs, a_self, total_costs, self.num_elites, i)\n",
    "            \n",
    "            # OPTIONAL: Debug action diversity\n",
    "            if i == self.opt_steps - 1:\n",
    "                action_dist = current_probs[0].cpu().numpy()\n",
    "                print(f\"Final action probs: {action_dist.round(3)}\")\n",
    "\n",
    "        return best_plan\n",
    "\n",
    "    def evolve(self, z_t, z_goal, h0_other, a_self, a_other):\n",
    "        S = self.num_samples\n",
    "        z_goal_target = z_goal \n",
    "\n",
    "        curr_z_self = repeat(z_t, 'b c h w -> (b s) c h w', s=S)\n",
    "        curr_h_other = repeat(h0_other, 'b t d -> (s b t) d', s=S)\n",
    "        \n",
    "        curr_z_other = rearrange(self.obs_pred(curr_h_other.unsqueeze(1)), \"s t c h w -> (s t) c h w\")\n",
    "        curr_h_self = self.msg_pred(curr_z_self[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        total_cost = torch.zeros(S, device=self.device)\n",
    "        \n",
    "        for t in range(self.horizon):\n",
    "            a_self_t = a_self[:, t].unsqueeze(1)\n",
    "            a_other_t = a_other[:, t].unsqueeze(1)\n",
    "            \n",
    "            next_z_self = self.model.dynamics.forward(\n",
    "                current_state=curr_z_self, \n",
    "                curr_action=a_self_t, \n",
    "                curr_msg=curr_h_other\n",
    "            )\n",
    "            next_z_other = self.model.dynamics.forward(\n",
    "                current_state=curr_z_other, \n",
    "                curr_action=a_other_t, \n",
    "                curr_msg=curr_h_self\n",
    "            )\n",
    "\n",
    "            curr_h_self = self.msg_pred(next_z_self[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "            curr_h_other = self.msg_pred(next_z_other[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "\n",
    "            diff = next_z_self[:, :-2] - z_goal_target\n",
    "            \n",
    "            # OPTIONAL FIX: Weight final timestep more if you want goal-seeking behavior\n",
    "            weight = 3.0 if t == self.horizon - 1 else 1.0\n",
    "            total_cost += weight * diff.pow(2).mean(dim=(1, 2, 3))\n",
    "\n",
    "            curr_z_self, curr_z_other = next_z_self, next_z_other\n",
    "\n",
    "        return total_cost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33cd258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "planner = CEMPlanner(model=model, msg_enc= msg_encoder, msg_pred=msg_pred, obs_pred=obs_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9672bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "torch.manual_seed(0)\n",
    "probs_j = torch.full((planner.horizon, planner.action_dim), 1.0/planner.action_dim)\n",
    "other_actions = torch.multinomial(probs_j, 1).squeeze(-1)  # [Horizon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa548c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 1, 2, 2, 4, 3, 4, 1, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009357a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# from einops import rearrange, repeat\n",
    "# planner.plan(obs_transformed[0], pos[0], o_g=goals[0], m_other=msgs['agent_0'], other_actions=other_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ece34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# ============================================\n",
    "# ALTERNATIVE: Boltzmann/Softmax CEM\n",
    "# ============================================\n",
    "# If the above doesn't work, try this version which uses\n",
    "# cost-weighted sampling instead of hard elite selection\n",
    "\n",
    "class CEMPlannerBoltzmann:\n",
    "    \"\"\"CEM with Boltzmann-weighted updates instead of hard elite selection.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, msg_enc, msg_pred, obs_pred, \n",
    "                 action_dim=5, horizon=10, num_samples=1000,\n",
    "                 opt_steps=10, device='cpu'):\n",
    "        \n",
    "        self.model = model\n",
    "        self.msg_enc = msg_enc\n",
    "        self.msg_pred = msg_pred\n",
    "        self.obs_pred = obs_pred\n",
    "        self.action_dim = action_dim\n",
    "        self.horizon = horizon\n",
    "        self.num_samples = num_samples\n",
    "        self.opt_steps = opt_steps\n",
    "        self.device = device\n",
    "        \n",
    "        self.alpha = 0.5\n",
    "        self.epsilon = 0.05\n",
    "        self.beta_schedule = torch.linspace(0.5, 5.0, opt_steps)  # Inverse temperature\n",
    "        \n",
    "    def update_dist(self, probs, samples, costs, iteration):\n",
    "        \"\"\"Use Boltzmann weighting instead of hard elite selection.\"\"\"\n",
    "        beta = self.beta_schedule[iteration]\n",
    "        \n",
    "        # Convert costs to weights (lower cost = higher weight)\n",
    "        weights = torch.softmax(-beta * costs, dim=0)\n",
    "        \n",
    "        # Weighted histogram\n",
    "        new_probs = torch.zeros_like(probs)\n",
    "        for t in range(self.horizon):\n",
    "            for a in range(self.action_dim):\n",
    "                mask = (samples[:, t] == a).float()\n",
    "                new_probs[t, a] = (weights * mask).sum()\n",
    "        \n",
    "        # Momentum\n",
    "        new_probs = self.alpha * probs + (1 - self.alpha) * new_probs\n",
    "        \n",
    "        # Smoothing\n",
    "        new_probs = (1 - self.epsilon) * new_probs + (self.epsilon / self.action_dim)\n",
    "        new_probs = new_probs / new_probs.sum(dim=1, keepdim=True)\n",
    "        \n",
    "        best_idx = costs.argmin()\n",
    "        return new_probs, samples[best_idx]\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def plan(self, o_t, pos_t, o_g, m_other, other_actions):\n",
    "\n",
    "        o_t = o_t.to(self.device)\n",
    "        o_g = o_g.to(self.device)\n",
    "        pos_t = pos_t.to(self.device)\n",
    "        m_other = m_other.to(self.device)\n",
    "        other_actions = other_actions.to(self.device)\n",
    "        \n",
    "        current_probs = torch.full(\n",
    "            (self.horizon, self.action_dim), \n",
    "            1.0/self.action_dim, \n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        z_t = self.model.backbone(o_t.unsqueeze(0)) \n",
    "        pos_t_expanded = Expander2D(z_t.shape[-1], z_t.shape[-2])(pos_t.unsqueeze(0))\n",
    "        z_t = torch.cat([z_t, pos_t_expanded], dim=1) \n",
    "        z_g = self.model.backbone(o_g.unsqueeze(0))\n",
    "        z_goal_target = z_g[:, :-2] if z_g.shape[1] > 16 else z_g\n",
    "        \n",
    "        h0_other = self.msg_enc(m_other.unsqueeze(0).unsqueeze(1)) \n",
    "        a_other = other_actions.repeat(self.num_samples, 1) \n",
    "\n",
    "        best_plan = None\n",
    "        \n",
    "        for i in range(self.opt_steps):\n",
    "            a_self = torch.multinomial(current_probs, self.num_samples, replacement=True).T \n",
    "            total_costs = self.evolve(z_t, z_goal_target, h0_other, a_self, a_other)\n",
    "            \n",
    "            if i == 0 or i == self.opt_steps - 1:\n",
    "                print(f\"Iter {i}: Cost ={total_costs.mean():.4f}, \"\n",
    "                      f\"Std={total_costs.std():.4f}, min={total_costs.min():.4f}\")\n",
    "            \n",
    "            current_probs, best_plan = self.update_dist(current_probs, a_self, total_costs, i)\n",
    "\n",
    "        return best_plan\n",
    "    \n",
    "    def evolve(self, z_t, z_goal, h0_other, a_self, a_other):\n",
    "        # Same as original\n",
    "        S = self.num_samples\n",
    "        curr_z_self = repeat(z_t, 'b c h w -> (b s) c h w', s=S)\n",
    "        curr_h_other = repeat(h0_other, 'b t d -> (s b t) d', s=S)\n",
    "        curr_z_other = rearrange(self.obs_pred(curr_h_other.unsqueeze(1)), \"s t c h w -> (s t) c h w\")\n",
    "        curr_h_self = self.msg_pred(curr_z_self[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "        total_cost = torch.zeros(S, device=self.device)\n",
    "        \n",
    "        for t in range(self.horizon):\n",
    "            a_self_t = a_self[:, t].unsqueeze(1)\n",
    "            a_other_t = a_other[:, t].unsqueeze(1)\n",
    "            next_z_self = self.model.dynamics.forward(current_state=curr_z_self, curr_action=a_self_t, curr_msg=curr_h_other)\n",
    "            next_z_other = self.model.dynamics.forward(current_state=curr_z_other, curr_action=a_other_t, curr_msg=curr_h_self)\n",
    "            curr_h_self = self.msg_pred(next_z_self[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "            curr_h_other = self.msg_pred(next_z_other[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "            diff = next_z_self[:, :-2] - z_goal\n",
    "            total_cost += diff.pow(2).mean(dim=(1, 2, 3))\n",
    "            curr_z_self, curr_z_other = next_z_self, next_z_other\n",
    "        \n",
    "        return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3f4ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "nbdev.nbdev_export() # type: ignore  # noqa: E702\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
