{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "368be84d",
   "metadata": {},
   "source": [
    "# Cross-Entropy Method (CEM) Planner\n",
    "\n",
    "> Planner using the Cross-Entropy Method (CEM) for optimization of discrete action sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ea932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp planners.cem_planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f4e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# from nbdev.showdoc import *  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd474d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "from fastcore.utils import *\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import os\n",
    "from mawm.data.utils import base_tf, msg_tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a640b5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "class DiscreteCEMPlanner():\n",
    "    def __init__(\n",
    "        self,\n",
    "        horizon,\n",
    "        topk,\n",
    "        num_samples,\n",
    "        opt_steps,\n",
    "        eval_every,\n",
    "        wm,\n",
    "        action_dim, # This is now the number of discrete actions\n",
    "        objective_fn,\n",
    "        preprocessor,\n",
    "        evaluator,\n",
    "        wandb_run,\n",
    "        smoothing=0.01, # Laplace smoothing constant\n",
    "        logging_prefix=\"plan_discrete\",\n",
    "        log_filename=\"logs.json\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            wm, action_dim, objective_fn, preprocessor, \n",
    "            evaluator, wandb_run, log_filename\n",
    "        )\n",
    "        self.horizon = horizon\n",
    "        self.topk = topk\n",
    "        self.num_samples = num_samples\n",
    "        self.opt_steps = opt_steps\n",
    "        self.eval_every = eval_every\n",
    "        self.smoothing = smoothing\n",
    "        self.logging_prefix = logging_prefix\n",
    "\n",
    "    def init_probs(self, obs_0):\n",
    "        \"\"\"Initializes a uniform distribution over actions for each timestep.\"\"\"\n",
    "        n_evals = obs_0[\"visual\"].shape[0]\n",
    "        # (Batch, Horizon, Num_Actions) - start with uniform probabilities\n",
    "        probs = torch.full((n_evals, self.horizon, self.action_dim), 1.0 / self.action_dim)\n",
    "        return probs\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea4a8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def plan(self: DiscreteCEMPlanner, obs_0, obs_g, actions=None):\n",
    "    self.probs = torch.full((self.horizon, self.action_dim), 1.0/self.action_dim).to(self.device)\n",
    "    trans_obs_0 = self.preprocessor(obs_0).to(self.device)\n",
    "    trans_obs_g = self.preprocessor(obs_g).to(self.device)\n",
    "    \n",
    "    z_obs_g = self.wm.backbone(trans_obs_g)\n",
    "    z_obs_g = {f\"goal_agent{i}\": v for i, v in enumerate(z_obs_g)}\n",
    "    \n",
    "    trans_obs_0 = {f\"agent{i}\": v for i, v in enumerate(trans_obs_0)}\n",
    "\n",
    "    msgs = {agent: msg_tf((obs_0[agent]['pov'], agent, False)) for agent in self.agents}\n",
    "\n",
    "    # Initialize probabilities\n",
    "    probs = self.init_probs(obs_0).to(self.device)\n",
    "    n_evals = probs.shape[0]\n",
    "\n",
    "    for i in range(self.opt_steps):\n",
    "        losses = []\n",
    "        for traj_idx in range(n_evals):\n",
    "            # 1. Prepare observations for the current trajectory batch\n",
    "            cur_trans_obs_0 = {\n",
    "                key: repeat(arr[traj_idx].unsqueeze(0), \"1 ... -> n ...\", n=self.num_samples)\n",
    "                for key, arr in trans_obs_0.items()\n",
    "            }\n",
    "            cur_z_obs_g = {\n",
    "                key: repeat(arr[traj_idx].unsqueeze(0), \"1 ... -> n ...\", n=self.num_samples)\n",
    "                for key, arr in z_obs_g.items()\n",
    "            }\n",
    "\n",
    "            # 2. Sample discrete actions from the current distribution\n",
    "            # We flatten to sample, then reshape back\n",
    "            p = probs[traj_idx] # (H, action_dim)\n",
    "            # Sample (num_samples) for each step in the horizon\n",
    "            sampled_indices = torch.multinomial(p, self.num_samples, replacement=True) \n",
    "            sampled_indices = sampled_indices.T # (num_samples, H)\n",
    "\n",
    "            # 3. Rollout in World Model\n",
    "            # Note: If your WM expects one-hot, convert sampled_indices here\n",
    "            with torch.no_grad():\n",
    "                # We pass sampled_indices (integers). Adjust if WM needs one-hot vectors.\n",
    "                i_z_obses, i_zs = self.wm.forward_multiple(\n",
    "                    obs_0=cur_trans_obs_0,\n",
    "                    act=sampled_indices, \n",
    "                )\n",
    "\n",
    "            # 4. Evaluate and find Elites\n",
    "            loss = self.objective_fn(i_z_obses, cur_z_obs_g)\n",
    "            topk_idx = torch.argsort(loss)[: self.topk]\n",
    "            elite_actions = sampled_indices[topk_idx] # (topk, H)\n",
    "\n",
    "            # 5. Update Distribution (Frequency Counting)\n",
    "            # Convert elite actions to one-hot: (topk, H, action_dim)\n",
    "            elite_one_hot = F.one_hot(elite_actions, num_classes=self.action_dim).float()\n",
    "            \n",
    "            # Average the one-hots to get new probabilities\n",
    "            new_probs = elite_one_hot.mean(dim=0) # (H, action_dim)\n",
    "\n",
    "            # 6. Apply Laplace Smoothing\n",
    "            # Ensures we don't have 0% probability for any action\n",
    "            new_probs = (new_probs + self.smoothing) / (1 + self.smoothing * self.action_dim)\n",
    "            probs[traj_idx] = new_probs\n",
    "\n",
    "            losses.append(loss[topk_idx[0]].item())\n",
    "\n",
    "        # Logging logic (same as your original code)\n",
    "        self.wandb_run.log({f\"{self.logging_prefix}/loss\": np.mean(losses), \"step\": i + 1})\n",
    "        \n",
    "        if self.evaluator is not None and i % self.eval_every == 0:\n",
    "            # For evaluation, we pick the most likely action (argmax)\n",
    "            best_actions = torch.argmax(probs, dim=-1)\n",
    "            logs, successes, _, _ = self.evaluator.eval_actions(\n",
    "                best_actions, filename=f\"{self.logging_prefix}_output_{i+1}\"\n",
    "            )\n",
    "            # ... (rest of logging)\n",
    "            if np.all(successes): break\n",
    "\n",
    "    # Return the most likely action sequence\n",
    "    return torch.argmax(probs, dim=-1), np.full(n_evals, np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f9a239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from mawm.envs.marl_grid import make_env\n",
    "from mawm.envs.marl_grid.cfg import config\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "seed = np.random.randint(0, 10000)\n",
    "cfg = copy.deepcopy(config)\n",
    "cfg.env_cfg.seed = int(seed)\n",
    "cfg.env_cfg.max_steps = 512\n",
    "\n",
    "env = make_env(cfg.env_cfg)\n",
    "agents = [f\"agent_{i}\" for i in range(cfg.env_cfg.num_agents)]\n",
    "obs = env.reset()\n",
    "goal_pos = obs[\"global\"][\"goal_pos\"]\n",
    "goal_obs = np.array([\n",
    "    env.get_goal(env.agents[i], goal_pos)[0]\n",
    "    for i in range(config.env_cfg.num_agents)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e174bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, cfg.env_cfg.num_agents)\n",
    "for i in range(cfg.env_cfg.num_agents):\n",
    "    ax[i].imshow(goal_obs[i])\n",
    "    ax[i].set_title(f\"Agent {i} Goal Observation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50d0ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 42, 42, 3)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "goal_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd025d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from mawm.data.utils import base_tf, msg_tf\n",
    "def preprocessor(obs):\n",
    "    obs = torch.stack([base_tf(obs[i].astype(np.uint8)) for i in range(len(obs))])\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669d8799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 42, 42])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "import torch\n",
    "from mawm.data.utils import base_tf, msg_tf\n",
    "goals = torch.stack([base_tf(goal_obs[i].astype(np.uint8)) for i in range(len(goal_obs))])\n",
    "goals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1564f23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CellEmpty': 0, 'CellObstacle': 1, 'CellItem': 2, 'CellGoal': 3, 'CellAgent': 4, 'GoalAt': 5, 'ItemAt': 6, 'Near': 7, 'SeeGoal': 8, 'CanMove': 9, 'OtherAgentAt': 10, 'OtherAgentNear': 11, 'OtherAgentDirection': 12}\n"
     ]
    }
   ],
   "source": [
    "#| hide \n",
    "from mawm.models.jepa import JEPA\n",
    "from omegaconf import OmegaConf\n",
    "cfg = OmegaConf.load(\"../cfgs/MPCJepa/mpc.yaml\")\n",
    "model = JEPA(cfg.model, input_dim=(3, 42, 42), action_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af1a62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 15, 15])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "import torch\n",
    "encoded_goals = model.backbone(goals)\n",
    "encoded_goals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b2771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pov', 'selfpos', 'orientation', 'identity'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "obs['agent_0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5c6cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "obs = env.reset()\n",
    "goal_obs = np.array([\n",
    "    env.get_goal(env.agents[i], goal_pos)[0]\n",
    "    for i in range(config.env_cfg.num_agents)\n",
    "])\n",
    "goals = torch.stack([base_tf(goal_obs[i].astype(np.uint8)) for i in range(len(goal_obs))])\n",
    "encoded_goals = model.backbone(goals)\n",
    "\n",
    "msgs = {agent: msg_tf((obs[agent]['pov'], agent, False)) for agent in agents}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69c2f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42, 42, 3), torch.Size([5, 7, 7]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "obs['agent_0']['pov'].astype(np.uint8).shape,  msgs['agent_0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe034eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8QAAAHkCAYAAAD4n+boAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOYFJREFUeJzt3XuYVmW9P/73ADIgOIMHFEJAAUMo8gR5FvAQpnhMMTGETM0dnvqmpe5U0jZm3yx2mErmBpU0z2ZpliVkmimaeD6EiqJbPIAyooAC6/dHP55v46AOBD7oer2ua13Mc6/7uddnrXnG8T33OtQURVEEAAAASqZFtQsAAACAahCIAQAAKCWBGAAAgFISiAEAACglgRgAAIBSEogBAAAoJYEYAACAUhKIAQAAKCWBGAAAgFISiPnEGTNmTGpqalbqvZMmTUpNTU1mzpy5aov6FzNnzkxNTU0mTZq02rYBAAB8OIGYNcajjz6ar3zlK+nSpUtqa2vzqU99KocddlgeffTRapdWFVOnTk1NTU2uvfbaapcCAEAVLVy4MA0NDatlWbhwYbV3r6paVbsASJLrr78+hx56aNZbb7187Wtfy6abbpqZM2fmkksuybXXXptf/epXOeCAA5o11ne/+92ccsopK1XHiBEj8uUvfzm1tbUr9X4AAFiVFi5cmLZtN00ye7WMX1dXl86dO6dFixYZPXp0Ro8evVq2s6YSiKm6p59+OiNGjEiPHj1yxx13pGPHjpV1J5xwQnbeeeeMGDEiDz30UHr06PG+47z11ltp165dWrVqlVatVu6j3bJly7Rs2XKl3gsAAKvaO++8k3+G4VlJ6lbx6A1paOiaWbNmpa5uVY/98eCUaaru//7f/5u33347P//5zxuF4STZYIMNMmHChLz11lv54Q9/WGlfdp3wY489luHDh2fdddfNTjvt1Gjdv1qwYEGOP/74bLDBBllnnXWy77775sUXX0xNTU3GjBlT6be8a4g32WSTDB06NHfeeWc+//nPp02bNunRo0cuu+yyRtuYO3duTjrppPTr1y/t27dPXV1dvvjFL+bBBx9cRUfq/+3bU089la985Supr69Px44dc/rpp6coisyaNSv77bdf6urq0qlTp5x33nmN3v/OO+/kjDPOyDbbbJP6+vq0a9cuO++8c6ZMmdJkW3PmzMmIESNSV1eXDh06ZOTIkXnwwQeXe/3zE088kYMOOijrrbde2rRpk/79++emm25aZfsNAEDdalrKTSCm6n7zm99kk002yc4777zc9bvssks22WST3HzzzU3WHXzwwXn77bczduzYHHXUUe+7jVGjRmX8+PHZa6+9cu6556Zt27bZe++9m13jjBkzctBBB2WPPfbIeeedl3XXXTejRo1qdH3zM888kxtvvDFDhw7Nj3/845x88sl5+OGHM3DgwPzv//5vs7fVHIccckiWLl2aH/zgB9l2223z/e9/P+PGjcsee+yRLl265Nxzz02vXr1y0kkn5Y477qi8r6GhIb/4xS8yaNCgnHvuuRkzZkxeffXVDBkyJNOnT6/0W7p0afbZZ59ceeWVGTlyZP7rv/4rL730UkaOHNmklkcffTTbbbddHn/88Zxyyik577zz0q5du+y///654YYbVul+AwDAKlVAFb3xxhtFkmK//fb7wH777rtvkaRoaGgoiqIozjzzzCJJceihhzbpu2zdMvfff3+RpDjxxBMb9Rs1alSRpDjzzDMrbRMnTiySFM8++2ylrXv37kWS4o477qi0vfLKK0VtbW3xrW99q9K2cOHCYsmSJY228eyzzxa1tbXFWWed1agtSTFx4sQP3OcpU6YUSYprrrmmyb4dffTRlbbFixcXG2+8cVFTU1P84Ac/qLS//vrrRdu2bYuRI0c26rto0aJG23n99deLjTbaqDjiiCMqbdddd12RpBg3blylbcmSJcWuu+7apPbddtut6NevX7Fw4cJK29KlS4sddtih2GyzzT5wHwEA+GDz5s0rkhTJvCIpVvHyz7HnzZtX7d2sGjPEVNWbb76ZJFlnnXU+sN+y9Q0NDY3ajznmmA/dxq233pok+cY3vtGo/bjjjmt2nX379m00g92xY8f07t07zzzzTKWttrY2LVr880dqyZIlmTNnTtq3b5/evXvn73//e7O31RxHHnlk5euWLVumf//+KYoiX/va1yrtHTp0aFJjy5Yt07p16yT/nAWeO3duFi9enP79+zeq8dZbb81aa63VaNZ92Y0W/tXcuXNz++23Z9iwYXnzzTfz2muv5bXXXsucOXMyZMiQ/OMf/8iLL764SvcdAABWFTfVoqqWBd1lwfj9vF9w3nTTTT90G88991xatGjRpG+vXr2aXWe3bt2atK277rp5/fXXK6+XLl2a//7v/84FF1yQZ599NkuWLKmsW3/99Zu9rZWpp76+Pm3atMkGG2zQpH3OnDmN2i699NKcd955eeKJJ/Luu+9W2v/1+Dz33HPp3Llz1l577Ubvfe8xmzFjRoqiyOmnn57TTz99ubW+8sor6dKlS/N3DgAAPiICMVVVX1+fzp0756GHHvrAfg899FC6dOnS5O53bdu2XZ3lVbzfnaeLoqh8PXbs2Jx++uk54ogjcvbZZ2e99dZLixYtcuKJJ2bp0qWrvZ7m1Dh58uSMGjUq+++/f04++eRsuOGGadmyZc4555w8/fTTK1zHsv066aSTMmTIkOX2WZE/PAAAwEdJIKbqhg4dmosvvjh33nln5U7R/+ovf/lLZs6cma9//esrNX737t2zdOnSPPvss9lss80q7TNmzFjpmpfn2muvzeDBg3PJJZc0an/jjTeazNxWy7XXXpsePXrk+uuvb3Qn7jPPPLNRv+7du2fKlCl5++23G80Sv/eYLXsM1lprrZXdd999NVYOAACrnmuIqbqTTz45bdu2zde//vUmp/fOnTs3xxxzTNZee+2cfPLJKzX+spnLCy64oFH7+PHjV67g99GyZctGs7FJcs0116xR19Aum0X+1zrvueee3H333Y36DRkyJO+++24uvvjiStvSpUvzs5/9rFG/DTfcMIMGDcqECRPy0ksvNdneq6++uirLBwCAVcoMMVW32Wab5dJLL81hhx2Wfv365Wtf+1o23XTTzJw5M5dccklee+21XHnllenZs+dKjb/NNtvkS1/6UsaNG5c5c+Zku+22y5///Oc89dRTSdLkmcUra+jQoTnrrLPy1a9+NTvssEMefvjh/PKXv6zMoq4Jhg4dmuuvvz4HHHBA9t577zz77LO56KKL0rdv38yfP7/Sb//998/nP//5fOtb38qMGTOy+eab56abbsrcuXOTND5mP/vZz7LTTjulX79+Oeqoo9KjR4+8/PLLufvuu/PCCy+s0ucwAwDAqiQQs0Y4+OCDs/nmm+ecc86phOD1118/gwcPzmmnnZbPfvaz/9b4l112WTp16pQrr7wyN9xwQ3bfffdcddVV6d27d9q0abNK9uG0007LW2+9lSuuuCJXXXVVtt5669x888055ZRTVsn4q8KoUaMye/bsTJgwIb///e/Tt2/fTJ48Oddcc02mTp1a6deyZcvcfPPNOeGEE3LppZemRYsWOeCAA3LmmWdmxx13bHTM+vbtm/vuuy/f+973MmnSpMyZMycbbrhhttpqq5xxxhlV2EsAAGiemuK953hCSUyfPj1bbbVVJk+enMMOO6za5Xws3HjjjTnggANy5513Zscdd6x2OQAAn3gNDQ2pr69PMi9J3Yd1X9HRk9Rn3rx5TW5eWxauIaYUFixY0KRt3LhxadGiRXbZZZcqVLTme+8xW7JkScaPH5+6urpsvfXWVaoKAABWHadMUwo//OEPc//992fw4MFp1apVfve73+V3v/tdjj766HTt2rXa5a2RjjvuuCxYsCDbb799Fi1alOuvvz5//etfM3bs2I/scVcAALA6CcSUwg477JDbbrstZ599dubPn59u3bplzJgx+c///M9ql7bG2nXXXXPeeeflt7/9bRYuXJhevXpl/PjxOfbYY6tdGgAArBKuIQYAAFhDuYZ49XINMQAAAKUkEAMAAFBKAjEAAACl1OybatXU1KzOOgBghbkNBgDw7zBDDAAAQCkJxAAAAJSSQAwAAEApCcQAAACUkkAMAABAKQnEAAAAlJJADAAAQCkJxAAAAJSSQAwAAEApCcQAAACUkkAMAABAKQnEAAAAlJJADAAAQCkJxAAAAJSSQAwAAEApCcQAAACUkkAMAABAKQnEAAAAlJJADAAAQCkJxAAAJTJz5szU1NRk0qRJq2zMSZMmpaamJjNnzlxlY7L6jBkzJjU1Nc3qW1NTkzFjxqzegqCKBGIAgBWwLPwtW9q0aZNPfepTGTJkSH7605/mzTffrHaJa6xlQaxFixaZNWtWk/UNDQ1p27Ztampqcuyxx1ahwjXbK6+8klNOOSX9+vVL+/bt06ZNm/Tq1Stf/epXc+edd1a7PKj8wW369OnVLqXZBGIAgJVw1lln5fLLL8+FF16Y4447Lkly4oknpl+/fnnooYeqXN2arba2NldeeWWT9uuvv74K1Xw83HvvvfnMZz6TcePGZZtttsm5556b888/P4ccckjuvffe7LzzzrnjjjuaNdZ3v/vdLFiwYDVXzCfRqFGjGv1BcP3118+ee+75sf5vXqtqFwAA8HH0xS9+Mf3796+8PvXUU3P77bdn6NCh2XffffP444+nbdu2VaxwzbXXXnvlyiuvzLe//e1G7VdccUX23nvvXHfddVWqbM30+uuvZ//990+rVq0yffr0bL755o3Wf//738+vfvWrD/28vfXWW2nXrl1atWqVVq3EAFbOnnvumYkTJyZJZs+ene9+97sZOnRonn/++SpXtnLMEAMArCK77rprTj/99Dz33HOZPHlyo3VPPPFEDjrooKy33npp06ZN+vfvn5tuuqnJGG+88Ua++c1vZpNNNkltbW023njjHH744XnttdcqfV555ZV87Wtfy0YbbZQ2bdpkiy22yKWXXrrcsUaNGpX6+vp06NAhI0eOzBtvvLHc2ptb36OPPppdd901bdu2zcYbb5zvf//7Wbp06Qodp+HDh2f69Ol54oknKm2zZ8/O7bffnuHDhy/3PYsWLcqZZ56ZXr16pba2Nl27ds23v/3tLFq0qFG/2267LTvttFM6dOiQ9u3bp3fv3jnttNMa9Rk/fnw+85nPZO211866666b/v3754orrqisf+655/KNb3wjvXv3Ttu2bbP++uvn4IMPXu410g899FAGDhzY6HhMnDhxuddU/+53v8vOO++cdu3aZZ111snee++dRx999EOP10UXXZSXXnop48aNaxKGk39e53vooYdmwIABlbZlp6c/9thjGT58eNZdd93stNNOjda99/h+85vfTMeOHbPOOutk3333zQsvvPChtVE+tbW16dSpUzp16pQtt9wyp5xySmbNmpVXX321Sd9JkyalQ4cOjdpuvPHGJp+/X//619l6663Tpk2b9OjRI9/73veyePHi1bkbFf40BACwCo0YMSKnnXZa/vCHP+Soo45K8s8QueOOO6ZLly455ZRT0q5du1x99dXZf//9c9111+WAAw5IksyfPz8777xzHn/88RxxxBHZeuut89prr+Wmm27KCy+8kA022CALFizIoEGDMmPGjBx77LHZdNNNc80112TUqFF54403csIJJyRJiqLIfvvtlzvvvDPHHHNM+vTpkxtuuCEjR45sUnNz65s9e3YGDx6cxYsXV/r9/Oc/X+GZ8F122SUbb7xxrrjiipx11llJkquuuirt27fP3nvv3aT/0qVLs+++++bOO+/M0UcfnT59+uThhx/OT37ykzz11FO58cYbK/sxdOjQfO5zn8tZZ52V2trazJgxI3fddVdlrIsvvjjHH398DjrooJxwwglZuHBhHnroodxzzz2VMD5t2rT89a9/zZe//OVsvPHGmTlzZi688MIMGjQojz32WNZee+0kyYsvvpjBgwenpqYmp556atq1a5df/OIXqa2tbbIPl19+eUaOHJkhQ4bk3HPPzdtvv50LL7wwO+20Ux544IFssskm73u8fvOb36Rt27Y58MADV+g4J8nBBx+czTbbLGPHjk1RFO/b78gjj8zkyZMzfPjw7LDDDrn99tuX+73gk6mhoaHR69ra2uV+jt9r/vz5mTx5cnr16pX1118/b7311gpv+y9/+UsOP/zw/PSnP83OO++cp59+OkcffXSS5Mwzz1zh8VZY0UxJLBaLxWJZoxaohokTJxZJimnTpr1vn/r6+mKrrbaqvN5tt92Kfv36FQsXLqy0LV26tNhhhx2KzTbbrNJ2xhlnFEmK66+/vsmYS5cuLYqiKMaNG1ckKSZPnlxZ98477xTbb7990b59+6KhoaEoiqK48cYbiyTFD3/4w0q/xYsXFzvvvHORpJg4ceIK13fiiScWSYp77rmn0vbKK68U9fX1RZLi2Weffd9jUhRFceaZZxZJildffbU46aSTil69elXWDRgwoPjqV79aFMU//79z9OjRlXWXX3550aJFi+Ivf/lLo/EuuuiiIklx1113FUVRFD/5yU8q47+f/fbbr/jMZz7zgXW+/fbbTdruvvvuIklx2WWXVdqOO+64oqampnjggQcqbXPmzCnWW2+9RsfjzTffLDp06FAcddRRjcacPXt2UV9f36T9vdZdd91iyy23bNLe0NBQvPrqq5Vl/vz5lXXLjvWhhx7a5H3L1i0zffr0IknxjW98o1G/4cOHF0mKM8888wPrY/WaN2/e//97b16RFKt4WTZ24+X9vucjR44sWrZsWbRr165o165dkaTo3Llzcf/99xdFURTPPvtskaTyMzFx4sSivr6+0Rg33HBDo8/fbrvtVowdO7ZRn8svv7zo3LnzKjuGH8Qp0wAAq1j79u0rd5ueO3dubr/99gwbNixvvvlmXnvttbz22muZM2dOhgwZkn/84x958cUXkyTXXXddtthii8qM7L9adorhLbfckk6dOuXQQw+trFtrrbVy/PHHZ/78+fnzn/9c6deqVav8x3/8R6Vfy5YtKzcAW2ZF6rvllluy3Xbb5fOf/3zl/R07dsxhhx22wsdo+PDhmTFjRqZNm1b59/1Ol77mmmvSp0+fbL755pX6Xnvttey6665JkilTpiRJ5dTMX//61+97GneHDh3ywgsvZNq0ae9b27/OeL/77ruZM2dOevXqlQ4dOuTvf/97Zd2tt96a7bffPltuuWWlbb311mtyPG677ba88cYbOfTQQxvV37Jly2y77baV+t9PQ0ND2rdv36R9xIgR6dixY2X5zne+06TPMccc84FjJ//8vibJ8ccf36j9xBNP/ND38skwa9aszJs3r7Kceuqp79t38ODBmT59eqZPn5577703Q4YMyRe/+MU899xzK7XtBx98MGeddVbat29fWY466qi89NJLefvtt1d2l5rNKdMAAKvY/Pnzs+GGGyZJZsyYkaIocvrpp+f0009fbv9XXnklXbp0ydNPP50vfelLHzj2c889l8022ywtWjSe1+jTp09l/bJ/O3fu3CRI9e7du9HrFanvueeey7bbbttk/XvHbI6tttoqm2++ea644op06NAhnTp1qgTc9/rHP/6Rxx9/PB07dnzf+pLkkEMOyS9+8YsceeSROeWUU7LbbrvlwAMPzEEHHVQ5Xt/5znfyxz/+MZ///OfTq1evfOELX8jw4cOz4447VsZbsGBBzjnnnEycODEvvvhio1ON582bV/n6ueeey/bbb9+knl69ejWpP8n77l9dXd1y25dZZ511Mn/+/CbtZ511VuXxVHvsscdy37vpppt+4NjJP/ejRYsW6dmzZ6P2lfm+8vFUV1f3oZ/DZdq1a9foM/6LX/wi9fX1ufjii3PkkUc26tuiRYsmp+q/++67jV7Pnz8/3/ve95Z7SUCbNm2auwsrTSAGAFiFXnjhhcybN6/yP4zLZipPOumkDBkyZLnveW+A+ihVs77hw4fnwgsvzDrrrJNDDjmkScj/1xr79euXH//4x8td37Vr1yT/nNm94447MmXKlNx888259dZbc9VVV2XXXXfNH/7wh7Rs2TJ9+vTJk08+md/+9re59dZbc9111+WCCy7IGWecke9973tJkuOOOy4TJ07MiSeemO233z719fWpqanJl7/85RW+gdiy+pN/XkfcqVOnJus/7I7Pm2++eR588MG8++67WWuttSrtn/vc5z502+50zuq27Nniy3uUV8eOHfPmm29W7nCepMkzirfeeus8+eSTVfvvoEAMALAKXX755UlSCZc9evRI8s/TmnffffcPfG/Pnj3zyCOPfGCf7t2756GHHsrSpUsbBchld2zu3r175d8//elPmT9/fqNZ4ieffLLReCtSX/fu3Suznf/qvWM21/Dhw3PGGWfkpZdeqhy35enZs2cefPDB7Lbbbk3uTvteLVq0yG677ZbddtstP/7xjzN27Nj853/+Z6ZMmVLZv3bt2uWQQw7JIYccknfeeScHHnhg/uu//iunnnpq2rRpk2uvvTYjR47MeeedVxl34cKFTe7Q3b1798yYMaNJDe9tWzbzuuGGG37oMV6eoUOH5m9/+1tuuOGGDBs2bIXf/2G6d++epUuX5umnn240K7yy31c+2RYtWpTZs2cn+ecjwc4///zMnz8/++yzT5O+2267bdZee+2cdtppOf7443PPPfdk0qRJjfqcccYZGTp0aLp161Y5m+PBBx/MI488ku9///urfX9cQwwAsIrcfvvtOfvss7PppptWriPdcMMNM2jQoEyYMCEvvfRSk/f866NKvvSlL+XBBx/MDTfc0KTfstMO99prr8yePTtXXXVVZd3ixYszfvz4tG/fPgMHDqz0W7x4cS688MJKvyVLlmT8+PGNxl2R+vbaa6/87W9/y7333tto/S9/+csPPjDvo2fPnhk3blzOOeecRtclv9ewYcPy4osv5uKLL26ybsGCBZU7286dO7fJ+mXX9y57PNOcOXMarW/dunX69u2boigqp3K2bNmyyWme48ePz5IlSxq1DRkyJHfffXejGa+5c+c2OR5DhgxJXV1dxo4d2+R00STLfVzNv/qP//iPbLTRRvnmN7+Zp556qsn699a6or74xS8mSX760582ah83bty/NS6fTLfeems6d+6czp07Z9ttt820adNyzTXXZNCgQU36rrfeepk8eXJuueWW9OvXL1deeWXGjBnTqM+QIUPy29/+Nn/4wx8yYMCAbLfddvnJT35S+ePe6maGGABgJfzud7/LE088kcWLF+fll1/O7bffnttuuy3du3fPTTfd1Ojat5/97GfZaaed0q9fvxx11FHp0aNHXn755dx999154YUX8uCDDyZJTj755Fx77bU5+OCDc8QRR2SbbbbJ3Llzc9NNN+Wiiy7KFltskaOPPjoTJkzIqFGjcv/992eTTTbJtddem7vuuivjxo3LOuuskyTZZ599suOOO+aUU07JzJkz07dv31x//fWNroFd0fq+/e1v5/LLL8+ee+6ZE044ofLYpWWz1itj2WOiPsiIESNy9dVX55hjjsmUKVOy4447ZsmSJXniiSdy9dVX5/e//3369++fs846K3fccUf23nvvdO/ePa+88kouuOCCbLzxxpVn8H7hC19Ip06dsuOOO2ajjTbK448/nvPPPz9777135dgNHTo0l19+eerr69O3b9/cfffd+eMf/5j111+/UV3f/va3M3ny5Oyxxx457rjjKo9d6tatW+bOnVuZza6rq8uFF16YESNGZOutt86Xv/zldOzYMc8//3xuvvnm7Ljjjjn//PPfd//XW2+93HDDDdlnn32yxRZb5Mtf/nIGDBiQtdZaK7Nmzco111yTJOnWrdtKfQ+23HLLHHroobngggsyb9687LDDDvnTn/603Nlvym3SpElNZnj/1SabbNLkDzT7779/9t9//0Ztyx5Jt8yQIUPe95KN1a65t6POGvB4DYvFYrFY/nWBalj22KVlS+vWrYtOnToVe+yxR/Hf//3flccevdfTTz9dHH744UWnTp2KtdZaq+jSpUsxdOjQ4tprr23Ub86cOcWxxx5bdOnSpWjdunWx8cYbFyNHjixee+21Sp+XX365+OpXv1pssMEGRevWrYt+/fo1eozSv441YsSIoq6urqivry9GjBhRPPDAA0WSJv2bW99DDz1UDBw4sGjTpk3RpUuX4uyzzy4uueSSIlmxxy59kKTxY5eK4p+Pljr33HOLz3zmM0VtbW2x7rrrFttss03xve99r5g3b15RFEXxpz/9qdhvv/2KT33qU0Xr1q2LT33qU8Whhx5aPPXUU5VxJkyYUOyyyy7F+uuvX9TW1hY9e/YsTj755MoYRVEUr7/+euX4tm/fvhgyZEjxxBNPFN27dy9GjhzZqK4HHnig2HnnnYva2tpi4403Ls4555zipz/9aZGkmD17dqO+U6ZMKYYMGVLU19cXbdq0KXr27FmMGjWquO+++z7weCzz0ksvFSeffHLRt2/fom3btkVtbW3Ro0eP4vDDDy/uuOOOZh/r9z52qSiKYsGCBcXxxx9frL/++kW7du2KffbZp5g1a1aReOxStX0Uj136189/2dQURfPOsfiw6zUA4KPWzF9hAB+pE088MRMmTMj8+fPTsmXLapfDx1xDQ0Pq6+uTzEvSvDtBr8DoSeozb968Zt9l+pPGNcQAALCS3ntn3Tlz5uTyyy/PTjvtJAzDx4BriAEAYCVtv/32GTRoUPr06ZOXX345l1xySRoaGt73mc7AmkUgBgCAlbTXXnvl2muvzc9//vPU1NRk6623ziWXXJJddtml2qUBzeAaYgA+tlxDDMAnnWuIVy/XEAMAAFBKAjEAAAClJBADAABQSm6qBQAkSfr161ftEgA+9h5++OFql8AKMEMMAABAKQnEAAAAlJJADAAAQCkJxAAAAJSSQAwAAEApCcQAAACUkkAMAABAKQnEAAAAlJJADAAAQCkJxAAAAJSSQAwAAEApCcQAAACUkkAMAABAKQnEAAAAlJJADAAAQCkJxAAAAJRSq+Z23Gtw39VZBwAAAHykzBADAABQSgIxAAAApSQQAwAAUEoCMQAAAKUkEAMAAFBKAjEAAAClJBADAABQSgIxAAAApSQQAwAAUEoCMQAAAKUkEAMAAFBKAjEAAAClJBADAACs4ealPkVqVukyL/VJkgEDBqRv37752c9+VuW9/Oi1qnYBAAAAVM+0adNSV1dX7TKqwgwxAAAApSQQAwAAUEoCMQAAAKUkEAMAAFBKAjEAAAClJBADAABQSgIxAAAApSQQAwAAUEoCMQAAAKUkEAMAAFBKAjEAAAClJBADAABQSgIxAAAApSQQAwAAUEoCMQAAAKXUqtoFAABrhq02aFftEgDgI2WGGAAAgFISiAEAACglgRgAAIBSEogBAAAoJYEYAACAUhKIAQAAKCWBGAAAgFISiAEAACglgRgAAIBSEogBAAAoJYEYAACAUhKIAQAAKCWBGAAAgFISiAEAACglgRgAAIBSEogBAAAoJYEYAACAUhKIAQAAKCWBGAAAgFISiAEAACglgRgAAIBSEogBAAAoJYEYAACAUhKIAQAAKCWBGAAAgKqYOnVqampq8sYbb1Rl+wIxAAAAH2rUqFGpqalJTU1N1lprrWy66ab59re/nYULF1a7tJXWqtoFAAAA8PGw5557ZuLEiXn33Xdz//33Z+TIkampqcm5555b7dJWihliAAAAmqW2tjadOnVK165ds//++2f33XfPbbfdliRZunRpzjnnnGy66aZp27Zttthii1x77bWN3n/LLbfk05/+dNq2bZvBgwdn5syZVdiL/8cMMQAAQIk1NDQ0el1bW5va2toPfd8jjzySv/71r+nevXuS5JxzzsnkyZNz0UUXZbPNNssdd9yRr3zlK+nYsWMGDhyYWbNm5cADD8zo0aNz9NFH57777su3vvWt1bJPzSUQAwAAlFjXrl0bvT7zzDMzZsyY5fb97W9/m/bt22fx4sVZtGhRWrRokfPPPz+LFi3K2LFj88c//jHbb799kqRHjx658847M2HChAwcODAXXnhhevbsmfPOOy9J0rt37zz88MNVPd262YH4limPrc464CO31+C+1S7hI+fn+JOvjJ9rAODfM2vWrNTV1VVef9Ds8ODBg3PhhRfmrbfeyk9+8pO0atUqX/rSl/Loo4/m7bffzh577NGo/zvvvJOtttoqSfL4449n2223bbR+WXiuFjPEAAAAJVZXV9coEH+Qdu3apVevXkmS//mf/8kWW2yRSy65JJ/97GeTJDfffHO6dOnS6D3NOf26WgRiAAAAVliLFi1y2mmn5f/8n/+Tp556KrW1tXn++eczcODA5fbv06dPbrrppkZtf/vb3z6KUt+Xu0wDAACwUg4++OC0bNkyEyZMyEknnZRvfvObufTSS/P000/n73//e8aPH59LL700SXLMMcfkH//4R04++eQ8+eSTueKKKzJp0qSq1m+GGAAAgJXSqlWrHHvssfnhD3+YZ599Nh07dsw555yTZ555Jh06dMjWW2+d0047LUnSrVu3XHfddfnmN7+Z8ePH5/Of/3zGjh2bI444omr11xRFUTSrY03N6q4FPlJlvPmQm2p98pXtc33z7Y9Wu4RPlMMHb1ftEgA+9i6bsmpPAW5oaEh9fX3mJWneVb4rMHaS+iTz5s1r9jXEnzROmQYAAKCUBGIAAABKSSAGAACglARiAAAASsldpgGycTP7Xb2Ktzusmf1eWMXbBQAgMUMMAABASQnEAAAAlJJADAAAQCkJxAAAAJSSQAwAAEApCcQAAACUkkAMAABAKXkOMQCQJHngtbeqXQIfc1tt0K7aJfzbPu4/B4888nC1S/i3jBi0XbVLoGTMEAMAAFBKZogBcnUz+21fpe3usIq3CwBAYoYYAACAkhKIAQAAKCWBGAAAgFISiAEAACglgRgAAIBSEogBAAAoJYEYAACAUhKIAQAAKCWBGAAAgFISiAEAACglgRgAAIBSEogBAAAoJYEYAACAUhKIAQAAKCWBGAAAgFISiAEAACglgRgAAIBSEogBAAAoJYEYAACAUmpV7QIAqm9YM/tdXaXtAgCwOpghBgAAoJQEYgAAAEpJIAYAAKCUBGIAAABKyU21AAAA1nDDfrl31lp7rVU65rtvv5scdnMGDBiQli1bZvTo0Rk9evQq3caaTiAGAAAosWnTpqWurq7aZVSFU6YBAAAoJYEYAACAUhKIAQAAKCXXEAPkhWb222G1VgEAwEfLDDEAAAClJBADAABQSgIxAAAApSQQAwAAUEoCMQAAAKUkEAMAAFBKAjEAAAClJBADAABQSgIxAAAApdSq2gVAtdwy5bFqlwCrnM81AEDzmSEGAACglARiAAAASkkgBgAAoJQEYgAAAEpJIAYAAKCU3GUaAIBV4rKp91S7hH9bv89+ttol/Fs++9l+1S7h3/LAa9WugLIxQwwAAEApCcQAAACUkkAMAABAKbmGGD7Exs3sd/Vq2PawZvZ7YTVsGwAAPunMEAMAAFBKAjEAAAClJBADAABQSgIxAAAApSQQAwAAUEoCMQAAAKUkEAMAAFBKAjEAAAClJBADAABQSq2qXQCs6a5uZr/tq7jtHVbDtgEA4JPODDEAAAClJBADAABQSgIxAAAApSQQAwAAUEoCMQAAAKUkEAMAALBG2WSTTTJu3LjVvh2BGAAAgGaZPXt2TjjhhPTq1Stt2rTJRhttlB133DEXXnhh3n777WqXt8I8hxgAAIAP9cwzz2THHXdMhw4dMnbs2PTr1y+1tbV5+OGH8/Of/zxdunTJvvvuW+0yV4gZYgAAAD7UN77xjbRq1Sr33Xdfhg0blj59+qRHjx7Zb7/9cvPNN2efffZJkjz//PPZb7/90r59+9TV1WXYsGF5+eWXK+M8/fTT2W+//bLRRhulffv2GTBgQP74xz9WZZ8EYgAAgBJraGhotCxatKhJnzlz5uQPf/hDRo8enXbt2i13nJqamixdujT77bdf5s6dmz//+c+57bbb8swzz+SQQw6p9Js/f3722muv/OlPf8oDDzyQPffcM/vss0+ef/751baP78cp0wAAACXWtWvXRq/PPPPMjBkzplHbjBkzUhRFevfu3ah9gw02yMKFC5Mko0ePzu67756HH344zz77bGXcyy67LJ/5zGcybdq0DBgwIFtssUW22GKLyhhnn312brjhhtx000059thjV8Mevj+BGAAAoMRmzZqVurq6yuva2tpmv/fee+/N0qVLc9hhh2XRokV5/PHH07Vr10Yhu2/fvunQoUMef/zxDBgwIPPnz8+YMWNy880356WXXsrixYuzYMECM8QAAAB8tOrq6hoF4uXp1atXampq8uSTTzZq79GjR5Kkbdu2zd7eSSedlNtuuy0/+tGP0qtXr7Rt2zYHHXRQ3nnnnRUv/t/kGmIAAAA+0Prrr5899tgj559/ft5666337denT5/MmjUrs2bNqrQ99thjeeONN9K3b98kyV133ZVRo0blgAMOSL9+/dKpU6fMnDlzde/CcgnEAAAAfKgLLrggixcvTv/+/XPVVVfl8ccfz5NPPpnJkyfniSeeSMuWLbP77runX79+Oeyww/L3v/899957bw4//PAMHDgw/fv3T5Jsttlmuf766zN9+vQ8+OCDGT58eJYuXVqVfRKIAQAA+FA9e/bMAw88kN133z2nnnpqtthii/Tv3z/jx4/PSSedlLPPPjs1NTX59a9/nXXXXTe77LJLdt999/To0SNXXXVVZZwf//jHWXfddbPDDjtkn332yZAhQ7L11ltXZZ9qiqIomtWxpmZ11wJrpL82s9/2q2Hbdzez3w6rYdvwcdDMX2E0U79+/apdAh9zDz/ySLVL+Lf1++xnq10CH3MPP/zwKh2voaEh9fX1GfLLvbPW2mut0rHfffvd/P6wmzNv3rwPvYb4k8oMMQAAAKUkEAMAAFBKAjEAAACl5DnE8CGGNbPf1VXcNgAAsOLMEAMAAFBKAjEAAAClJBADAABQSgIxAAAApSQQAwAAUEoCMQAAAKUkEAMAAFBKAjEAAAClJBADAABQSq2qXQCs6V5oZr8dVmsVAADAqmaGGAAAgFISiAEAACglgRgAAIBScg0xAPCJsNUG7apdwr/tgdfeqnYJ/5Z+n/1stUv4t30SPkcfZx/3nwE+fswQAwAAUEoCMQAAAKUkEAMAAFBKAjEAAAClJBADAABQSu4y/T72Gty32iV85G6Z8li1S2A1K+Pnumz8HAMANJ8ZYgAAAEpJIAYAAKCUBGIAAABKSSAGAACglARiAAAASkkgBgAAoJQEYgAAAEpJIAYAAKCUBGIAAABKSSAGAACglARiAAAASkkgBgAAoJQEYgAAAEpJIAYAAKCUBGIAAABKqVW1CwAAAOCDdbhwdlq3WrXx7Z3Fi5MkAwYMSMuWLTN69OiMHj16lW5jTScQAwAAlNi0adNSV1dX7TKqwinTAAAAlJJADAAAQCkJxAAAAJSSQAwAAEApCcQAAACUkkAMAABAKQnEAAAAlJJADAAAQCkJxAAAAJSSQAwAAEApCcQAAACUkkAMAABAKQnEAAAAlJJADAAAQCkJxAAAAJSSQAwAAEApCcQAAACUkkAMAABAKQnEAAAAlJJADAAAQCkJxAAAAJSSQAwAAEApCcQAAACUkkAMAABAKbWqdgEAAKvCA6+9Ve0S+ATwOYJyMUMMAABAKQnEAAAAlJJADAAAQCkJxAAAAJSSQAwAAEApCcQAAACUkkAMAABAKQnEAAAAlJJADAAAQCkJxAAAAJSSQAwAAEApCcQAAACUkkAMAABAKQnEAAAAlJJADAAAQCkJxAAAAHzkpk6dmpqamrzxxhtJkkmTJqVDhw4faQ0CMQAAAB/ooosuyjrrrJPFixdX2ubPn5+11lorgwYNatR3WdB9+umnP+IqV1yrahewprplymPVLgFWOZ9rAABWxuDBgzN//vzcd9992W677ZIkf/nLX9KpU6fcc889WbhwYdq0aZMkmTJlSrp165aePXtWs+RmMUMMAABQYg0NDY2WRYsWNenTu3fvdO7cOVOnTq20TZ06Nfvtt1823XTT/O1vf2vUPnjw4Fx++eXp379/1llnnXTq1CnDhw/PK6+88lHsUrMJxAAAACXWtWvX1NfXV5Zzzjlnuf0GDx6cKVOmVF5PmTIlgwYNysCBAyvtCxYsyD333JPBgwfn3Xffzdlnn50HH3wwN954Y2bOnJlRo0Z9FLvUbE6ZBgAAKLFZs2alrq6u8rq2tna5/QYPHpwTTzwxixcvzoIFC/LAAw9k4MCBeffdd3PRRRclSe6+++4sWrQogwcPTrdu3Srv7dGjR376059mwIABmT9/ftq3b796d6qZzBADAACUWF1dXaPl/QLxoEGD8tZbb2XatGn5y1/+kk9/+tPp2LFjBg4cWLmOeOrUqenRo0e6deuW+++/P/vss0+6deuWddZZJwMHDkySPP/88x/l7n0gM8QAAAB8qF69emXjjTfOlClT8vrrr1cC7qc+9al07do1f/3rXzNlypTsuuuueeuttzJkyJAMGTIkv/zlL9OxY8c8//zzGTJkSN55550q78n/Y4YYAACAZhk8eHCmTp2aqVOnNnrc0i677JLf/e53uffeezN48OA88cQTmTNnTn7wgx9k5513zuabb77G3VArEYgBAABopsGDB+fOO+/M9OnTKzPESTJw4MBMmDAh77zzTuX64datW2f8+PF55plnctNNN+Xss8+uYuXLJxADAADQLIMHD86CBQvSq1evbLTRRpX2gQMH5s0336w8nqljx46ZNGlSrrnmmvTt2zc/+MEP8qMf/aiKlS9fTVEURbM61tSs7loAYIU081cYzdSvX79qlwDwsffwww+v0vEaGhpSX1+fQ3baJq1brdpbQL2zeHGuuvP+zJs3r9FdpsvEDDEAAAClJBADAABQSgIxAAAApSQQAwAAUEoCMQAAAKUkEAMAAFBKAjEAAAClJBADAABQSgIxAAAApSQQAwAAUEoCMQAAAKUkEAMAAFBKAjEAAAClJBADAABQSgIxAAAApSQQAwAAUEoCMQAAAKUkEAMAAFBKAjEAAAClJBADAABQSq2qXQAAAP+01Qbtql1C6T3w2lvVLgH4CJkhBgAAoJQEYgAAAEpJIAYAAKCUBGIAAABKSSAGAACglARiAAAASkkgBgAAoJQEYgAAAEpJIAYAAKCUBGIAAABKSSAGAACglARiAAAASkkgBgAAoJQEYgAAAEpJIAYAAKCUBGIAAABKSSAGAACglARiAAAASqlVtQsAAADggz005+20bNlylY65ZMmSJMmAAQPSsmXLjB49OqNHj16l21jTCcQAAAAlNm3atNTV1VW7jKpwyjQAAAClJBADAABQSgIxAAAApSQQAwAAUEoCMQAAAKUkEAMAAFBKAjEAAAClJBADAABQSgIxAAAApSQQAwAAUEqtql0Aa469BvetdgmsZrdMeazaJQAAwBrDDDEAAAClJBADAABQSgIxAAAApSQQAwAAUEoCMQAAAKUkEAMAAFBKAjEAAAClJBADAABQSgIxAAAApSQQAwAAUEoCMQAAAKUkEAMAAFBKAjEAAAClJBADAABQSgIxAAAApSQQAwAAUEoCMQAAAKXUqtoFAABrhocffrjaJQDAR8oMMQAAAKUkEAMAAFBKAjEAAAClJBADAABQSgIxAAAApSQQAwAAUEoCMQAAAKUkEAMAAFBKAjEAAAClJBADAABQSgIxAAAApSQQAwAA8KFGjRqVmpqaJsuee+652re7//77r5axW62WUQEAAPjE2XPPPTNx4sRGbbW1tVWq5t9nhhgAAIBmqa2tTadOnRot6667bpKkpqYmEyZMyNChQ7P22munT58+ufvuuzNjxowMGjQo7dq1yw477JCnn366Mt6YMWOy5ZZbZsKECenatWvWXnvtDBs2LPPmzausv/TSS/PrX/+6MiM9derU7Lrrrjn22GMb1fbqq6+mdevW+dOf/tTs/RGIAQAASqyhoaHRsmjRopUe6+yzz87hhx+e6dOnZ/PNN8/w4cPz9a9/Paeeemruu+++FEXRJMjOmDEjV199dX7zm9/k1ltvzQMPPJBvfOMbSZKTTjopw4YNy5577pmXXnopL730UnbYYYcceeSRueKKKxrVOnny5HTp0iW77rprs+sViAEAAEqsa9euqa+vryznnHPO+/b97W9/m/bt2zdaxo4dW1n/1a9+NcOGDcunP/3pfOc738nMmTNz2GGHZciQIenTp09OOOGETJ06tdGYCxcuzGWXXZYtt9wyu+yyS8aPH59f/epXmT17dtq3b5+2bds2mplu3bp1DjzwwCTJr3/968o4kyZNqlzn3FyuIQYAACixWbNmpa6urvL6g64JHjx4cC688MJGbeutt17l68997nOVrzfaaKMkSb9+/Rq1LVy4MA0NDZVtduvWLV26dKn02X777bN06dI8+eST6dSp03LraNOmTUaMGJH/+Z//ybBhw/L3v/89jzzySG666abm7HKFQAwAAFBidXV1jQLxB2nXrl169er1vuvXWmutytfLZmqX17Z06dKVKbWRI488MltuuWVeeOGFTJw4Mbvuumu6d+++QmM4ZRoAAICqef755/O///u/ldd/+9vf0qJFi/Tu3TtJ0rp16yxZsqTJ+/r165f+/fvn4osvzhVXXJEjjjhihbdthhgAAIBmWbRoUWbPnt2orVWrVtlggw1Wesw2bdpk5MiR+dGPfpSGhoYcf/zxGTZsWOV06U022SS///3v8+STT2b99ddPfX19Zdb5yCOPzLHHHpt27drlgAMOWOFtmyEGAACgWW699dZ07ty50bLTTjv9W2P26tUrBx54YPbaa6984QtfyOc+97lccMEFlfVHHXVUevfunf79+6djx4656667KusOPfTQtGrVKoceemjatGmzwtuuKYqiaFbHFbhTFx9Pew3uW+0SWM1umfJYtUuAVaqZv8IA4GOroaEh9fX16dOnT1q2bLlKx16yZEkef/zxzJs3r9nXEK9qY8aMyY033pjp06ev1PtnzpyZnj17Ztq0adl6661X+P1OmQYAAOBj5d13382cOXPy3e9+N9ttt91KheHEKdMAAAB8zNx1113p3Llzpk2blosuumilx3HKNBVOmf7kc8o0nzROmQbgk+6Tfsp0tZkhBgAAoJQEYgAAAEpJIAYAAKCUBGIAAABKSSAGAACglARiAAAASkkgBgAAoJQEYgAAAEpJIAYAAKCUBGIAAABKSSAGAACglARiAAAASkkgBgAAoJQEYgAAAEpJIAYAAKCUBGIAAABKqVVzOxZFsTrrAAAAgI+UGWIAAABKSSAGAACglARiAAAASkkgBgAAoJQEYgAAAEpJIAYAAKCUBGIAAABKSSAGAACglARiAAAASkkgBgAAoJQEYgAAAEpJIAYAAKCUBGIAAABKSSAGAACglARiAAAASkkgBgAAoJQEYgAAAEpJIAYAAKCUWlW7AAAAAD7Y0qVLPxZjftzUFEVRVLsIAAAAmlq4cGE23XTTzJ49e7WMX1dXl86dO6dFixYZPXp0Ro8evVq2s6YSiAEAANZgCxcuzDvvvLNaxm7dunXatGmzWsb+OBCIAQAAKCU31QIAAKCUBGIAAABKSSAGAACglARiAAAASkkgBgAAoJQEYgAAAEpJIAYAAKCU/j/grCQ7Atia+AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "from mawm.data.utils import plot_grid\n",
    "plot_grid(obs['agent_0']['pov'].astype(np.uint8), msgs['agent_0'].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe77daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 15, 15])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "obs_transformed = torch.stack([base_tf(obs[agent]['pov'].astype(np.uint8)) for agent in agents])\n",
    "encoded_obs = model.backbone(obs_transformed)\n",
    "encoded_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43db6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "pos = torch.stack([torch.from_numpy(obs[agent]['selfpos']) for agent in agents])\n",
    "pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04b2c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 18, 15, 15])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "encoded_obs = model.backbone(obs_transformed, position=pos)\n",
    "encoded_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db52b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 15, 15)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "model.backbone.repr_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a12a34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 15, 15])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "encoded_goals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2872f60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2187d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from mawm.models.misc import ObsPred, MsgPred\n",
    "from mawm.models.vision import SemanticEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256af2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "obs_pred = ObsPred(h_dim=32, out_channels=18)\n",
    "msg_pred = MsgPred(h_dim=32, in_channels=18)\n",
    "msg_encoder = SemanticEncoder(latent_dim=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5790dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# from mawm.models.utils import Expander2D\n",
    "# class CEMPlanner:\n",
    "#     def __init__(self, model, msg_enc, msg_pred, obs_pred, \n",
    "#                  action_dim= 5, horizon= 10, num_samples= 1000,\n",
    "#                  num_elites=100, opt_steps=100):\n",
    "        \n",
    "#         self.probs = torch.full((horizon, action_dim), 1.0/action_dim) # Uniform initial distribution of shape [Horizon, Action_Dim]\n",
    "#         self.model = model\n",
    "#         self.msg_enc = msg_enc\n",
    "#         self.msg_pred = msg_pred\n",
    "#         self.obs_pred = obs_pred\n",
    "#         self.action_dim = action_dim\n",
    "#         self.horizon = horizon\n",
    "#         self.num_samples = num_samples\n",
    "#         self.num_elites = num_elites\n",
    "#         self.opt_steps = opt_steps\n",
    "#         self.device = 'cpu'\n",
    "        \n",
    "\n",
    "#     def update_dist(self, probs, samples, costs, num_elites=50):\n",
    "\n",
    "#         values, elite_indices = torch.topk(-costs, num_elites)\n",
    "#         elites = samples[elite_indices] # [num_elites, Horizon]\n",
    "        \n",
    "#         # Update probabilities for the next round\n",
    "#         new_probs = torch.full_like(probs, 0.01 / probs.shape[-1])\n",
    "#         for t in range(probs.shape[0]):\n",
    "#             new_probs[t].scatter_add_(0, elites[:, t], torch.ones(num_elites) * (0.99 / num_elites))\n",
    "        \n",
    "#         best_plan = elites[0]\n",
    "        \n",
    "#         return new_probs, best_plan\n",
    "\n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def plan(self, o_t, pos_t, o_g, m_other, other_actions):\n",
    "#         z_t  = self.model.backbone(o_t.unsqueeze(0)) # [B=1, C, H, W] => [1, 16, 15, 15] #, position= pos_t.unsqueeze(0)\n",
    "#         pos_t = Expander2D(z_t.shape[-1], z_t.shape[-2])(pos_t.unsqueeze(0)) # [1, 2, 15, 15]\n",
    "#         z_t = torch.cat([z_t, pos_t], dim=1) # [1, 18, 15, 15]\n",
    "#         z_g = self.model.backbone(o_g.unsqueeze(0)) # [B=1, C, H, W] => [1, 16, 15, 15]\n",
    "\n",
    "#         a_self = torch.multinomial(self.probs, self.num_samples, replacement=True).T # [num_samples, horizon] \n",
    "        \n",
    "#         h0_other = self.msg_enc(m_other.unsqueeze(0).unsqueeze(1)) # [5, 7, 7] => [1, 1, 32]\n",
    "#         a_other = other_actions.repeat(self.num_samples, 1) # [num_samples, horizon]\n",
    "\n",
    "#         total_costs = self.evolve(z_t, z_g, h0_other, a_self, a_other)\n",
    "#         self.probs, best_plan = self.update_dist(self.probs, a_self, total_costs, self.num_elites)\n",
    "#         return best_plan\n",
    "\n",
    "#     def evolve(self, z_t, z_goal, h0_other, a_self, a_other):\n",
    "#         S = self.num_samples\n",
    "\n",
    "#         curr_z_self = repeat(z_t, 'b c h w -> (b s) t c h w', b= 1, s=S, t= 1) # [s, t= 1, c=18, h=15, w=15]\n",
    "#         curr_h_other = repeat(h0_other, 'b t d -> s t (b d)', s=S) # [s, 1, 32]\n",
    "        \n",
    "#         curr_z_other = self.obs_pred(curr_h_other)#[s, 1, 16, 15, 15]  \n",
    "#         curr_h_self = self.msg_pred(curr_z_self[:, :, :-2]) #[s, 1, 32]\n",
    "\n",
    "#         curr_z_self = rearrange(curr_z_self, \"s t c h w -> (t s) c h w\", t= 1)\n",
    "#         curr_z_other = rearrange(curr_z_other, \"s t c h w -> (t s) c h w\", t= 1)\n",
    "\n",
    "#         total_cost = torch.zeros(S, device=self.device)\n",
    "#         # import pdb; pdb.set_trace()\n",
    "#         for t in range(self.horizon):\n",
    "            \n",
    "#             curr_h_other = rearrange(curr_h_other, \"s t d -> (t s) d\", t= 1)\n",
    "#             curr_h_self = rearrange(curr_h_self, \"s t d -> (t s) d\", t= 1)\n",
    "\n",
    "#             a_self_t = a_self[:, t].unsqueeze(1) # [1 500]\n",
    "#             a_other_t = a_other[:, t].unsqueeze(1) # [1, 500]\n",
    "            \n",
    "\n",
    "#             next_z_self = self.model.dynamics.forward(current_state = curr_z_self, curr_action= a_self_t, curr_msg= curr_h_other)\n",
    "#             next_z_other = self.model.dynamics.forward(current_state = curr_z_other, curr_action= a_other_t, curr_msg= curr_h_self)\n",
    "\n",
    "#             next_h_self = self.msg_pred(rearrange(next_z_self[:, :-2], '(s t) c h w -> s t c h w ', t= 1))\n",
    "#             next_h_other = self.msg_pred(rearrange(next_z_other[:, :-2], '(s t) c h w -> s t c h w ', t= 1))\n",
    "\n",
    "#             total_cost += (next_z_self[:, :-2] - z_goal.unsqueeze(1)).pow(2).mean(dim=(2, 3, 4)).squeeze()\n",
    "\n",
    "#             curr_z_self, curr_z_other = next_z_self, next_z_other\n",
    "#             curr_h_self, curr_h_other = next_h_self, next_h_other\n",
    "\n",
    "#         return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bfe86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CellEmpty': 0, 'CellObstacle': 1, 'CellItem': 2, 'CellGoal': 3, 'CellAgent': 4, 'GoalAt': 5, 'ItemAt': 6, 'Near': 7, 'SeeGoal': 8, 'CanMove': 9, 'OtherAgentAt': 10, 'OtherAgentNear': 11, 'OtherAgentDirection': 12}\n"
     ]
    }
   ],
   "source": [
    "# #| export\n",
    "# from mawm.models.utils import Expander2D\n",
    "# import torch\n",
    "# from einops import repeat, rearrange\n",
    "\n",
    "# class CEMPlanner:\n",
    "#     def __init__(self, model, msg_enc, msg_pred, obs_pred, \n",
    "#                  action_dim=5, horizon=10, num_samples=1000,\n",
    "#                  num_elites=100, opt_steps=10): # Reduced opt_steps for speed, adjust as needed\n",
    "        \n",
    "#         self.model = model\n",
    "#         self.msg_enc = msg_enc\n",
    "#         self.msg_pred = msg_pred\n",
    "#         self.obs_pred = obs_pred\n",
    "#         self.action_dim = action_dim\n",
    "#         self.horizon = horizon\n",
    "#         self.num_samples = num_samples\n",
    "#         self.num_elites = num_elites\n",
    "#         self.opt_steps = opt_steps\n",
    "#         self.device = 'cpu'\n",
    "        \n",
    "#     def update_dist(self, probs, samples, costs, num_elites):\n",
    "#         # Find indices of samples with the lowest cost\n",
    "#         # topk on negative costs gives us the minimum values\n",
    "#         _, elite_indices = torch.topk(-costs, num_elites)\n",
    "#         elites = samples[elite_indices] # [num_elites, horizon]\n",
    "        \n",
    "#         # Create a fresh probability distribution based on elite actions\n",
    "#         new_probs = torch.zeros_like(probs)\n",
    "#         for t in range(self.horizon):\n",
    "#             # Count how often each action appeared in the elite set at time t\n",
    "#             counts = torch.bincount(elites[:, t], minlength=self.action_dim).float()\n",
    "#             new_probs[t] = counts / num_elites\n",
    "        \n",
    "#         # Apply smoothing (Laplace smoothing) to prevent 0-probability actions\n",
    "#         # This keeps the distribution \"open\" for the next opt_step\n",
    "#         epsilon = 0.01\n",
    "#         new_probs = (1 - epsilon) * new_probs + (epsilon / self.action_dim)\n",
    "        \n",
    "#         best_plan = elites[0]\n",
    "#         return new_probs, best_plan\n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def plan(self, o_t, pos_t, o_g, m_other, other_actions):\n",
    "#         # 1. INITIALIZE: Reset distribution to uniform at the start of every plan call\n",
    "#         # This ensures we don't carry over bias from previous environment steps.\n",
    "#         current_probs = torch.full((self.horizon, self.action_dim), 1.0/self.action_dim, device=self.device)\n",
    "\n",
    "#         # 2. ENCODE: Prepare latent states once\n",
    "#         z_t = self.model.backbone(o_t.unsqueeze(0)) \n",
    "#         pos_t_expanded = Expander2D(z_t.shape[-1], z_t.shape[-2])(pos_t.unsqueeze(0))\n",
    "#         z_t = torch.cat([z_t, pos_t_expanded], dim=1) \n",
    "#         z_g = self.model.backbone(o_g.unsqueeze(0)) \n",
    "        \n",
    "#         h0_other = self.msg_enc(m_other.unsqueeze(0).unsqueeze(1)) \n",
    "#         # The other agent's plan is treated as a fixed anchor for this optimization cycle\n",
    "#         a_other = other_actions.repeat(self.num_samples, 1) \n",
    "\n",
    "#         # 3. OPTIMIZE: The CEM Loop (Step 'f' in your paper)\n",
    "#         best_plan = None\n",
    "#         for _ in range(self.opt_steps):\n",
    "#             # Sample sequences from current distribution\n",
    "#             # Shape: [num_samples, horizon]\n",
    "#             a_self = torch.multinomial(current_probs, self.num_samples, replacement=True).T \n",
    "            \n",
    "#             # Evaluate samples using the world model\n",
    "#             total_costs = self.evolve(z_t, z_g, h0_other, a_self, a_other)\n",
    "            \n",
    "#             # Update the distribution to focus on low-cost regions\n",
    "#             current_probs, best_plan = self.update_dist(current_probs, a_self, total_costs, self.num_elites)\n",
    "\n",
    "#         return best_plan\n",
    "\n",
    "#     def evolve(self, z_t, z_goal, h0_other, a_self, a_other):\n",
    "#         S = self.num_samples\n",
    "#         # ... (Your existing evolve logic remains the same) ...\n",
    "#         curr_z_self = repeat(z_t, 'b c h w -> (b s) t c h w', b= 1, s=S, t= 1)\n",
    "#         curr_h_other = repeat(h0_other, 'b t d -> s t (b d)', s=S)\n",
    "        \n",
    "#         curr_z_other = self.obs_pred(curr_h_other)  \n",
    "#         curr_h_self = self.msg_pred(curr_z_self[:, :, :-2]) \n",
    "\n",
    "#         curr_z_self = rearrange(curr_z_self, \"s t c h w -> (t s) c h w\", t= 1)\n",
    "#         curr_z_other = rearrange(curr_z_other, \"s t c h w -> (t s) c h w\", t= 1)\n",
    "\n",
    "#         total_cost = torch.zeros(S, device=self.device)\n",
    "        \n",
    "#         for t in range(self.horizon):\n",
    "#             curr_h_other = rearrange(curr_h_other, \"s t d -> (t s) d\", t= 1)\n",
    "#             curr_h_self = rearrange(curr_h_self, \"s t d -> (t s) d\", t= 1)\n",
    "\n",
    "#             a_self_t = a_self[:, t].unsqueeze(1) \n",
    "#             a_other_t = a_other[:, t].unsqueeze(1) \n",
    "            \n",
    "#             next_z_self = self.model.dynamics.forward(current_state=curr_z_self, curr_action=a_self_t, curr_msg=curr_h_other)\n",
    "#             next_z_other = self.model.dynamics.forward(current_state=curr_z_other, curr_action=a_other_t, curr_msg=curr_h_self)\n",
    "\n",
    "#             next_h_self = self.msg_pred(rearrange(next_z_self[:, :-2], '(s t) c h w -> s t c h w ', t= 1))\n",
    "#             next_h_other = self.msg_pred(rearrange(next_z_other[:, :-2], '(s t) c h w -> s t c h w ', t= 1))\n",
    "\n",
    "#             # Cost calculation: MSE to goal\n",
    "#             total_cost += (next_z_self[:, :-2] - z_goal).pow(2).mean(dim=(1, 2, 3))\n",
    "\n",
    "#             curr_z_self, curr_z_other = next_z_self, next_z_other\n",
    "#             curr_h_self, curr_h_other = next_h_self, next_h_other\n",
    "\n",
    "#         return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a2811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# from mawm.models.utils import Expander2D\n",
    "# import torch\n",
    "# from einops import repeat, rearrange\n",
    "\n",
    "# class CEMPlanner:\n",
    "#     def __init__(self, model, msg_enc, msg_pred, obs_pred, \n",
    "#                  action_dim=5, horizon=10, num_samples=1000,\n",
    "#                  num_elites=100, opt_steps=10):\n",
    "        \n",
    "#         self.model = model\n",
    "#         self.msg_enc = msg_enc\n",
    "#         self.msg_pred = msg_pred\n",
    "#         self.obs_pred = obs_pred\n",
    "#         self.action_dim = action_dim # Number of discrete choices (0-4)\n",
    "#         self.horizon = horizon\n",
    "#         self.num_samples = num_samples\n",
    "#         self.num_elites = num_elites\n",
    "#         self.opt_steps = opt_steps\n",
    "#         self.device = 'cpu'\n",
    "        \n",
    "#     def update_dist(self, probs, samples, costs, num_elites):\n",
    "#         # We want to MINIMIZE cost, so we take the topk of negative costs\n",
    "#         _, elite_indices = torch.topk(-costs, num_elites)\n",
    "#         elites = samples[elite_indices] # [num_elites, horizon]\n",
    "        \n",
    "#         new_probs = torch.zeros_like(probs)\n",
    "#         for t in range(self.horizon):\n",
    "#             counts = torch.bincount(elites[:, t], minlength=self.action_dim).float()\n",
    "#             new_probs[t] = counts / num_elites\n",
    "        \n",
    "#         # Laplace smoothing to ensure we always have some exploration noise\n",
    "#         epsilon = 0.01\n",
    "#         new_probs = (1 - epsilon) * new_probs + (epsilon / self.action_dim)\n",
    "        \n",
    "#         return new_probs, elites[0]\n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def plan(self, o_t, pos_t, o_g, m_other, other_actions):\n",
    "#         # RESET: Start fresh so we don't get stuck in a local minimum from the last step\n",
    "#         current_probs = torch.full((self.horizon, self.action_dim), 1.0/self.action_dim, device=self.device)\n",
    "\n",
    "#         z_t = self.model.backbone(o_t.unsqueeze(0)) \n",
    "#         pos_t_expanded = Expander2D(z_t.shape[-1], z_t.shape[-2])(pos_t.unsqueeze(0))\n",
    "#         z_t = torch.cat([z_t, pos_t_expanded], dim=1) \n",
    "#         z_g = self.model.backbone(o_g.unsqueeze(0)) \n",
    "        \n",
    "#         h0_other = self.msg_enc(m_other.unsqueeze(0).unsqueeze(1)) \n",
    "#         a_other = other_actions.repeat(self.num_samples, 1) \n",
    "\n",
    "#         best_plan = None\n",
    "#         for i in range(self.opt_steps):\n",
    "#             # Sample sequences: [num_samples, horizon]\n",
    "#             a_self = torch.multinomial(current_probs, self.num_samples, replacement=True).T \n",
    "            \n",
    "#             total_costs = self.evolve(z_t, z_g, h0_other, a_self, a_other)\n",
    "            \n",
    "#             # DEBUG: Uncomment this to see if costs are actually changing\n",
    "#             if i == 0: print(f\"Cost Std: {total_costs.std():.6f}, Min: {total_costs.min():.4f}\")\n",
    "\n",
    "#             current_probs, best_plan = self.update_dist(current_probs, a_self, total_costs, self.num_elites)\n",
    "\n",
    "#         return best_plan\n",
    "\n",
    "#     def evolve(self, z_t, z_goal, h0_other, a_self, a_other):\n",
    "#         S = self.num_samples\n",
    "        \n",
    "#         # Ensure z_goal is ready for broadcasting: [1, C, H, W]\n",
    "#         # We strip the last 2 channels if your goal doesn't include the pos_t expansion\n",
    "#         z_goal_target = z_goal \n",
    "\n",
    "#         curr_z_self = repeat(z_t, 'b c h w -> (b s) c h w', s=S)\n",
    "#         curr_h_other = repeat(h0_other, 'b t d -> (s b t) d', s=S)\n",
    "        \n",
    "#         # Initial imagined states for the other agent\n",
    "#         curr_z_other = rearrange(self.obs_pred(curr_h_other.unsqueeze(1)), \"s t c h w -> (s t) c h w\")\n",
    "#         curr_h_self = self.msg_pred(curr_z_self[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "\n",
    "#         total_cost = torch.zeros(S, device=self.device)\n",
    "        \n",
    "#         for t in range(self.horizon):\n",
    "#             a_self_t = a_self[:, t].unsqueeze(1) # [S, 1]\n",
    "#             a_other_t = a_other[:, t].unsqueeze(1) # [S, 1]\n",
    "            \n",
    "#             # Forward dynamics\n",
    "#             next_z_self = self.model.dynamics.forward(current_state=curr_z_self, curr_action=a_self_t, curr_msg=curr_h_other)\n",
    "#             next_z_other = self.model.dynamics.forward(current_state=curr_z_other, curr_action=a_other_t, curr_msg=curr_h_self)\n",
    "\n",
    "#             # Predict next messages\n",
    "#             curr_h_self = self.msg_pred(next_z_self[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "#             curr_h_other = self.msg_pred(next_z_other[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "\n",
    "#             # --- CRITICAL: Cost calculation ---\n",
    "#             # Compare only the latent state (excluding position channels if necessary)\n",
    "#             # next_z_self[:, :-2] is [S, 16, 15, 15]\n",
    "#             # z_goal_target is [1, 16, 15, 15]\n",
    "#             diff = next_z_self[:, :-2] - z_goal_target\n",
    "            \n",
    "#             # Step-wise cost (MSE)\n",
    "#             total_cost += diff.pow(2).mean(dim=(1, 2, 3))\n",
    "\n",
    "#             curr_z_self, curr_z_other = next_z_self, next_z_other\n",
    "\n",
    "#         return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bf002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from einops import repeat, rearrange\n",
    "from mawm.models.utils import Expander2D\n",
    "\n",
    "class CEMPlanner:\n",
    "    def __init__(self, model, msg_enc, msg_pred, obs_pred, \n",
    "                 action_dim=5, horizon=10, num_samples=1000,\n",
    "                 num_elites=100, opt_steps=10, device='cpu'):\n",
    "        \n",
    "        self.model = model\n",
    "        self.msg_enc = msg_enc\n",
    "        self.msg_pred = msg_pred\n",
    "        self.obs_pred = obs_pred\n",
    "        self.action_dim = action_dim\n",
    "        self.horizon = horizon\n",
    "        self.num_samples = num_samples\n",
    "        self.num_elites = num_elites\n",
    "        self.opt_steps = opt_steps\n",
    "        self.device = device\n",
    "        \n",
    "        # Hyperparameters for improved stability\n",
    "        self.alpha = 0.3  # Momentum for distribution update\n",
    "        self.epsilon = 0.01  # Laplace smoothing\n",
    "        self.temp_start = 1.0  # Initial temperature\n",
    "        self.temp_end = 0.5  # Final temperature\n",
    "        \n",
    "    def update_dist(self, probs, samples, costs, num_elites, iteration):\n",
    "        \"\"\"Update probability distribution using elite samples with momentum.\"\"\"\n",
    "        # Select elites (minimize cost)\n",
    "        _, elite_indices = torch.topk(-costs, num_elites)\n",
    "        elites = samples[elite_indices]\n",
    "        \n",
    "        # Compute empirical distribution from elites\n",
    "        empirical_probs = torch.zeros_like(probs)\n",
    "        for t in range(self.horizon):\n",
    "            counts = torch.bincount(elites[:, t], minlength=self.action_dim).float()\n",
    "            empirical_probs[t] = counts / num_elites\n",
    "        \n",
    "        # Momentum update for stability\n",
    "        new_probs = self.alpha * empirical_probs + (1 - self.alpha) * probs\n",
    "        \n",
    "        # Laplace smoothing\n",
    "        new_probs = (1 - self.epsilon) * new_probs + (self.epsilon / self.action_dim)\n",
    "        \n",
    "        # Temperature annealing for sharpening\n",
    "        temp = self.temp_start + (self.temp_end - self.temp_start) * (iteration / self.opt_steps)\n",
    "        new_probs = new_probs ** (1 / temp)\n",
    "        new_probs = new_probs / new_probs.sum(dim=1, keepdim=True)\n",
    "        \n",
    "        return new_probs, elites[0]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def plan(self, o_t, o_g, pos_t, m_other, other_actions):\n",
    "        \"\"\"Plan action sequence using CEM.\"\"\"\n",
    "        # Move inputs to device\n",
    "        o_t = o_t.to(self.device)\n",
    "        o_g = o_g.to(self.device)\n",
    "        pos_t = pos_t.to(self.device)\n",
    "        m_other = m_other.to(self.device)\n",
    "        other_actions = other_actions.to(self.device)\n",
    "        \n",
    "        # Initialize uniform distribution\n",
    "        current_probs = torch.full(\n",
    "            (self.horizon, self.action_dim), \n",
    "            1.0 / self.action_dim, \n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "        # Encode current state and goal\n",
    "        z_t = self.model.backbone(o_t.unsqueeze(0))\n",
    "        pos_t_expanded = Expander2D(z_t.shape[-1], z_t.shape[-2])(pos_t.unsqueeze(0))\n",
    "        z_t = torch.cat([z_t, pos_t_expanded], dim=1)\n",
    "        \n",
    "        z_g = self.model.backbone(o_g.unsqueeze(0))\n",
    "        # Match dimensions with cost calculation (exclude position channels)\n",
    "        z_goal_target = z_g#[:, :-2]\n",
    "        \n",
    "        # Encode other agent's message\n",
    "        h0_other = self.msg_enc(m_other.unsqueeze(0).unsqueeze(1))\n",
    "        a_other = other_actions.repeat(self.num_samples, 1)\n",
    "\n",
    "        best_plan = None\n",
    "        best_cost = float('inf')\n",
    "        \n",
    "        for i in range(self.opt_steps):\n",
    "            # Sample action sequences\n",
    "            a_self = torch.multinomial(\n",
    "                current_probs, \n",
    "                self.num_samples, \n",
    "                replacement=True\n",
    "            ).T.to(self.device)\n",
    "            \n",
    "            # Evaluate sampled sequences\n",
    "            total_costs = self.evolve(z_t, z_goal_target, h0_other, a_self, a_other)\n",
    "            \n",
    "            # Track best solution\n",
    "            min_cost = total_costs.min()\n",
    "            if min_cost < best_cost:\n",
    "                best_cost = min_cost\n",
    "                best_idx = total_costs.argmin()\n",
    "                best_plan = a_self[best_idx]\n",
    "            \n",
    "            # Debug info\n",
    "            if i == 0 or i == self.opt_steps - 1:\n",
    "                print(f\"Iter {i}: Cost ={total_costs.mean():.4f}, \"\n",
    "                      f\"Std={total_costs.std():.4f}, min={min_cost:.4f}\")\n",
    "\n",
    "            # Update distribution\n",
    "            current_probs, _ = self.update_dist(\n",
    "                current_probs, a_self, total_costs, self.num_elites, i\n",
    "            )\n",
    "\n",
    "        return best_plan\n",
    "\n",
    "    def evolve(self, z_t, z_goal, h0_other, a_self, a_other):\n",
    "        \"\"\"Roll out trajectories and compute costs.\"\"\"\n",
    "        S = self.num_samples\n",
    "        \n",
    "        # Initialize states\n",
    "        curr_z_self = repeat(z_t, 'b c h w -> (b s) c h w', s=S)\n",
    "        curr_h_other = repeat(h0_other, 'b t d -> (s b t) d', s=S)\n",
    "        \n",
    "        curr_z_other = rearrange(\n",
    "            self.obs_pred(curr_h_other.unsqueeze(1)), \n",
    "            \"s t c h w -> (s t) c h w\"\n",
    "        )\n",
    "        curr_h_self = self.msg_pred(curr_z_self[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        total_cost = torch.zeros(S, device=self.device)\n",
    "        \n",
    "        # Roll out trajectories\n",
    "        for t in range(self.horizon):\n",
    "            a_self_t = a_self[:, t].unsqueeze(1)\n",
    "            a_other_t = a_other[:, t].unsqueeze(1)\n",
    "            \n",
    "            # Forward dynamics\n",
    "            next_z_self = self.model.dynamics.forward(\n",
    "                current_state=curr_z_self, \n",
    "                curr_action=a_self_t, \n",
    "                curr_msg=curr_h_other\n",
    "            )\n",
    "            next_z_other = self.model.dynamics.forward(\n",
    "                current_state=curr_z_other, \n",
    "                curr_action=a_other_t, \n",
    "                curr_msg=curr_h_self\n",
    "            )\n",
    "\n",
    "            # Update messages\n",
    "            curr_h_self = self.msg_pred(next_z_self[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "            curr_h_other = self.msg_pred(next_z_other[:, :-2].unsqueeze(1)).squeeze(1)\n",
    "\n",
    "            # Compute step cost (MSE to goal)\n",
    "            diff = next_z_self[:, :-2] - z_goal\n",
    "            step_cost = diff.pow(2).mean(dim=(1, 2, 3))\n",
    "            \n",
    "            # Weight final timestep more heavily\n",
    "            weight = 2.0 if t == self.horizon - 1 else 1.0\n",
    "            total_cost += weight * step_cost\n",
    "\n",
    "            curr_z_self, curr_z_other = next_z_self, next_z_other\n",
    "\n",
    "        return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33cd258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "planner = CEMPlanner(model=model, msg_enc= msg_encoder, msg_pred=msg_pred, obs_pred=obs_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9672bd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "torch.manual_seed(0)\n",
    "probs_j = torch.full((planner.horizon, planner.action_dim), 1.0/planner.action_dim)\n",
    "other_actions = torch.multinomial(probs_j, 1).squeeze(-1)  # [Horizon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa548c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 1, 4, 0, 4, 0, 0, 1, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009357a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T =  0\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "T =  1\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "T =  2\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "T =  3\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "T =  4\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "T =  5\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "T =  6\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "T =  7\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "T =  8\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "T =  9\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 1]) torch.Size([1000, 32]) torch.Size([1000, 18, 15, 15])\n",
      "torch.Size([1000, 18, 15, 15])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 3, 0, 3, 4, 0, 0, 1, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #| hide\n",
    "# from einops import rearrange, repeat\n",
    "# planner.plan(obs_transformed[0], pos[0], o_g=goals[0], m_other=msgs['agent_0'], other_actions=other_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ece34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3f4ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "nbdev.nbdev_export() # type: ignore  # noqa: E702\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
