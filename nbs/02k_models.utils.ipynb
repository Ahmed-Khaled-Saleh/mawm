{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models utilities module\n",
    "\n",
    "> This module handles all aspects of the world model, including state representation, environment dynamics, and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore import *\n",
    "from fastcore.utils import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from torch import nn\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def flatten_conv_output(x):\n",
    "    if len(x.shape) > 3:\n",
    "        if len(x.shape) == 4:\n",
    "            bs, ch, h, w = x.shape\n",
    "            return x.view(bs, -1)\n",
    "        elif len(x.shape) == 5:\n",
    "            t, bs, ch, h, w = x.shape\n",
    "            return x.view(t, bs, -1)\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "\n",
    "def build_conv(layers_config, input_dim=None, apply_norm=True):\n",
    "    input_channels = input_dim[0]\n",
    "    layers = []\n",
    "    for i in range(len(layers_config) - 1):\n",
    "        if isinstance(layers_config[i][0], str) and \"pool\" in layers_config[i][0]:\n",
    "            _, kernel_size, stride, padding = layers_config[i]\n",
    "\n",
    "            if layers_config[i][0] == \"avg_pool\":\n",
    "                pool_layer = nn.AvgPool2d(\n",
    "                    kernel_size=kernel_size, stride=stride, padding=padding\n",
    "                )\n",
    "            elif layers_config[i][0] == \"max_pool\":\n",
    "                pool_layer = nn.MaxPool2d(\n",
    "                    kernel_size=kernel_size, stride=stride, padding=padding\n",
    "                )\n",
    "            layers.append(pool_layer)\n",
    "        elif layers_config[i][0] == \"pad\":\n",
    "            _, padding = layers_config[i]\n",
    "            layers.append(nn.ZeroPad2d(padding))\n",
    "        else:\n",
    "            in_channels, out_channels, kernel_size, stride, padding = layers_config[i]\n",
    "\n",
    "            # we override input_channels for first layer with explicit argument\n",
    "            if i == 0:\n",
    "                in_channels = input_channels\n",
    "\n",
    "            layers.append(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "            )\n",
    "            if apply_norm:\n",
    "                layers.append(nn.GroupNorm(out_channels // 4, out_channels))\n",
    "            layers.append(nn.ReLU())\n",
    "\n",
    "    # last layer\n",
    "    last_layer_config = layers_config[-1]\n",
    "    if last_layer_config[0] == \"fc\":\n",
    "        _, fc_in_dim, fc_out_dim = last_layer_config\n",
    "\n",
    "        if fc_in_dim == -1:\n",
    "            # we need to infer this\n",
    "            prev_conv_net = nn.Sequential(*layers)\n",
    "            sample_input = torch.rand(input_dim).unsqueeze(0)\n",
    "            sample_output = prev_conv_net(sample_input)\n",
    "            prev_conv_net = None\n",
    "            fc_in_dim = torch.prod(torch.tensor(sample_output.shape)).item()\n",
    "\n",
    "        layers.append(nn.Flatten(1, -1))\n",
    "        layers.append(nn.Linear(fc_in_dim, fc_out_dim))\n",
    "    elif isinstance(last_layer_config[0], str) and \"pool\" in last_layer_config[0]:\n",
    "        _, kernel_size, stride, padding = last_layer_config\n",
    "        if last_layer_config[0] == \"avg_pool\":\n",
    "            pool_layer = nn.AvgPool2d(\n",
    "                kernel_size=kernel_size, stride=stride, padding=padding\n",
    "            )\n",
    "        elif last_layer_config[0] == \"max_pool\":\n",
    "            pool_layer = nn.MaxPool2d(\n",
    "                kernel_size=kernel_size, stride=stride, padding=padding\n",
    "            )\n",
    "        layers.append(pool_layer)\n",
    "    else:\n",
    "        in_channels, out_channels, kernel_size, stride, padding = last_layer_config\n",
    "        layers.append(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        )\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from torch import nn\n",
    "class Expander2D(nn.Module):\n",
    "    \"\"\"\n",
    "    This class takes in input of shape (..., n) and expand it into planes (..., n, w, h)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, w, h):\n",
    "        super(Expander2D, self).__init__()\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape to (..., n, 1, 1)\n",
    "        x = x.unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        # TODO: TO REMOVE THIS HACK LATER\n",
    "        # if x.shape[1] > 2:\n",
    "        #     x = x[:, :2]\n",
    "\n",
    "        # Calculate the number of dimensions excluding the last 2\n",
    "        num_dims = x.dim() - 2\n",
    "\n",
    "        # Create a repeat pattern that matches the number of dimensions\n",
    "        repeat_pattern = [1] * num_dims + [self.w, self.h]\n",
    "\n",
    "        # Repeat the last two dimensions to create the (w, h) planes\n",
    "        x = x.repeat(*repeat_pattern)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "x = torch.randn(4, 1) # (B, 1)\n",
    "expander = Expander2D(26, 26)\n",
    "expanded_x = expander(x)\n",
    "expanded_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_checkpoint(state, is_best, filename, best_filename):\n",
    "    \"\"\" Save state in filename. Also save in best_filename if is_best. \"\"\"\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        torch.save(state, best_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
