{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities for data \n",
    "\n",
    "> This module handles all communication-related functionalities, including message passing, event handling, and notifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore import *\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import math\n",
    "from os.path import join, exists\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "ASIZE, LSIZE, RSIZE, RED_SIZE, SIZE =\\\n",
    "    3, 32, 256, 32, 40\n",
    "\n",
    "# transform_train = transforms.Compose([\n",
    "#     transforms.ToPILImage(),\n",
    "#     transforms.Resize((RED_SIZE, RED_SIZE)),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((RED_SIZE, RED_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                         (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((RED_SIZE, RED_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                         (0.5, 0.5, 0.5)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "lejepa_train_tf = v2.Compose(\n",
    "    [\n",
    "        v2.ToPILImage(),\n",
    "        v2.RandomResizedCrop(42, scale=(0.8, 1.0)), \n",
    "        v2.RandomApply([v2.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "        v2.RandomGrayscale(p=0.2),\n",
    "        # Reduced kernel size for smaller image resolution\n",
    "        v2.RandomApply([v2.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))], p=0.1),\n",
    "        v2.RandomHorizontalFlip(),\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        # Normalizes to [-1, 1] to match Tanh output\n",
    "        v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "lejepa_test_tf = v2.Compose(\n",
    "            [\n",
    "                v2.ToPILImage(),\n",
    "                v2.Resize(42),\n",
    "                v2.CenterCrop(42),\n",
    "                v2.ToImage(),\n",
    "                v2.ToDtype(torch.float32, scale=True),\n",
    "                v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "class BufferAwareConcatDataset(ConcatDataset):\n",
    "    \"\"\"\n",
    "    A ConcatDataset wrapper that provides a method to call \n",
    "    load_next_buffer() on all its constituent datasets.\n",
    "    \"\"\"\n",
    "    def load_next_buffer(self):\n",
    "        \"\"\"\n",
    "        Iterates through all underlying datasets and calls their \n",
    "        load_next_buffer method.\n",
    "        \"\"\"\n",
    "        for dataset in self.datasets:\n",
    "            # Check if the method exists to be safe, though \n",
    "            # in your context, it should exist on all of them.\n",
    "            if hasattr(dataset, 'load_next_buffer'):\n",
    "                dataset.load_next_buffer()\n",
    "            else:\n",
    "                # Optionally, you can raise an error or log a warning \n",
    "                # if a dataset is missing the expected method\n",
    "                print(f\"Warning: Dataset {type(dataset)} is missing load_next_buffer()\")\n",
    "                \n",
    "        self.cumulative_sizes = self.cumsum(self.datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
