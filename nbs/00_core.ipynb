{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- Collect random trajectories from the environment.\n",
    "- Train an encoder using VAE on the collected trajectories.\n",
    "- End-to-end training of the world model and communication module using the trained encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import importlib\n",
    "def get_cls(module_name, class_name):\n",
    "    module = importlib.import_module(module_name)\n",
    "    return getattr(module, class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "Z_DIM = 32\n",
    "ACTION_DIM = 1\n",
    "PROG_HID = 128\n",
    "PRIM_EMB = 32\n",
    "PARAM_EMB = 16\n",
    "PROG_RNN_HID = 128\n",
    "MSG_DIM = 32#23\n",
    "MAX_PARAMS = 2        # maximum params per primitive; everything is padded to this\n",
    "GRID_SIZE = 5\n",
    "BEAM_WIDTH = 5\n",
    "PROP_TOPK = 6\n",
    "MAX_PROG_LEN = 5\n",
    "LAMBDA_Z = 1.0\n",
    "LAMBDA_R = 1.0\n",
    "LEARNING_RATE = 1e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CellEmpty': 0, 'CellObstacle': 1, 'CellItem': 2, 'CellGoal': 3, 'CellAgent': 4, 'GoalAt': 5, 'ItemAt': 6, 'Near': 7, 'SeeGoal': 8, 'CanMove': 9, 'OtherAgentAt': 10, 'OtherAgentNear': 11, 'OtherAgentDirection': 12}\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "# -------------------------\n",
    "# Primitive templates (name, arity)\n",
    "# -------------------------\n",
    "PRIMITIVE_TEMPLATES = [\n",
    "    (\"CellEmpty\", 2),        # cell (i, j) is empty\n",
    "    (\"CellObstacle\", 2),\n",
    "    (\"CellItem\", 2),\n",
    "    (\"CellGoal\", 2),\n",
    "    (\"CellAgent\", 2),\n",
    "    # (\"AgentAt\", 2),\n",
    "    (\"GoalAt\", 2),\n",
    "    # (\"ObstacleAt\", 2),\n",
    "    (\"ItemAt\", 2),\n",
    "    (\"Near\", 0),       # boolean style (no params)\n",
    "    (\"SeeGoal\", 0),\n",
    "    (\"CanMove\", 1),    # direction (0..3)\n",
    "    (\"OtherAgentAt\", 2),\n",
    "    (\"OtherAgentNear\", 0),\n",
    "    (\"OtherAgentDirection\", 1)\n",
    "\n",
    "]\n",
    "PRIM_NAME_TO_IDX = {name: i for i, (name, ar) in enumerate(PRIMITIVE_TEMPLATES)}\n",
    "NUM_PRIMS = len(PRIMITIVE_TEMPLATES)\n",
    "# print(PRIM_NAME_TO_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# -------------------------\n",
    "# Program representation\n",
    "# -------------------------\n",
    "class Program:\n",
    "    def __init__(self, tokens: List[Tuple[int, List[float]]] = None, finished: bool = False):\n",
    "        # tokens: list of (prim_idx, params_list)\n",
    "        self.tokens = tokens or []\n",
    "        self.EOS_IDX = len(PRIMITIVE_TEMPLATES)\n",
    "        self.finished = finished\n",
    "\n",
    "\n",
    "    # def extend(self, prim_idx: int, params: List[float]):\n",
    "    #     return Program(self.tokens + [(int(prim_idx), [float(p) for p in params])])\n",
    "    def extend(self, prim_idx, params):\n",
    "        if self.finished:\n",
    "            return self  # don't extend finished programs\n",
    "        if prim_idx == self.EOS_IDX:\n",
    "            return Program(self.tokens, finished=True)\n",
    "        return Program(self.tokens + [(prim_idx, params)], finished=False)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "\n",
    "    def __repr__(self):\n",
    "        if len(self.tokens) == 0:\n",
    "            return \"<EMPTY>\"\n",
    "        elif len(self.tokens) == 1 and self.tokens[0][0] == -1:\n",
    "            return \"<BOP>\"\n",
    "        \n",
    "        toks = []\n",
    "        for pidx, params in self.tokens:\n",
    "            name = PRIMITIVE_TEMPLATES[pidx][0]\n",
    "            toks.append(f\"{name}{tuple(params)}\")\n",
    "        return \" | \".join(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentAt(1.0, 2.0) | Near() | GoalAt(3.0, 4.0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = Program(tokens=[(0, [1.0, 2.0]), (4, []), (1, [3.0, 4.0])])\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentAt(1.0, 2.0) | Near() | GoalAt(3.0, 4.0) | ObstacleAt(5.0, 6.0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = P.extend(2, [5.0, 6.0])\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import argparse\n",
    "import dataclasses\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from typing import Any, Iterable, Tuple, Union, cast, List\n",
    "\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "DataClass = Any\n",
    "DataClassType = Any\n",
    "class DataclassArgParser(argparse.ArgumentParser):\n",
    "    \"\"\"A class for handling dataclasses and argument parsing.\n",
    "    Closely based on Hugging Face's HfArgumentParser class,\n",
    "    extended to support recursive dataclasses.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataclass_types: Union[DataClassType, Iterable[DataClassType]],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataclass_types:\n",
    "                Dataclass type, or list of dataclass types for which we will\n",
    "                \"fill\" instances with the parsed args.\n",
    "            kwargs:\n",
    "                (Optional) Passed to `argparse.ArgumentParser()` in the regular\n",
    "                way.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        if dataclasses.is_dataclass(dataclass_types):\n",
    "            dataclass_types = cast(DataClassType, dataclass_types)\n",
    "            dataclass_types = [dataclass_types]\n",
    "        self.dataclass_types = cast(Iterable[DataClassType], dataclass_types)\n",
    "        for dtype in self.dataclass_types:\n",
    "            self._add_dataclass_arguments(dtype)\n",
    "\n",
    "    def _add_dataclass_arguments(self, dtype: DataClassType):\n",
    "        for f in dataclasses.fields(dtype):\n",
    "            field_name = f\"--{f.name}\"\n",
    "            kwargs = dict(f.metadata).copy()\n",
    "            typestring = str(f.type)\n",
    "            for x in (int, float, str):\n",
    "                if typestring == f\"typing.Union[{x.__name__}, NoneType]\":\n",
    "                    f.type = x\n",
    "            if isinstance(f.type, type) and issubclass(f.type, Enum):\n",
    "                kwargs[\"choices\"] = list(f.type)\n",
    "                kwargs[\"type\"] = f.type\n",
    "                if f.default is not dataclasses.MISSING:\n",
    "                    kwargs[\"default\"] = f.default\n",
    "            elif f.type is bool:\n",
    "                kwargs[\"action\"] = \"store_false\" if f.default is True else \"store_true\"\n",
    "                if f.default is True:\n",
    "                    field_name = f\"--no-{f.name}\"\n",
    "                    kwargs[\"dest\"] = f.name\n",
    "            elif dataclasses.is_dataclass(f.type):\n",
    "                self._add_dataclass_arguments(f.type)\n",
    "            else:\n",
    "                kwargs[\"type\"] = f.type\n",
    "                if f.default is not dataclasses.MISSING:\n",
    "                    kwargs[\"default\"] = f.default\n",
    "                else:\n",
    "                    kwargs[\"required\"] = True\n",
    "            self.add_argument(field_name, **kwargs)\n",
    "\n",
    "    def parse_args_into_dataclasses(\n",
    "        self,\n",
    "        args=None,\n",
    "    ) -> Tuple[DataClass, ...]:\n",
    "        \"\"\"\n",
    "        Parse command-line args into instances of the specified dataclass\n",
    "        types.  This relies on argparse's `ArgumentParser.parse_known_args`.\n",
    "        See the doc at:\n",
    "        docs.python.org/3.7/library/argparse.html#argparse.ArgumentParser.parse_args\n",
    "        Args:\n",
    "            args:\n",
    "                List of strings to parse. The default is taken from sys.argv.\n",
    "                (same as argparse.ArgumentParser)\n",
    "        Returns:\n",
    "            Tuple consisting of:\n",
    "                - the dataclass instances in the same order as they\n",
    "                  were passed to the initializer.abspath\n",
    "                - if applicable, an additional namespace for more\n",
    "                  (non-dataclass backed) arguments added to the parser\n",
    "                  after initialization.\n",
    "                - The potential list of remaining argument strings.\n",
    "                  (same as argparse.ArgumentParser.parse_known_args)\n",
    "        \"\"\"\n",
    "        namespace, unknown = self.parse_known_args(args=args)\n",
    "        outputs = []\n",
    "\n",
    "        for dtype in self.dataclass_types:\n",
    "            outputs.append(self._populate_dataclass(dtype, namespace))\n",
    "        if len(namespace.__dict__) > 0:\n",
    "            # additional namespace.\n",
    "            outputs.append(namespace)\n",
    "        if len(unknown) > 0:\n",
    "            outputs.append(unknown)\n",
    "        return tuple(outputs)\n",
    "\n",
    "    @staticmethod\n",
    "    def _populate_dataclass(dtype: DataClassType, namespace: argparse.Namespace):\n",
    "        keys = {f.name for f in dataclasses.fields(dtype)}\n",
    "        inputs = {k: v for k, v in vars(namespace).items() if k in keys}\n",
    "        for k in keys:\n",
    "            delattr(namespace, k)\n",
    "        sub_dataclasses = {\n",
    "            f.name: f.type\n",
    "            for f in dataclasses.fields(dtype)\n",
    "            if dataclasses.is_dataclass(f.type)\n",
    "        }\n",
    "        for k, s in sub_dataclasses.items():\n",
    "            inputs[k] = DataclassArgParser._populate_dataclass(s, namespace)\n",
    "        obj = dtype(**inputs)\n",
    "        return obj\n",
    "\n",
    "    @staticmethod\n",
    "    def _populate_dataclass_from_dict(dtype: DataClassType, d: dict):\n",
    "        d = DataclassArgParser.legacy_transform_dict(d.copy())\n",
    "        keys = {f.name for f in dataclasses.fields(dtype)}\n",
    "        inputs = {k: v for k, v in d.items() if k in keys}\n",
    "        for k in keys:\n",
    "            if k in d:\n",
    "                del d[k]\n",
    "        sub_dataclasses = {\n",
    "            f.name: f.type\n",
    "            for f in dataclasses.fields(dtype)\n",
    "            if dataclasses.is_dataclass(f.type)\n",
    "        }\n",
    "        for k, s in sub_dataclasses.items():\n",
    "            if k not in inputs:\n",
    "                v = {}\n",
    "            else:\n",
    "                v = inputs[k]\n",
    "            inputs[k] = DataclassArgParser._populate_dataclass_from_dict(s, v)\n",
    "        obj = dtype(**inputs)\n",
    "        return obj\n",
    "\n",
    "    @staticmethod\n",
    "    def _populate_dataclass_from_flat_dict(dtype: DataClassType, d: dict):\n",
    "        d = DataclassArgParser.legacy_transform_dict(d.copy())\n",
    "        keys = {f.name for f in dataclasses.fields(dtype)}\n",
    "        inputs = {k: v for k, v in d.items() if k in keys}\n",
    "        for k in keys:\n",
    "            if k in d:\n",
    "                del d[k]\n",
    "        sub_dataclasses = {\n",
    "            f.name: f.type\n",
    "            for f in dataclasses.fields(dtype)\n",
    "            if dataclasses.is_dataclass(f.type)\n",
    "        }\n",
    "        for k, s in sub_dataclasses.items():\n",
    "            inputs[k] = DataclassArgParser._populate_dataclass_from_dict(s, d)\n",
    "        obj = dtype(**inputs)\n",
    "        return obj\n",
    "\n",
    "    @staticmethod\n",
    "    def legacy_transform_dict(d: dict):\n",
    "        \"\"\"Transforms the dictionary to an older version of the dataclasses\"\"\"\n",
    "        key_mapping = {\n",
    "            \"training_config\": \"training\",\n",
    "            \"model_config\": \"model\",\n",
    "            \"cost_config\": \"cost\",\n",
    "        }\n",
    "        nd = {}\n",
    "        for k in d:\n",
    "            if k in key_mapping:\n",
    "                nd[key_mapping[k]] = d[k]\n",
    "            else:\n",
    "                nd[k] = d[k]\n",
    "        return nd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def omegaconf_parse(cls):\n",
    "    parser = argparse.ArgumentParser(fromfile_prefix_chars=\"@\")\n",
    "    parser.add_argument(\n",
    "        \"--configs\",\n",
    "        nargs=\"*\",\n",
    "        default=[],\n",
    "        help=\"Configs to load\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--values\",\n",
    "        nargs=\"*\",\n",
    "        default=[],\n",
    "        help=\"Dot values to change configs\",\n",
    "    )\n",
    "    args, _unknown = parser.parse_known_args()\n",
    "\n",
    "    return omegaconf_parse_files_vals(cls, args.configs, args.values)\n",
    "\n",
    "\n",
    "def omegaconf_parse_files_vals(cls, files_paths: List[str], dotlist: List[str]):\n",
    "    configs = [OmegaConf.structured(cls)]\n",
    "    for path in files_paths:\n",
    "        configs.append(OmegaConf.load(path))\n",
    "    configs.append(OmegaConf.from_dotlist(dotlist))\n",
    "    omega_config = OmegaConf.merge(*configs)\n",
    "    res = cls.parse_from_dict(OmegaConf.to_container(omega_config))\n",
    "    return res\n",
    "\n",
    "\n",
    "def combine_cli_dict(cls, c_dict):\n",
    "    \"\"\"A function to load cli configs and merge them with a dictionary\"\"\"\n",
    "    config_base = cls.parse_from_command_line()\n",
    "    return combine_dataclass_dict(config_base, c_dict)\n",
    "\n",
    "\n",
    "def combine_dataclass_dict(dcls, c_dict):\n",
    "    \"\"\"Combines the parameters in an instantiated dataclass with the dictionary.\"\"\"\n",
    "    config = OmegaConf.create(dataclasses.asdict(dcls))\n",
    "    for k, v in c_dict.items():\n",
    "        OmegaConf.update(config, k, v)\n",
    "    return dcls.parse_from_dict(OmegaConf.to_container(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import argparse\n",
    "import dataclasses\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from typing import Any, Iterable, Tuple, Union, cast, List\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "DataClass = Any\n",
    "DataClassType = Any\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ConfigBase:\n",
    "    \"\"\"Base class that should handle parsing from command line,\n",
    "    json, dicts.\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def parse_from_command_line(cls):\n",
    "        return omegaconf_parse(cls)\n",
    "\n",
    "    @classmethod\n",
    "    def parse_from_file(cls, path: str):\n",
    "        oc = OmegaConf.load(path)\n",
    "        return cls.parse_from_dict(OmegaConf.to_container(oc))\n",
    "\n",
    "    @classmethod\n",
    "    def parse_from_command_line_deprecated(cls):\n",
    "        result = DataclassArgParser(\n",
    "            cls, fromfile_prefix_chars=\"@\"\n",
    "        ).parse_args_into_dataclasses()\n",
    "        if len(result) > 1:\n",
    "            raise RuntimeError(\n",
    "                f\"The following arguments were not recognized: {result[1:]}\"\n",
    "            )\n",
    "        return result[0]\n",
    "\n",
    "    @classmethod\n",
    "    def parse_from_dict(cls, inputs):\n",
    "        return DataclassArgParser._populate_dataclass_from_dict(cls, inputs.copy())\n",
    "\n",
    "    @classmethod\n",
    "    def parse_from_flat_dict(cls, inputs):\n",
    "        return DataclassArgParser._populate_dataclass_from_flat_dict(cls, inputs.copy())\n",
    "\n",
    "    def save(self, path: str):\n",
    "        with open(path, \"w\") as f:\n",
    "            OmegaConf.save(config=self, f=f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me reiterate the exact setting. I have two agents, each with partial local observation as an RGB image, representing the 7*7 grid around it. We derive a message from this observation by parsing the grid information, resulting in a one-hot encoded message of shape (5*7*7), where 5 is the channel number representing the number of object types in the environment (wall, goal cell, ...). Each agent can send and receive messages. They both have an image encoder and a message encoder, which are trained in an SSL manner using LEJEPA (or vicreg). The training paradigm is centralized, but the execution has to be decentralized. The following is an example of the forward pass regarding the message:\n",
    "\n",
    "\n",
    "C = self.msg_encoder(msg)\n",
    "\n",
    "z_sender = self.model.backbone(obs_sender, position = pos_sender)\n",
    "\n",
    "sigreg_img = self.sigreg(proj_z)\n",
    "\n",
    "sigreg_msg = self.sigreg(proj_c)\n",
    "\n",
    "sigreg_loss = 0.5 * (sigreg_img + sigreg_msg )\n",
    "\n",
    "lejepa_loss = (1- self.lambda_) * inv_loss + self.lambda_ * sigreg_loss \n",
    "\n",
    "\n",
    "Now, to learn the dynamics model, we have two more models:\n",
    "\n",
    "an image encoder (same as above) and a predictor, which predicts T-1 steps ahead in latent space:\n",
    "\n",
    "Z0, Z = self.model(x= obs, pos= pos, actions= act, msgs= C, T= act.size(1)-1)\n",
    "\n",
    "vicreg_loss = self.vicreg(Z0, Z, mask= mask)\n",
    "\n",
    "\n",
    "The training pipeline optimizes:\n",
    "\n",
    "lejepa_loss + vicreg_loss['total_loss']\n",
    "\n",
    "\n",
    "Now I want to focus on how this model can be leveraged to plan with the discrete CEM \n",
    "\n",
    "(an ideally allow communication between agents in the planning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, let's discard the generative modeling part for now. If we allowed agents to share only the very first discrete message in the very first environment interaction, and also share the actions taken during planning, can we not rely on the predictor to \"recreate\" an imagined series of messages.\n",
    "\n",
    "The mechanism is like this, in the training phase, along with training jepa for good encoders and prediction of the next latent, we train two other predictors, one to predict the latent of observation from the message, and one for the other way around. At planning time, we have the predictor to get z from the message, so we can obtain ~ z0 with no access to the other agent's observation. \n",
    "\n",
    "Now, what happens in planning is as follows:\n",
    "\n",
    "t = 0\n",
    "agent j send message (grid encoded as 7*7, so agent send only 49 integer numbers as 2d array. \n",
    "\n",
    "Agent I encode the message using the message encoder. Agent, I apply one_hot encoding to obtain the msg of shape 5*7*7.  \n",
    "\n",
    "Agent I Use the encoded message, h,  of j to condition the predictor (along with its action) to get z_{1} such as: z_{1}^i = f(z_0^i, a,_0^i, h_0^j)\n",
    "\n",
    "finally, get the z_0 of agent j by using the observation predictor (at agent i) as:\n",
    "z_0^j = obsPred(h^j)\n",
    "\n",
    "agent j communicate its action ALREADY, so we have the action of t=0 already, then agent i uses its dynamics model to forward the agent's j latent to get z_1^j as:\n",
    "z_1^j = f(z_0^j, a_0^j, msgEncoder(msg_1^i))\n",
    "\n",
    "t = 1\n",
    "\n",
    "get the encoded message of agent j by using the message predictor (which already learned to predict the latent of the message from the latent of the observation):\n",
    "h_1^j = msgPred(z_1^j)\n",
    "use the dynamics model again but now for the agent i himself:\n",
    "z_{2} such as: z_{1}^i = f(z_1^i, a,_1^i, h_1^j)\n",
    "\n",
    "Note: during training all models are shared across the two agents, to simplify things \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
