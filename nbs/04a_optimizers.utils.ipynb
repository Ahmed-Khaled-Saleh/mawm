{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities for Optimization\n",
    "\n",
    "> This module handles all aspects of the world model, including state representation, environment dynamics, and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp optimizers.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore import *\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from functools import partial\n",
    "from torch.optim import Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import importlib\n",
    "def get_cls(module_name, class_name):\n",
    "    module = importlib.import_module(module_name)\n",
    "    return getattr(module, class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_opt(cfg, model):\n",
    "    optimizer_cls = get_cls(\"torch.optim\", cfg.optimizer.name)\n",
    "    optimizer = optimizer_cls(model.parameters(), lr=cfg.optimizer.lr)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Source - https://stackoverflow.com/a\n",
    "# Posted by isle_of_gods, modified by community. See post 'Timeline' for change history\n",
    "# Retrieved 2025-11-15, License - CC BY-SA 4.0\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "def init_opt(\n",
    "    cfg,\n",
    "    models,\n",
    "):\n",
    "    # all_params = []\n",
    "    # for k in models.keys():\n",
    "    #     for model in models[k].values():\n",
    "    #         all_params += list(model.parameters())\n",
    "    # optimizer = torch.optim.AdamW(all_params, lr= cfg.optimizer.lr, betas=betas, eps=eps)\n",
    "\n",
    "    base_lr = cfg.optimizer.lr\n",
    "    jepa_params = list(models['rec']['jepa'].parameters())\n",
    "    encoder_params = list(models[\"send\"][\"obs_enc\"].parameters()) + list(models['send']['msg_enc'].parameters())\n",
    "    comm_params = list(models['send']['comm_module'].parameters())\n",
    "    proj_params = list(models['send']['proj'].parameters())\n",
    "    \n",
    "    param_groups = [\n",
    "        {'params': jepa_params, 'lr': 0.5 * base_lr, 'name': 'jepa'},\n",
    "        {'params': encoder_params, 'lr': base_lr, 'name': 'encoders'},\n",
    "        {'params': comm_params, 'lr': base_lr * 1.0, 'name': 'comm_module'},\n",
    "        {'params': proj_params, 'lr': base_lr * 0.5, 'name': 'proj'}\n",
    "    ]\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(param_groups, weight_decay=1e-4)\n",
    "    \n",
    "\n",
    "    return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:JEPA Parameters: 98560\n",
      "INFO:root:CommModule Parameters: 56005\n",
      "INFO:root:MSgEncoder Parameters: 32608\n",
      "INFO:root:Projector Parameters: 2241536\n",
      "INFO:root:--------------------------------------------------\n",
      "INFO:root:Total Parameters: 2462245\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "from mawm.models import init_models\n",
    "from omegaconf import OmegaConf\n",
    "cfg = OmegaConf.load(\"../cfgs/MPCJepa/mpc.yaml\")\n",
    "\n",
    "model = init_models(cfg, \"cpu\", distributed= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    decoupled_weight_decay: True\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.0001\n",
       "    maximize: False\n",
       "    name: jepa\n",
       "    weight_decay: 0.01\n",
       "\n",
       "Parameter Group 1\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    decoupled_weight_decay: True\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.00015000000000000001\n",
       "    maximize: False\n",
       "    name: encoders\n",
       "    weight_decay: 0.01\n",
       "\n",
       "Parameter Group 2\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    decoupled_weight_decay: True\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.0002\n",
       "    maximize: False\n",
       "    name: comm_module\n",
       "    weight_decay: 0.01\n",
       "\n",
       "Parameter Group 3\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    decoupled_weight_decay: True\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.00015000000000000001\n",
       "    maximize: False\n",
       "    name: proj\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "optimizer = init_opt(cfg, model)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
