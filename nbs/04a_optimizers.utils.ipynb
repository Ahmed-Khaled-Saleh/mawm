{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities for Optimization\n",
    "\n",
    "> This module handles all aspects of the world model, including state representation, environment dynamics, and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp optimizers.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore import *\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from functools import partial\n",
    "from torch.optim import Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import importlib\n",
    "def get_cls(module_name, class_name):\n",
    "    module = importlib.import_module(module_name)\n",
    "    return getattr(module, class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def init_opt(cfg, model):\n",
    "    optimizer_cls = get_cls(\"torch.optim\", cfg.optimizer.name)\n",
    "    optimizer = optimizer_cls(model.parameters(), lr=cfg.optimizer.lr)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Source - https://stackoverflow.com/a\n",
    "# Posted by isle_of_gods, modified by community. See post 'Timeline' for change history\n",
    "# Retrieved 2025-11-15, License - CC BY-SA 4.0\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# from mawm.optimizers.schedulers import WSDSchedule, CosineWDSchedule\n",
    "import torch\n",
    "def init_opt(\n",
    "    cfg,\n",
    "    *models,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8,\n",
    "):\n",
    "    all_params = []\n",
    "    for model in models:\n",
    "        all_params += list(model.parameters())\n",
    "    \n",
    "\n",
    "    optimizer = torch.optim.AdamW(all_params, betas=betas, eps=eps)\n",
    "    # scheduler = WSDSchedule(\n",
    "    #     optimizer,\n",
    "    #     warmup_steps=int(warmup * iterations_per_epoch),\n",
    "    #     anneal_steps=int(anneal * iterations_per_epoch),\n",
    "    #     start_lr=start_lr,\n",
    "    #     ref_lr=ref_lr,\n",
    "    #     final_lr=final_lr,\n",
    "    #     T_max=int(num_epochs * iterations_per_epoch),\n",
    "    # )\n",
    "    # wd_scheduler = CosineWDSchedule(\n",
    "    #     optimizer,\n",
    "    #     ref_wd=wd,\n",
    "    #     final_wd=final_wd,\n",
    "    #     T_max=int(num_epochs * iterations_per_epoch),\n",
    "    # )\n",
    "    # scaler = torch.cuda.amp.GradScaler() if mixed_precision else None\n",
    "    return optimizer#, scaler, scheduler, wd_scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
