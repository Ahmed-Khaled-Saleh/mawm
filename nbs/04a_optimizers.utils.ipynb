{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities for Optimization\n",
    "\n",
    "> This module handles all aspects of the world model, including state representation, environment dynamics, and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp optimizers.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore import *\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from functools import partial\n",
    "from torch.optim import Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import importlib\n",
    "def get_cls(module_name, class_name):\n",
    "    module = importlib.import_module(module_name)\n",
    "    return getattr(module, class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def init_opt(cfg, model):\n",
    "    optimizer_cls = get_cls(\"torch.optim\", cfg.optimizer.name)\n",
    "    optimizer = optimizer_cls(model.parameters(), lr=cfg.optimizer.lr)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Source - https://stackoverflow.com/a\n",
    "# Posted by isle_of_gods, modified by community. See post 'Timeline' for change history\n",
    "# Retrieved 2025-11-15, License - CC BY-SA 4.0\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# def init_models_dist(\n",
    "#     device,\n",
    "#     patch_size=16,\n",
    "#     max_num_frames=16,\n",
    "#     tubelet_size=2,\n",
    "#     model_name=\"vit_base\",\n",
    "#     crop_size=224,\n",
    "#     pred_depth=6,\n",
    "#     pred_num_heads=None,\n",
    "#     pred_embed_dim=384,\n",
    "#     uniform_power=False,\n",
    "#     use_sdpa=False,\n",
    "#     use_rope=False,\n",
    "#     use_silu=False,\n",
    "#     use_pred_silu=False,\n",
    "#     wide_silu=False,\n",
    "#     pred_is_frame_causal=True,\n",
    "#     use_activation_checkpointing=False,\n",
    "#     return_all_tokens=False,\n",
    "#     action_embed_dim=7,\n",
    "#     use_extrinsics=False,\n",
    "#     old_pred=False,\n",
    "# ):\n",
    "#     encoder = video_vit.__dict__[model_name](\n",
    "#         img_size=crop_size,\n",
    "#         patch_size=patch_size,\n",
    "#         num_frames=max_num_frames,\n",
    "#         tubelet_size=tubelet_size,\n",
    "#         uniform_power=uniform_power,\n",
    "#         use_sdpa=use_sdpa,\n",
    "#         use_silu=use_silu,\n",
    "#         wide_silu=wide_silu,\n",
    "#         use_activation_checkpointing=use_activation_checkpointing,\n",
    "#         use_rope=use_rope,\n",
    "#     )\n",
    "\n",
    "#     predictor = vit_ac_pred.__dict__[\"vit_ac_predictor\"](\n",
    "#         img_size=crop_size,\n",
    "#         patch_size=patch_size,\n",
    "#         num_frames=max_num_frames,\n",
    "#         tubelet_size=tubelet_size,\n",
    "#         embed_dim=encoder.embed_dim,\n",
    "#         predictor_embed_dim=pred_embed_dim,\n",
    "#         action_embed_dim=action_embed_dim,\n",
    "#         depth=pred_depth,\n",
    "#         is_frame_causal=pred_is_frame_causal,\n",
    "#         num_heads=encoder.num_heads if pred_num_heads is None else pred_num_heads,\n",
    "#         uniform_power=uniform_power,\n",
    "#         use_rope=use_rope,\n",
    "#         use_sdpa=use_sdpa,\n",
    "#         use_silu=use_pred_silu,\n",
    "#         wide_silu=wide_silu,\n",
    "#         use_extrinsics=use_extrinsics,\n",
    "#         use_activation_checkpointing=use_activation_checkpointing,\n",
    "#     )\n",
    "\n",
    "#     encoder.to(device)\n",
    "#     predictor.to(device)\n",
    "#     logger.info(encoder)\n",
    "#     logger.info(predictor)\n",
    "\n",
    "#     def count_parameters(model):\n",
    "#         return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "#     logger.info(f\"Encoder number of parameters: {count_parameters(encoder)}\")\n",
    "#     logger.info(f\"Predictor number of parameters: {count_parameters(predictor)}\")\n",
    "\n",
    "#     return encoder, predictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# from mawm.optimizers.schedulers import WSDSchedule, CosineWDSchedule\n",
    "import torch\n",
    "def init_opt_dis(\n",
    "    cfg,\n",
    "    jepa,\n",
    "    msg_encoder,\n",
    "    msg_pred,\n",
    "    obs_pred,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8,\n",
    "):\n",
    "    all_params = (\n",
    "        list(jepa.parameters()) + \n",
    "        list(msg_encoder.parameters()) + \n",
    "        list(msg_pred.parameters()) +\n",
    "        list(obs_pred.parameters())\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.AdamW(all_params, betas=betas, eps=eps)\n",
    "    # scheduler = WSDSchedule(\n",
    "    #     optimizer,\n",
    "    #     warmup_steps=int(warmup * iterations_per_epoch),\n",
    "    #     anneal_steps=int(anneal * iterations_per_epoch),\n",
    "    #     start_lr=start_lr,\n",
    "    #     ref_lr=ref_lr,\n",
    "    #     final_lr=final_lr,\n",
    "    #     T_max=int(num_epochs * iterations_per_epoch),\n",
    "    # )\n",
    "    # wd_scheduler = CosineWDSchedule(\n",
    "    #     optimizer,\n",
    "    #     ref_wd=wd,\n",
    "    #     final_wd=final_wd,\n",
    "    #     T_max=int(num_epochs * iterations_per_epoch),\n",
    "    # )\n",
    "    # scaler = torch.cuda.amp.GradScaler() if mixed_precision else None\n",
    "    return optimizer#, scaler, scheduler, wd_scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
