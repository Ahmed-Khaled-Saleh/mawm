{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "368be84d",
   "metadata": {},
   "source": [
    "<!-- # Planning Evaluator\n",
    "\n",
    "> Evaluator for planning performance using the Cross-Entropy Method (CEM) for optimization of discrete action sequences. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ea932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp evaluators.planning_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f4e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd474d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "from fastcore.utils import *\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import os\n",
    "from mawm.data.utils import base_tf, msg_tf\n",
    "import numpy as np\n",
    "import torch\n",
    "from mawm.planners.cem_planner import CEMPlanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc00b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def preprocessor(env, obs, pos=True, get_msg=True):\n",
    "    obs_transformed = {}\n",
    "    positions = {}\n",
    "    goals = {}\n",
    "    messages = {}\n",
    "    goal_pos = obs[\"global\"][\"goal_pos\"]\n",
    "\n",
    "    agents = [f'agent_{i}' for i in range(env.num_agents)]\n",
    "    for i, agent_id in enumerate(agents):\n",
    "        obs_transformed[agent_id] = base_tf(obs[agent_id]['pov'].astype(np.uint8))  # Add batch dimension\n",
    "        goal = env.get_goal(env.agents[i], goal_pos)[0]\n",
    "        goals[agent_id] = base_tf(goal.astype(np.uint8))\n",
    "\n",
    "        if pos:\n",
    "            positions[agent_id] = torch.from_numpy(obs[agent_id]['selfpos'])\n",
    "        if get_msg:\n",
    "            m = msg_tf((obs[agent_id]['pov'], agent_id, False))\n",
    "            messages[agent_id] = m\n",
    "\n",
    "    \n",
    "    if pos and get_msg:\n",
    "        return obs_transformed, positions, goals, messages\n",
    "    elif pos:\n",
    "        return obs_transformed, positions, goals\n",
    "    elif get_msg:\n",
    "        return obs_transformed, messages\n",
    "    else:\n",
    "        return obs_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eacc291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PlanEvaluator:\n",
    "    \"Evaluator for planning performance using the Cross-Entropy Method (CEM) for optimization of discrete action sequences.\"\n",
    "    def __init__(self, planner, agents= ['agent_0', 'agent_1'], device='cpu'):\n",
    "        self.agents = agents\n",
    "        self.device = device\n",
    "        self.planners = {agent: planner for agent in agents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb5194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def eval_all_agents(self: PlanEvaluator, env, preprocessor=preprocessor, negotiation_rounds=3):\n",
    "    obs = env.reset()\n",
    "    step = 0\n",
    "    agents = self.agents\n",
    "    horizon = self.planners[agents[0]].horizon\n",
    "\n",
    "    # 1. Initialize \"Intents\" (The Draft Plans)\n",
    "    # At t=0, we start with zeros (staying still)\n",
    "    lst_intents = []\n",
    "    intents = {agent: torch.zeros(horizon, dtype=torch.long) for agent in agents}\n",
    "\n",
    "    while step < 100:\n",
    "\n",
    "        obs_transformed, pos, goals, msgs = preprocessor(env, obs, pos=True, get_msg=True)\n",
    "\n",
    "        for r in range(negotiation_rounds):\n",
    "            new_intents = {}\n",
    "            print(\"Negotiation Round:\", r+1)\n",
    "            for agent in self.agents:\n",
    "                # Find the other agent\n",
    "                other_agent = [a for a in agents if a != agent][0]\n",
    "                \n",
    "                # Plan based on the OTHER agent's intent from the previous negotiation round\n",
    "                # This grounds the \"imagination\" in reality\n",
    "                new_intents[agent] = self.planners[agent].plan(\n",
    "                    o_t=obs_transformed[agent], \n",
    "                    pos_t=pos[agent], \n",
    "                    o_g=goals[agent], \n",
    "                    m_other=msgs[other_agent],\n",
    "                    other_actions=intents[other_agent] # This is the \"Anchor\"\n",
    "                )\n",
    "            \n",
    "            # Update intents for the next negotiation round\n",
    "            intents = new_intents\n",
    "\n",
    "        \n",
    "        lst_intents.append(intents.copy())\n",
    "        # After negotiation rounds, take the FIRST action of the final best plan\n",
    "        actions = {agent: intents[agent][0] for agent in agents}\n",
    "        actions = {agent: np.int64(actions[agent].item()) for agent in agents}\n",
    "        obs, rewards, done, infos = env.step(actions)\n",
    "        print(f\"Step: {step}, Actions taken: {actions}, Rewards: {rewards}, Done: {done}\")\n",
    "        # Shift the remaining plan forward by 1 and pad with a 0 (Stay)\n",
    "        for agent in agents:\n",
    "            shifted_plan = torch.cat([intents[agent][1:], torch.zeros(1, dtype=torch.long)])\n",
    "            intents[agent] = shifted_plan\n",
    "\n",
    "        if done['__all__']:\n",
    "            break\n",
    "\n",
    "        step += 1\n",
    "        \n",
    "    env.close()\n",
    "    return lst_intents # Returning the final sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613adbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from mawm.envs.marl_grid import make_env\n",
    "from mawm.envs.marl_grid.cfg import config\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "seed = np.random.randint(0, 10000)\n",
    "cfg = copy.deepcopy(config)\n",
    "cfg.env_cfg.seed = int(seed)\n",
    "cfg.env_cfg.max_steps = 512\n",
    "\n",
    "env = make_env(cfg.env_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8ab619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "obs = env.reset()\n",
    "items = preprocessor(env, obs, pos=True, get_msg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af8fc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 42, 42]),\n",
       " torch.Size([2]),\n",
       " torch.Size([3, 42, 42]),\n",
       " torch.Size([5, 7, 7]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "obs_transformed, positions, goals, messages = items\n",
    "obs_transformed['agent_0'].shape, positions['agent_0'].shape, goals['agent_0'].shape, messages['agent_0'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ba68a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide \n",
    "from mawm.models.jepa import JEPA\n",
    "from omegaconf import OmegaConf\n",
    "cfg = OmegaConf.load(\"../cfgs/MPCJepa/mpc.yaml\")\n",
    "model = JEPA(cfg.model, input_dim=(3, 42, 42), action_dim=1)\n",
    "\n",
    "#| \n",
    "from mawm.models.misc import ObsPred, MsgPred\n",
    "from mawm.models.vision import SemanticEncoder\n",
    "obs_pred = ObsPred(h_dim=32, out_channels=18)\n",
    "msg_pred = MsgPred(h_dim=32, in_channels=16)\n",
    "msg_encoder = SemanticEncoder(latent_dim=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3c0501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65246/404583005.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(\"./models/best.pth\", map_location='cpu')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'jepa', 'msg_encoder', 'msg_predictor', 'obs_predictor', 'train_loss', 'val_loss', 'optimizer', 'lr'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "import torch\n",
    "ckpt = torch.load(\"./models/best.pth\", map_location='cpu')\n",
    "ckpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc0f436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(ckpt['jepa'])\n",
    "msg_encoder.load_state_dict(ckpt['msg_encoder'])\n",
    "msg_pred.load_state_dict(ckpt['msg_predictor'])\n",
    "obs_pred.load_state_dict(ckpt['obs_predictor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0a5b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeNet6(\n",
       "  (layers): Sequential(\n",
       "    (0): Identity()\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "      (1): GroupNorm(4, 16, eps=1e-05, affine=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2))\n",
       "      (4): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (5): ReLU()\n",
       "      (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (7): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (8): ReLU()\n",
       "      (9): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (10): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (11): ReLU()\n",
       "      (12): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (position_encoder): Expander2D()\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604d7153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "planner = CEMPlanner(model=model, msg_enc= msg_encoder, msg_pred=msg_pred, obs_pred=obs_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfb668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# evaluator = PlanEvaluator(model, msg_encoder, msg_pred, planner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faf231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# evaluator.eval_all_agents(env, preprocessor, negotiation_rounds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3f4ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "nbdev.nbdev_export() # type: ignore  # noqa: E702\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
