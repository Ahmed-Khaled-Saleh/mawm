{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "368be84d",
   "metadata": {},
   "source": [
    "<!-- # Planning Evaluator\n",
    "\n",
    "> Evaluator for planning performance using the Cross-Entropy Method (CEM) for optimization of discrete action sequences. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ea932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp evaluators.planning_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f4e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# from nbdev.showdoc import *  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd474d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export \n",
    "# from fastcore.utils import *\n",
    "# import pandas as pd\n",
    "# import wandb\n",
    "# import os\n",
    "# from mawm.data.utils import base_tf, msg_tf\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# from mawm.planners.cem_planner import CEMPlanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc00b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# def preprocessor(env, obs, pos=True, get_msg=True):\n",
    "#     obs_transformed = {}\n",
    "#     positions = {}\n",
    "#     goals = {}\n",
    "#     messages = {}\n",
    "#     goal_pos = obs[\"global\"][\"goal_pos\"]\n",
    "\n",
    "#     agents = [f'agent_{i}' for i in range(env.num_agents)]\n",
    "#     for i, agent_id in enumerate(agents):\n",
    "#         obs_transformed[agent_id] = base_tf(obs[agent_id]['pov'].astype(np.uint8))  # Add batch dimension\n",
    "#         goal = env.get_goal(env.agents[i], goal_pos)[0]\n",
    "#         goals[agent_id] = base_tf(goal.astype(np.uint8))\n",
    "\n",
    "#         if pos:\n",
    "#             positions[agent_id] = torch.from_numpy(obs[agent_id]['selfpos'])\n",
    "#         if get_msg:\n",
    "#             m = msg_tf((obs[agent_id]['pov'], agent_id, False))\n",
    "#             messages[agent_id] = m\n",
    "\n",
    "    \n",
    "#     if pos and get_msg:\n",
    "#         return obs_transformed, positions, goals, messages\n",
    "#     elif pos:\n",
    "#         return obs_transformed, positions, goals\n",
    "#     elif get_msg:\n",
    "#         return obs_transformed, messages\n",
    "#     else:\n",
    "#         return obs_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eacc291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# class PlanEvaluator:\n",
    "#     \"Evaluator for planning performance using the Cross-Entropy Method (CEM) for optimization of discrete action sequences.\"\n",
    "#     def __init__(self, model, msg_enc, msg_pred, planner, agents= ['agent_0', 'agent_1'], device='cpu'):\n",
    "#         self.model = model\n",
    "#         self.msg_enc = msg_enc\n",
    "#         self.msg_pred = msg_pred\n",
    "#         self.agents = agents\n",
    "#         self.device = device\n",
    "#         self.planners = {agent: planner for agent in agents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb5194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# @patch\n",
    "# def eval_all_agents(self: PlanEvaluator, env, preprocessor=preprocessor, negotiation_rounds=3):\n",
    "#     obs = env.reset()\n",
    "#     step = 0\n",
    "#     agents = self.agents\n",
    "#     horizon = self.planners[agents[0]].horizon\n",
    "\n",
    "#     # 1. Initialize \"Intents\" (The Draft Plans)\n",
    "#     # At t=0, we start with zeros (staying still)\n",
    "#     intents = {agent: torch.zeros(horizon, dtype=torch.long) for agent in agents}\n",
    "\n",
    "#     while step < 100:\n",
    "\n",
    "#         obs_transformed, pos, goals, msgs = preprocessor(env, obs, pos=True, get_msg=True)\n",
    "\n",
    "#         for r in range(negotiation_rounds):\n",
    "#             new_intents = {}\n",
    "#             print(\"Negotiation Round:\", r+1)\n",
    "#             for agent in self.agents:\n",
    "#                 # Find the other agent\n",
    "#                 other_agent = [a for a in agents if a != agent][0]\n",
    "                \n",
    "#                 # Plan based on the OTHER agent's intent from the previous negotiation round\n",
    "#                 # This grounds the \"imagination\" in reality\n",
    "#                 new_intents[agent] = self.planners[agent].plan(\n",
    "#                     o_t=obs_transformed[agent], \n",
    "#                     pos_t=pos[agent], \n",
    "#                     o_g=goals[agent], \n",
    "#                     m_other=msgs[other_agent],\n",
    "#                     other_actions=intents[other_agent] # This is the \"Anchor\"\n",
    "#                 )\n",
    "            \n",
    "#             # Update intents for the next negotiation round\n",
    "#             intents = new_intents\n",
    "\n",
    "        \n",
    "#         # After negotiation rounds, take the FIRST action of the final best plan\n",
    "#         actions = {agent: intents[agent][0] for agent in agents}\n",
    "#         actions = {agent: np.int64(actions[agent].item()) for agent in agents}\n",
    "#         obs, rewards, done, infos = env.step(actions)\n",
    "#         print(f\"Step: {step}, Actions taken: {actions}, Rewards: {rewards}, Done: {done}\")\n",
    "#         # Shift the remaining plan forward by 1 and pad with a 0 (Stay)\n",
    "#         for agent in agents:\n",
    "#             shifted_plan = torch.cat([intents[agent][1:], torch.zeros(1, dtype=torch.long)])\n",
    "#             intents[agent] = shifted_plan\n",
    "\n",
    "#         if done['__all__']:\n",
    "#             break\n",
    "\n",
    "#         step += 1\n",
    "        \n",
    "#     env.close()\n",
    "#     return intents # Returning the final sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613adbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# from mawm.envs.marl_grid import make_env\n",
    "# from mawm.envs.marl_grid.cfg import config\n",
    "# import copy\n",
    "# import numpy as np\n",
    "\n",
    "# seed = np.random.randint(0, 10000)\n",
    "# cfg = copy.deepcopy(config)\n",
    "# cfg.env_cfg.seed = int(seed)\n",
    "# cfg.env_cfg.max_steps = 512\n",
    "\n",
    "# env = make_env(cfg.env_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8ab619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# obs = env.reset()\n",
    "# items = preprocessor(env, obs, pos=True, get_msg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af8fc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 42, 42]),\n",
       " torch.Size([2]),\n",
       " torch.Size([3, 42, 42]),\n",
       " torch.Size([5, 7, 7]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #| hide\n",
    "\n",
    "# obs_transformed, positions, goals, messages = items\n",
    "# obs_transformed['agent_0'].shape, positions['agent_0'].shape, goals['agent_0'].shape, messages['agent_0'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ba68a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide \n",
    "# from mawm.models.jepa import JEPA\n",
    "# from omegaconf import OmegaConf\n",
    "# cfg = OmegaConf.load(\"../cfgs/MPCJepa/mpc.yaml\")\n",
    "# model = JEPA(cfg.model, input_dim=(3, 42, 42), action_dim=1)\n",
    "\n",
    "# #| \n",
    "# from mawm.models.misc import ObsPred, MsgPred\n",
    "# from mawm.models.vision import SemanticEncoder\n",
    "# obs_pred = ObsPred(h_dim=32, out_channels=18)\n",
    "# msg_pred = MsgPred(h_dim=32, in_channels=16)\n",
    "# msg_encoder = SemanticEncoder(latent_dim=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3c0501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65246/404583005.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(\"./models/best.pth\", map_location='cpu')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'jepa', 'msg_encoder', 'msg_predictor', 'obs_predictor', 'train_loss', 'val_loss', 'optimizer', 'lr'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #| hide\n",
    "# import torch\n",
    "# ckpt = torch.load(\"./models/best.pth\", map_location='cpu')\n",
    "# ckpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc0f436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(ckpt['jepa'])\n",
    "# msg_encoder.load_state_dict(ckpt['msg_encoder'])\n",
    "# msg_pred.load_state_dict(ckpt['msg_predictor'])\n",
    "# obs_pred.load_state_dict(ckpt['obs_predictor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0a5b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeNet6(\n",
       "  (layers): Sequential(\n",
       "    (0): Identity()\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "      (1): GroupNorm(4, 16, eps=1e-05, affine=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2))\n",
       "      (4): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (5): ReLU()\n",
       "      (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (7): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (8): ReLU()\n",
       "      (9): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (10): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (11): ReLU()\n",
       "      (12): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (position_encoder): Expander2D()\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604d7153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# planner = CEMPlanner(model=model, msg_enc= msg_encoder, msg_pred=msg_pred, obs_pred=obs_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfb668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# evaluator = PlanEvaluator(model, msg_encoder, msg_pred, planner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faf231b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negotiation Round: 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 51, 3, 3], expected input[1000, 49, 15, 15] to have 51 channels, but got 49 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#| hide\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[43m.\u001b[49m\u001b[43meval_all_agents\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegotiation_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36meval_all_agents\u001b[39m\u001b[34m(self, env, preprocessor, negotiation_rounds)\u001b[39m\n\u001b[32m     22\u001b[39m     other_agent = [a \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m agents \u001b[38;5;28;01mif\u001b[39;00m a != agent][\u001b[32m0\u001b[39m]\n\u001b[32m     24\u001b[39m     \u001b[38;5;66;03m# Plan based on the OTHER agent's intent from the previous negotiation round\u001b[39;00m\n\u001b[32m     25\u001b[39m     \u001b[38;5;66;03m# This grounds the \"imagination\" in reality\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     new_intents[agent] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mplanners\u001b[49m\u001b[43m[\u001b[49m\u001b[43magent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mo_t\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobs_transformed\u001b[49m\u001b[43m[\u001b[49m\u001b[43magent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpos_t\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m[\u001b[49m\u001b[43magent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mo_g\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgoals\u001b[49m\u001b[43m[\u001b[49m\u001b[43magent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mm_other\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsgs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mother_agent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43mother_actions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mintents\u001b[49m\u001b[43m[\u001b[49m\u001b[43mother_agent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# This is the \"Anchor\"\u001b[39;49;00m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Update intents for the next negotiation round\u001b[39;00m\n\u001b[32m     35\u001b[39m intents = new_intents\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Ahmed-home/1- Projects/Research/Journal 2/Code/mawm/mawm/planners/cem_planner.py:257\u001b[39m, in \u001b[36mCEMPlanner.plan\u001b[39m\u001b[34m(self, o_t, pos_t, o_g, m_other, other_actions)\u001b[39m\n\u001b[32m    254\u001b[39m h0_other = \u001b[38;5;28mself\u001b[39m.msg_enc(m_other.unsqueeze(\u001b[32m0\u001b[39m).unsqueeze(\u001b[32m1\u001b[39m)) \u001b[38;5;66;03m# [5, 7, 7] => [1, 1, 32]\u001b[39;00m\n\u001b[32m    255\u001b[39m a_other = other_actions.repeat(\u001b[38;5;28mself\u001b[39m.num_samples, \u001b[32m1\u001b[39m) \u001b[38;5;66;03m# [num_samples, horizon]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m total_costs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_g\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh0_other\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_other\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[38;5;28mself\u001b[39m.probs, best_plan = \u001b[38;5;28mself\u001b[39m.update_dist(\u001b[38;5;28mself\u001b[39m.probs, a_self, total_costs, \u001b[38;5;28mself\u001b[39m.num_elites)\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m best_plan\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Ahmed-home/1- Projects/Research/Journal 2/Code/mawm/mawm/planners/cem_planner.py:283\u001b[39m, in \u001b[36mCEMPlanner.evolve\u001b[39m\u001b[34m(self, z_t, z_goal, h0_other, a_self, a_other)\u001b[39m\n\u001b[32m    280\u001b[39m a_self_t = a_self[:, t].unsqueeze(\u001b[32m1\u001b[39m) \u001b[38;5;66;03m# [1 500]\u001b[39;00m\n\u001b[32m    281\u001b[39m a_other_t = a_other[:, t].unsqueeze(\u001b[32m1\u001b[39m) \u001b[38;5;66;03m# [1, 500]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m next_z_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdynamics\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_state\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurr_z_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurr_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_self_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurr_msg\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurr_h_other\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    284\u001b[39m next_z_other = \u001b[38;5;28mself\u001b[39m.model.dynamics.forward(current_state = curr_z_other, curr_action= a_other_t, curr_msg= curr_h_self)\n\u001b[32m    286\u001b[39m next_h_self = \u001b[38;5;28mself\u001b[39m.msg_pred(rearrange(next_z_self, \u001b[33m'\u001b[39m\u001b[33m(s t) c h w -> s t c h w \u001b[39m\u001b[33m'\u001b[39m, t= \u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Ahmed-home/1- Projects/Research/Journal 2/Code/mawm/mawm/models/dynamics/predictor.py:653\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(self, current_state, curr_action, curr_msg)\u001b[39m\n\u001b[32m    651\u001b[39m curr_msg = \u001b[38;5;28mself\u001b[39m.msg_encoder(curr_msg)\n\u001b[32m    652\u001b[39m x = torch.cat([current_state, curr_action, curr_msg], dim=\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.residual:\n\u001b[32m    655\u001b[39m     x = x + current_state\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Given groups=1, weight of size [32, 51, 3, 3], expected input[1000, 49, 15, 15] to have 51 channels, but got 49 channels instead"
     ]
    }
   ],
   "source": [
    "# #| hide\n",
    "# evaluator.eval_all_agents(env, preprocessor, negotiation_rounds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3f4ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# import nbdev\n",
    "# nbdev.nbdev_export() # type: ignore  # noqa: E702\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
