{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Communication Module\n",
    "\n",
    "> Model architecture that handles communicaion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore import *\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CommunicationModuleGRU(nn.Module):\n",
    "    \"\"\"\n",
    "    Handles Agent J's message output. \n",
    "    1. During training, outputs the continuous message context (h_t^j).\n",
    "    2. During execution, outputs the hard-sampled discrete symbol index (m_hard).\n",
    "    \"\"\"\n",
    "    def __init__(self, observation_dim: int, message_context_dim: int, vocab_size: int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            observation_dim (int): Dimension of the encoded observation (z_t^j).\n",
    "            message_context_dim (int): Dimension of the embedded message/GRU hidden state (h_t^j).\n",
    "            vocab_size (int): The number of unique symbolic tokens in the vocabulary |V|.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.message_context_dim = message_context_dim\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        # --- 1. Recurrent Core (GRU) ---\n",
    "        # Computes h_t^j = GRU(z_t^j, h_{t-1}^j)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=observation_dim,\n",
    "            hidden_size=message_context_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # --- 2. Discretization Head Logits ---\n",
    "        # Learns to map the continuous context h_t^j to a symbol index for execution.\n",
    "        self.logit_proj = nn.Linear(message_context_dim, vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def forward(self: CommunicationModuleGRU, z_t_j: torch.Tensor, h_prev_j: torch.Tensor, is_training: bool):\n",
    "    \"\"\"\n",
    "    Calculates the new message context and determines the output based on mode.\n",
    "\n",
    "    Args:\n",
    "        z_t_j (torch.Tensor): The encoded observation at time t. Shape: (Batch, observation_dim)\n",
    "        h_prev_j (torch.Tensor): The previous embedded message context (h_{t-1}^j). \n",
    "                                    Shape: (Batch, message_context_dim)\n",
    "        is_training (bool): If True, returns h_t_j (continuous). \n",
    "                            If False, returns the discrete index m_hard.\n",
    "\n",
    "    Returns:\n",
    "        - If is_training=True: torch.Tensor (h_t^j), Shape: (Batch, message_context_dim)\n",
    "        - If is_training=False: torch.Tensor (m_hard), Shape: (Batch)\n",
    "    \"\"\"\n",
    "    B = z_t_j.size(0)\n",
    "\n",
    "    # 1. Update Recurrent Message Context (h_t^j)\n",
    "    \n",
    "    # Input reshape: (B, observation_dim) -> (B, 1, observation_dim)\n",
    "    z_t_j_seq = z_t_j.unsqueeze(1) \n",
    "\n",
    "    # Hidden state reshape: (B, message_context_dim) -> (1, B, message_context_dim)\n",
    "    h_prev_j_gru = h_prev_j.unsqueeze(0).contiguous()\n",
    "\n",
    "    # Output h_t_j_gru: (1, B, message_context_dim)\n",
    "    _, h_t_j_gru = self.gru(z_t_j_seq, h_prev_j_gru)\n",
    "    \n",
    "    # Final continuous message context: (B, message_context_dim)\n",
    "    h_t_j = h_t_j_gru.squeeze(0)\n",
    "\n",
    "    # 2. Determine Output Based on Mode\n",
    "    if is_training:\n",
    "        # --- TRAINING PATH: Pass Continuous Context ---\n",
    "        # Gradients flow through h_t_j to the GRU, optimizing for usefulness.\n",
    "        return h_t_j\n",
    "    else:\n",
    "        # --- EXECUTION PATH: Hard Discretization ---\n",
    "        # 2a. Compute Logits\n",
    "        logits = self.logit_proj(h_t_j) # Shape: (Batch, vocab_size)\n",
    "\n",
    "        # 2b. Hard Sampling (Argmax): Select the best symbol index\n",
    "        discrete_token_index = torch.argmax(logits, dim=-1) # Shape: (Batch)\n",
    "        \n",
    "        # This is the discrete message sent over the channel.\n",
    "        return discrete_token_index.long() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Agent J Communication Module Initialization ---\n",
      "\n",
      "Training Step:\n",
      "Output (Continuous Context h_t^j) shape: torch.Size([4, 128])\n",
      "\n",
      "Execution Step:\n",
      "Output (Discrete Symbol Indices m_hard): [7, 7, 7, 6]\n",
      "Output shape: torch.Size([4]) (LongTensor of symbol indices)\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Define Dimensions\n",
    "    BATCH_SIZE = 4\n",
    "    OBSERVATION_DIM = 64\n",
    "    MESSAGE_CONTEXT_DIM = 128\n",
    "    VOCAB_SIZE = 10\n",
    "    \n",
    "    print(f\"--- Agent J Communication Module Initialization ---\")\n",
    "    comm_module_j = CommunicationModuleGRU(OBSERVATION_DIM, MESSAGE_CONTEXT_DIM, VOCAB_SIZE)\n",
    "\n",
    "    # Mock Inputs\n",
    "    mock_z_t_j = torch.randn(BATCH_SIZE, OBSERVATION_DIM)\n",
    "    # h_{t-1}^j is the previous message context (initialize to zero for the first step)\n",
    "    mock_h_prev_j = torch.zeros(BATCH_SIZE, MESSAGE_CONTEXT_DIM) \n",
    "    \n",
    "    # --- Training Simulation ---\n",
    "    h_t_j_cont = comm_module_j(mock_z_t_j, mock_h_prev_j, is_training=True)\n",
    "    print(\"\\nTraining Step:\")\n",
    "    print(f\"Output (Continuous Context h_t^j) shape: {h_t_j_cont.shape}\")\n",
    "    \n",
    "    # --- Execution Simulation ---\n",
    "    m_hard = comm_module_j(mock_z_t_j, mock_h_prev_j, is_training=False)\n",
    "    print(\"\\nExecution Step:\")\n",
    "    print(f\"Output (Discrete Symbol Indices m_hard): {m_hard.tolist()}\")\n",
    "    print(f\"Output shape: {m_hard.shape} (LongTensor of symbol indices)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
