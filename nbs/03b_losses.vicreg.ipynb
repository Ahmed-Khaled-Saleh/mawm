{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VicReg Loss Function\n",
    "\n",
    "> As implemented in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp losses.vicreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore import *\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from mawm.models.utils import flatten_conv_output\n",
    "from functools import reduce\n",
    "import operator\n",
    "from mawm.models.misc import Projector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class VICReg(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cfg,\n",
    "        repr_dim: int,\n",
    "        pred_attr: str = \"state\",\n",
    "        name_prefix: str = \"\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if isinstance(repr_dim, tuple):\n",
    "            repr_dim = reduce(operator.mul, repr_dim)\n",
    "        self.cfg = cfg\n",
    "        self.name_prefix = name_prefix\n",
    "        self.pred_attr = pred_attr\n",
    "        self.projector = Projector(\n",
    "            arch=cfg.loss.vicreg.projector,\n",
    "            embedding=repr_dim,\n",
    "            # random=cfg.random_projector,\n",
    "        )#.cuda() #TODO: REMOVE\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def __call__(self: VICReg, encodings, state_predictions):\n",
    "    \n",
    "    sim_loss = (encodings[1:] - state_predictions[1:]).pow(2).mean()\n",
    "\n",
    "    if self.cfg.loss.vicreg.sim_coeff_t:\n",
    "        sim_loss_t = (encodings[1:] - encodings[:-1]).pow(2).mean()\n",
    "    else:\n",
    "        sim_loss_t = torch.zeros([1])\n",
    "\n",
    "    encodings = self.projector(encodings)\n",
    "\n",
    "    flat_encodings = flatten_conv_output(encodings)\n",
    "\n",
    "    std_loss = self.std_loss(flat_encodings[:1])\n",
    "\n",
    "    if self.cfg.loss.vicreg.cov_per_feature:\n",
    "        T, B, ch, h, w = encodings.shape\n",
    "        # reshape (1, bs, ch, h, w) --> (h*w, bs, ch)\n",
    "        per_feature_encodings = (\n",
    "            encodings[:1].reshape(1, B, ch, h * w).permute(0, 3, 1, 2).squeeze(0)\n",
    "        )\n",
    "        cov_loss = self.cov_loss(per_feature_encodings)\n",
    "    else:\n",
    "        # reshape (1, bs, ch, h, w) --> (w, bs, ch * h * w)\n",
    "        cov_loss = self.cov_loss(flat_encodings[:1])\n",
    "\n",
    "    std_loss_t = self.std_loss(\n",
    "        flat_encodings[1:].permute(1, 0, 2), across_time=True\n",
    "    )  # (bs, T, repr)\n",
    "    cov_loss_t = self.cov_loss(\n",
    "        flat_encodings[1:].permute(1, 0, 2), across_time=True\n",
    "    )  # (bs, T, repr)\n",
    "\n",
    "    total_loss = (\n",
    "        self.cfg.loss.vicreg.sim_coeff * sim_loss\n",
    "        + self.cfg.loss.vicreg.cov_coeff * cov_loss.mean()\n",
    "        + self.cfg.loss.vicreg.std_coeff * std_loss.mean()\n",
    "        + self.cfg.loss.vicreg.cov_coeff_t * cov_loss_t.mean()\n",
    "        + self.cfg.loss.vicreg.std_coeff_t * std_loss_t.mean()\n",
    "        + self.cfg.loss.vicreg.sim_coeff_t * sim_loss_t.mean()\n",
    "    )\n",
    "\n",
    "    losses = {\n",
    "        \"total_loss\": total_loss,\n",
    "        \"sim_loss\": sim_loss,\n",
    "        \"std_loss\": std_loss.mean(),\n",
    "        \"cov_loss\": cov_loss.mean(),\n",
    "        \"sim_loss_t\": sim_loss_t.mean(),\n",
    "        \"std_loss_t\": std_loss_t.mean(),\n",
    "        \"cov_loss_t\": cov_loss_t.mean(),\n",
    "        \n",
    "    }\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def std_loss(self:VICReg, x: torch.Tensor, across_time=False):\n",
    "    x = x - x.mean(dim=1, keepdim=True)  # mean for each dim across batch samples\n",
    "\n",
    "    if (\n",
    "        not across_time\n",
    "        and self.cfg.loss.vicreg.std_coeff\n",
    "        or across_time\n",
    "        and self.cfg.loss.vicreg.std_coeff_t\n",
    "    ):\n",
    "        std = torch.sqrt(x.var(dim=1) + 0.0001)\n",
    "\n",
    "        std_margin = (\n",
    "            self.cfg.loss.vicreg.std_margin_t if across_time else self.cfg.loss.vicreg.std_margin\n",
    "        )\n",
    "        std_loss = torch.mean(F.relu(std_margin - std), dim=-1)\n",
    "    else:\n",
    "        std_loss = torch.zeros([1])\n",
    "\n",
    "    return std_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def cov_loss(self: VICReg, x: torch.Tensor, across_time=False):\n",
    "    batch_size = x.shape[1]\n",
    "    num_features = x.shape[-1]\n",
    "\n",
    "    x = x - x.mean(dim=1, keepdim=True)\n",
    "\n",
    "    if (\n",
    "        not across_time\n",
    "        and self.cfg.loss.vicreg.cov_coeff\n",
    "        or across_time\n",
    "        and self.cfg.loss.vicreg.cov_coeff_t\n",
    "    ):\n",
    "        cov = torch.einsum(\"bki,bkj->bij\", x, x) / (batch_size - 1)\n",
    "        diagonals = torch.einsum(\"bii->bi\", cov).pow(2).sum(dim=-1)\n",
    "        # cov shape is TxDxD\n",
    "\n",
    "        cov_loss = (cov.pow(2).sum(dim=[-1, -2]) - diagonals).div(num_features)\n",
    "        if self.cfg.loss.vicreg.adjust_cov:\n",
    "            cov_loss = cov_loss / (\n",
    "                num_features - 1\n",
    "            )  # divide by num of elements on off-diagonal.\n",
    "            # in orig paper they divide by num_features\n",
    "            # but the correct version is (num_features - 1)*num_features\n",
    "    else:\n",
    "        cov_loss = torch.zeros([1])\n",
    "\n",
    "    return cov_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from omegaconf import OmegaConf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from mawm.models.jepa import JEPA\n",
    "cfg = OmegaConf.load(\"../cfgs/MPCJepa/mpc.yaml\")\n",
    "model = JEPA(cfg.model, input_dim=(3, 42, 42), action_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import torch\n",
    "B = 16\n",
    "T = 6\n",
    "x = torch.randn(B, T, 3, 42, 42)\n",
    "pos = torch.randn(B, T, 2)\n",
    "actions = torch.randn(B, T, 1)\n",
    "msgs = torch.randn(B, T, 32)\n",
    "z0, Z = model(x, pos=pos, repr_input=False, actions=actions, msgs=msgs, T=actions.size(1) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 16, 18, 15, 15]), torch.Size([6, 16, 18, 15, 15]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "Z.shape, z0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 16, 18, 15, 15])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z0[1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.6168, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2939, grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "encodings = z0\n",
    "state_predictions = Z\n",
    "sim_loss = (encodings[1:] - state_predictions[1:]).pow(2).mean()\n",
    "sim_loss_t = (encodings[1:] - encodings[:-1]).pow(2).mean()\n",
    "sim_loss, sim_loss_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "loss = VICReg(cfg, repr_dim=(18, 15, 15), name_prefix=\"JEPA\")\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_loss': tensor(27.5082, grad_fn=<AddBackward0>),\n",
       " 'sim_loss': tensor(1.6168, grad_fn=<MeanBackward0>),\n",
       " 'std_loss': tensor(0.6789, grad_fn=<MeanBackward0>),\n",
       " 'cov_loss': tensor(0.0042, grad_fn=<MeanBackward0>),\n",
       " 'sim_loss_t': tensor(0.2939, grad_fn=<MeanBackward0>),\n",
       " 'std_loss_t': tensor(0.6956, grad_fn=<MeanBackward0>),\n",
       " 'cov_loss_t': tensor(0.)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "loss_dict =loss(encodings, state_predictions)\n",
    "loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
