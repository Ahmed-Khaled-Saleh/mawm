{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fb656fc",
   "metadata": {},
   "source": [
    "# VAE trainer\n",
    "\n",
    "> This module handles all aspects of the VAE, including encoding, decoding, and latent space representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbb56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp trainers.vae_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd36cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore import *\n",
    "from fastcore.utils import *\n",
    "from torchvision.utils import save_image\n",
    "import torch\n",
    "import os\n",
    "from torch import nn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17b4240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from MAWM.trainers.trainer import Trainer\n",
    "from MAWM.models.utils import save_checkpoint\n",
    "\n",
    "class VAETrainer(Trainer):\n",
    "    def __init__(self, cfg, model, train_loader, val_loader=None, \n",
    "                 criterion=None, optimizer=None, device=None,\n",
    "                 earlystopping=None, scheduler=None, writer= None):\n",
    "        \n",
    "        super().__init__(cfg, model, train_loader, val_loader, criterion, optimizer, device)\n",
    "        self.earlystopping = earlystopping\n",
    "        self.scheduler = scheduler\n",
    "        self.writer = writer\n",
    "\n",
    "        self.vae_dir = os.path.join(self.cfg.log_dir, 'vae_marlrid')\n",
    "        if not os.path.exists(self.vae_dir):\n",
    "            os.mkdir(self.vae_dir)\n",
    "            os.mkdir(os.path.join(self.vae_dir, 'samples'))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d43888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def reload(self: VAETrainer):\n",
    "\n",
    "    reload_file = os.path.join(self.vae_dir, 'best.pth')\n",
    "    if not self.cfg.noreload and os.path.exists(reload_file):\n",
    "        state = torch.load(reload_file)\n",
    "        print(\"Reloading model at epoch {}\"\n",
    "            \", with test error {}\".format(\n",
    "                state['epoch'],\n",
    "                state['precision']))\n",
    "        \n",
    "        self.model.load_state_dict(state['state_dict'])\n",
    "        self.optimizer.load_state_dict(state['optimizer'])\n",
    "        self.scheduler.load_state_dict(state['scheduler'])\n",
    "        self.earlystopping.load_state_dict(state['earlystopping'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed8ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def train_epoch(self: VAETrainer, epoch):\n",
    "    self.model.train()\n",
    "    self.train_loader.dataset.load_next_buffer()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_idx, data in enumerate(self.train_loader):\n",
    "        # import pdb; pdb.set_trace()\n",
    "        obs, dones, agent_id = data\n",
    "        mask = ~dones.bool()     # keep only where done is False\n",
    "\n",
    "        if mask.sum() == 0:\n",
    "            continue  # entire batch is terminals\n",
    "\n",
    "        obs = obs[mask]          # filter observations\n",
    "        obs = obs.to(self.device)\n",
    "        self.optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = self.model(obs)\n",
    "        loss = self.criterion(recon_batch, obs, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        self.optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(obs), len(self.train_loader.dataset),\n",
    "                100. * batch_idx / len(self.train_loader),\n",
    "                loss.item() / len(obs)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "        epoch, train_loss / len(self.train_loader.dataset)))\n",
    "\n",
    "    return train_loss / len(self.train_loader.dataset)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72ef3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def eval_epoch(self: VAETrainer):\n",
    "    self.model.eval()\n",
    "    self.val_loader.dataset.load_next_buffer()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in self.val_loader:\n",
    "            obs, dones, agent_id = data\n",
    "            mask = ~dones.bool()     # keep only where done is False\n",
    "\n",
    "            if mask.sum() == 0:\n",
    "                continue  # entire batch is terminals\n",
    "\n",
    "            obs = obs[mask]          # filter observations\n",
    "            obs = obs.to(self.device)\n",
    "            recon_batch, mu, logvar = self.model(obs)\n",
    "            test_loss += self.criterion(recon_batch, obs, mu, logvar).item()\n",
    "\n",
    "    test_loss /= len(self.val_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "    return test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0041e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import wandb\n",
    "\n",
    "\n",
    "@patch\n",
    "def fit(self: VAETrainer):\n",
    "    cur_best = None\n",
    "    lst_dfs = []\n",
    "\n",
    "    for epoch in range(1, self.cfg.epochs + 1):\n",
    "        train_loss = self.train_epoch(epoch)\n",
    "        test_loss = self.eval_epoch()\n",
    "        self.scheduler.step(test_loss)\n",
    "\n",
    "        # checkpointing\n",
    "        best_filename = os.path.join(self.vae_dir, 'best.pth')\n",
    "        filename = os.path.join(self.vae_dir, 'checkpoint.pth')\n",
    "\n",
    "        is_best = not cur_best or test_loss < cur_best\n",
    "        if is_best:\n",
    "            cur_best = test_loss\n",
    "\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'state_dict': self.model.state_dict(),\n",
    "            'precision': test_loss,\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "            'scheduler': self.scheduler.state_dict(),\n",
    "            # 'earlystopping': self.earlystopping.state_dict()\n",
    "        }, is_best, filename, best_filename)\n",
    "\n",
    "        if self.earlystopping.early_stop(test_loss):             \n",
    "            break\n",
    "       \n",
    "\n",
    "        to_log = {\n",
    "            \"train_loss\": train_loss, \n",
    "            \"test_loss\": test_loss,\n",
    "        }\n",
    "\n",
    "        self.writer.write(to_log)\n",
    "        df = pd.DataFrame.from_records([{\"epoch\": epoch ,\"train_loss\": train_loss, \"test_loss\":test_loss}], index= \"epoch\")\n",
    "        lst_dfs.append(df)\n",
    "\n",
    "    df_res = pd.concat(lst_dfs)\n",
    "    df_reset = df_res.reset_index()\n",
    "    self.writer.write({'Train-Val Loss Table': wandb.Table(dataframe= df_reset)})\n",
    "\n",
    "    self.writer.finish()\n",
    "    return df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14185d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "epoch",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "train_loss",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "test_loss",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "65007163-3614-4be9-a86b-2e63d4a12a53",
       "rows": [
        [
         "2",
         "3",
         "3"
        ],
        [
         "3",
         "4",
         "4"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_loss  test_loss\n",
       "epoch                       \n",
       "2               3          3\n",
       "3               4          4"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "import pandas as pd\n",
    "df = pd.DataFrame.from_records([{\"epoch\": 2 ,\"train_loss\": 3, \"test_loss\":3}], index= \"epoch\")\n",
    "df2 = pd.DataFrame.from_records([{\"epoch\": 3 ,\"train_loss\": 4, \"test_loss\":4}], index= \"epoch\")\n",
    "pd.concat([df, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69feff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
