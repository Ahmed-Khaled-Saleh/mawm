{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# World Model\n",
    "\n",
    "> World model (Predictor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.worldmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore import *\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from MAWM.models.dense import DenseModel\n",
    "class WorldModel(DenseModel):\n",
    "    def __init__(self, z_dim=32, action_dim=1, prog_dim=32, model_info={ 'layers': 3,'node_size': 256,'activation': nn.ReLU,'dist': None}):\n",
    "        input_dim = z_dim + action_dim + prog_dim\n",
    "        output_dim = z_dim + 1  # next state + reward\n",
    "        self.z_dim = z_dim\n",
    "        super().__init__((output_dim,), input_dim, model_info)\n",
    "    \n",
    "    def forward(self, z_t: torch.FloatTensor, a_t: torch.FloatTensor, prog_emb: torch.FloatTensor):\n",
    "        x = torch.cat([z_t, a_t, prog_emb], dim=-1)\n",
    "        out = super().forward(x)\n",
    "        z_next = out[:, :self.z_dim]\n",
    "        return z_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "z = torch.randn(4, 32)\n",
    "a = torch.randn(4, 1)\n",
    "p = torch.randn(4, 32)\n",
    "wm = WorldModel()\n",
    "z_next = wm(z, a, p)\n",
    "eq(z_next.shape, (4, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RewardModel(DenseModel):\n",
    "    def __init__(self, z_dim=32, action_dim=1, model_info={ 'layers': 3,'node_size': 256,'activation': nn.ReLU,'dist': 'binary'}):\n",
    "        input_dim = z_dim + action_dim \n",
    "        output_dim = 1\n",
    "        self.z_dim = z_dim\n",
    "        super().__init__((output_dim,), input_dim, model_info)\n",
    "    \n",
    "    def forward(self, z_t, a_t):\n",
    "        x = torch.cat([z_t, a_t], dim=-1)\n",
    "        out = super().forward(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Independent(Bernoulli(logits: torch.Size([4, 1])), 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "z = torch.randn(4, 32)\n",
    "a = torch.randn(4, 1)\n",
    "rm = RewardModel()\n",
    "r = rm(z, a)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "r.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, latent_dim=32, action_dim=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim + action_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, latent_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, z, a):\n",
    "        return self.net(torch.cat([z, a], dim=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "z_t = torch.randn(16, 32)\n",
    "a_t = torch.randn(16, 1)\n",
    "model = MLPPredictor(latent_dim=32, action_dim=1)\n",
    "model(z_t, a_t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "# Reusing the Multi-Head Attention logic from our previous conversation, \n",
    "# ensuring all components for Agent I are in this single module.\n",
    "class WorldModelAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    World Model with Multi-Head Cross-Attention.\n",
    "    \n",
    "    Handles message reception:\n",
    "    - Training: Accepts continuous message vector (h_t^j).\n",
    "    - Execution: Accepts discrete symbol index (m_hard) and performs embedding lookup.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 state_dim: int, \n",
    "                 action_dim: int, \n",
    "                 vocab_size: int, \n",
    "                 embed_dim: int, # Dimension of the actual message vector\n",
    "                 predictor_embed_dim: int = 64,\n",
    "                 total_attention_dim: int = 128,\n",
    "                 num_heads: int = 3):\n",
    "        \"\"\"\n",
    "        Initializes the World Model and the Symbol Embedding Table.\n",
    "\n",
    "        Args:\n",
    "            state_dim (int): Dimension of z_t^i and z_{t+1}^i.\n",
    "            action_dim (int): Dimension of raw action a_t^i.\n",
    "            vocab_size (int): Size of the shared symbol vocabulary |V|.\n",
    "            embed_dim (int): Dimension of the message vector (h_t^j or h_received).\n",
    "            ... MHA and MLP parameters ...\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Critical shared component: Agent I's version of the Symbol Embedding Matrix\n",
    "        self.symbol_embeddings = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "        # --- Multi-Head Attention Setup ---\n",
    "        self.num_heads = num_heads\n",
    "        self.total_attention_dim = total_attention_dim\n",
    "        self.head_dim = total_attention_dim // num_heads\n",
    "        self.predictor_embed_dim = predictor_embed_dim\n",
    "\n",
    "        # MHA Projections: Key/Value input size is the message embedding dimension (embed_dim)\n",
    "        self.query_proj = nn.Linear(state_dim, total_attention_dim, bias=False)\n",
    "        self.key_proj = nn.Linear(embed_dim, total_attention_dim, bias=False)\n",
    "        self.value_proj = nn.Linear(embed_dim, total_attention_dim, bias=False)\n",
    "        self.output_proj = nn.Linear(total_attention_dim, total_attention_dim)\n",
    "\n",
    "        # --- Action Encoding Layer ---\n",
    "        self.action_encoder = nn.Linear(action_dim, predictor_embed_dim, bias=True)\n",
    "\n",
    "        # --- Final Prediction Network (MLP) ---\n",
    "        mlp_input_dim = state_dim + total_attention_dim + predictor_embed_dim\n",
    "        \n",
    "        self.prediction_mlp = nn.Sequential(\n",
    "            nn.Linear(mlp_input_dim, state_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(state_dim * 2, state_dim) \n",
    "        )\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# --- Utility methods for MHA (as before) ---\n",
    "@patch\n",
    "def _split_heads(self: WorldModelAttention, x: torch.Tensor):\n",
    "    new_shape = x.size()[:-1] + (self.num_heads, self.head_dim)\n",
    "    x = x.view(*new_shape)\n",
    "    return x.unsqueeze(2) # Add sequence length L=1: (B, num_heads, 1, head_dim)\n",
    "\n",
    "@patch\n",
    "def _combine_heads(self: WorldModelAttention, x: torch.Tensor):\n",
    "    x = x.squeeze(2) \n",
    "    new_shape = x.size()[:-2] + (self.total_attention_dim,)\n",
    "    return x.view(*new_shape)\n",
    "\n",
    "# --- Core Attention Logic ---\n",
    "\n",
    "@patch\n",
    "def _multi_head_attention(self: WorldModelAttention, Q_input: torch.Tensor, KV_input: torch.Tensor):\n",
    "    \"\"\" Computes Multi-Head Attention given the Q and KV sources. \"\"\"\n",
    "    \n",
    "    # Compute Q, K, V Projections\n",
    "    Q_proj = self.query_proj(Q_input)   # Q_input is z_t^i\n",
    "    K_proj = self.key_proj(KV_input)    # KV_input is the continuous message (h_t^j or h_received)\n",
    "    V_proj = self.value_proj(KV_input)  \n",
    "\n",
    "    # Split into Multiple Heads\n",
    "    Q = self._split_heads(Q_proj) # (B, num_heads, 1, head_dim)\n",
    "    K = self._split_heads(K_proj) \n",
    "    V = self._split_heads(V_proj) \n",
    "    \n",
    "    # Scaled Dot-Product\n",
    "    K_T = K.transpose(-1, -2)\n",
    "    scores = torch.matmul(Q, K_T) / math.sqrt(self.head_dim)\n",
    "    \n",
    "    weights = F.softmax(scores, dim=-1) \n",
    "    context_head_output = torch.matmul(weights, V)\n",
    "\n",
    "    # Combine Heads and Final Projection\n",
    "    context_vector_combined = self._combine_heads(context_head_output)\n",
    "    context_vector = self.output_proj(context_vector_combined) # (B, total_attention_dim)\n",
    "    \n",
    "    return context_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def forward(self: WorldModelAttention, \n",
    "            z_t_i, \n",
    "            message_input, \n",
    "            action_t,\n",
    "            is_training):\n",
    "    \"\"\"\n",
    "    Predicts the next state z_{t+1}^i.\n",
    "\n",
    "    Args:\n",
    "        z_t_i (torch.Tensor): Agent i's current state. Shape: (Batch, state_dim)\n",
    "        message_input (torch.Tensor): \n",
    "            - TRAINING: Continuous vector h_t^j. Shape: (Batch, embed_dim)\n",
    "            - EXECUTION: Discrete symbol index m_hard. Shape: (Batch)\n",
    "        action_t (torch.Tensor): Agent i's action. Shape: (Batch, action_dim)\n",
    "        is_training (bool): Flag to switch message processing mode.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. Message Processing (The Key Difference) ---\n",
    "    if is_training:\n",
    "        # Training: Use the continuous message directly\n",
    "        h_message = message_input # (B, embed_dim)\n",
    "    else:\n",
    "        # Execution: Perform non-differentiable lookup on the received index\n",
    "        # message_input is the discrete index m_hard (LongTensor)\n",
    "        h_message = self.symbol_embeddings(message_input.long()) # (B, embed_dim)\n",
    "    \n",
    "    \n",
    "    # --- 2. Multi-Head Attention ---\n",
    "    # Q comes from z_t_i, K/V comes from the processed message h_message\n",
    "    context_vector = self._multi_head_attention(\n",
    "        Q_input=z_t_i,\n",
    "        KV_input=h_message\n",
    "    )\n",
    "\n",
    "    # --- 3. Encode Action ---\n",
    "    a = self.action_encoder(action_t) # (B, predictor_embed_dim)\n",
    "\n",
    "    # --- 4. Final Prediction ---\n",
    "    combined_features = torch.cat([z_t_i, context_vector, a], dim=1) \n",
    "    z_t_plus_1_i = self.prediction_mlp(combined_features) \n",
    "\n",
    "    return z_t_plus_1_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Simulation: Training Step (Continuous Channel) ---\n",
      "Agent J sent: Continuous vector (shape torch.Size([16, 64]))\n",
      "Predicted state z_t+1_i (Training) shape: torch.Size([16, 100])\n",
      "\n",
      "--- Simulation: Execution Step (Discrete Channel) ---\n",
      "Agent J sent: Discrete Index (example indices: [5, 3, 5, 9])\n",
      "Agent I performed lookup to get message vector.\n",
      "Predicted state z_t+1_i (Execution) shape: torch.Size([16, 100])\n"
     ]
    }
   ],
   "source": [
    "# # # | hide\n",
    "# from MAWM.models.comm import CommunicationModuleGRU\n",
    "# # # --- Example Usage (Simulation of one step) ---\n",
    "\n",
    "# # Define Shared Dimensions\n",
    "# BATCH_SIZE = 16\n",
    "# STATE_DIM = 100       \n",
    "# ACTION_DIM = 8        \n",
    "# VOCAB_SIZE = 10       \n",
    "# EMBED_DIM = 64        # Message vector dimension (h_t^j and h_received)\n",
    "# PREDICTOR_EMBED_DIM = 32\n",
    "# NUM_HEADS = 4\n",
    "# TOTAL_ATTENTION_DIM = 64\n",
    "# MESSAGE_CONTEXT_DIM = EMBED_DIM  # For Agent J's GRU output dimension\n",
    "\n",
    "# # --- Setup ---\n",
    "# # Need the two modules we defined\n",
    "# sender = CommunicationModuleGRU(observation_dim=EMBED_DIM, message_context_dim=EMBED_DIM, vocab_size=VOCAB_SIZE)\n",
    "# receiver_wm = WorldModelAttention(\n",
    "#     state_dim=STATE_DIM,\n",
    "#     action_dim=ACTION_DIM,\n",
    "#     vocab_size=VOCAB_SIZE,\n",
    "#     embed_dim=EMBED_DIM,\n",
    "#     predictor_embed_dim=PREDICTOR_EMBED_DIM,\n",
    "#     total_attention_dim=TOTAL_ATTENTION_DIM,\n",
    "#     num_heads=NUM_HEADS\n",
    "# )\n",
    "\n",
    "# # CRITICAL: In a real system, the symbol embeddings must be synchronized/shared.\n",
    "# # Here, we copy Agent I's learned embeddings to Agent J's output projection for demonstration.\n",
    "# # In training, Agent I's embedding matrix E is trained by the World Model loss.\n",
    "# # Agent J's Logit Projection (W_L) is also trained.\n",
    "\n",
    "# #     # We won't copy/sync here, but note that the final message dimension must match (EMBED_DIM).\n",
    "\n",
    "# #     # Mock Inputs\n",
    "# mock_z_t_i = torch.randn(BATCH_SIZE, STATE_DIM)\n",
    "# mock_z_t_j_GRU_output = torch.randn(BATCH_SIZE, EMBED_DIM) # The continuous GRU output h_t^j\n",
    "# mock_action_t = torch.randn(BATCH_SIZE, ACTION_DIM)\n",
    "# mock_h_prev_j = torch.zeros(BATCH_SIZE, MESSAGE_CONTEXT_DIM) \n",
    "\n",
    "# print(\"--- Simulation: Training Step (Continuous Channel) ---\")\n",
    "\n",
    "# # 1. Agent J Output (Training)\n",
    "# h_t_j_cont = sender(mock_z_t_j_GRU_output, mock_h_prev_j, is_training=True)\n",
    "\n",
    "# # 2. Agent I Prediction (Training)\n",
    "# z_t_plus_1_i_train = receiver_wm(\n",
    "#     z_t_i=mock_z_t_i,\n",
    "#     message_input=h_t_j_cont,\n",
    "#     action_t=mock_action_t,\n",
    "#     is_training=True\n",
    "# )\n",
    "# print(f\"Agent J sent: Continuous vector (shape {h_t_j_cont.shape})\")\n",
    "# print(f\"Predicted state z_t+1_i (Training) shape: {z_t_plus_1_i_train.shape}\")\n",
    "\n",
    "\n",
    "# print(\"\\n--- Simulation: Execution Step (Discrete Channel) ---\")\n",
    "\n",
    "# # 1. Agent J Output (Execution) - Sends DISCRETE INDEX\n",
    "# m_hard = sender(mock_z_t_j_GRU_output, mock_h_prev_j, is_training=False)\n",
    "\n",
    "# # 2. Agent I Prediction (Execution) - Performs lookup using the index\n",
    "# z_t_plus_1_i_exec = receiver_wm(\n",
    "#     z_t_i=mock_z_t_i,\n",
    "#     message_input=m_hard, # Passes the discrete index (LongTensor)\n",
    "#     action_t=mock_action_t,\n",
    "#     is_training=False\n",
    "# )\n",
    "\n",
    "# print(f\"Agent J sent: Discrete Index (example indices: {m_hard[0:4].tolist()})\")\n",
    "# print(f\"Agent I performed lookup to get message vector.\")\n",
    "# print(f\"Predicted state z_t+1_i (Execution) shape: {z_t_plus_1_i_exec.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
