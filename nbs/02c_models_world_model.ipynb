{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# World Model\n",
    "\n",
    "> World model (Predictor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.worldmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore import *\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from MAWM.models.dense import DenseModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from MAWM.models.dense import DenseModel\n",
    "class WorldModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        obs_dim: int,\n",
    "        msg_dim: int,\n",
    "        action_dim: int,\n",
    "        output_dim: int,\n",
    "        model_info:dict={'layers': 3,'node_size': 128,'activation': nn.ReLU,'dist': None}\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.message_proj = nn.Linear(msg_dim, model_info['node_size'], bias=True) #[B, D]\n",
    "        self.action_proj = nn.Linear(action_dim, model_info['node_size'], bias=True) # [B, D]\n",
    "        self.obs_proj = nn.Linear(obs_dim, model_info['node_size'], bias=True) # [B, D]\n",
    "\n",
    "        self.fuse = nn.Linear(model_info['node_size'] * 3, model_info['node_size'])\n",
    "        self.wm = DenseModel(output_shape= (output_dim,), input_size=model_info['node_size'], info= model_info)\n",
    "\n",
    "    def forward(self, z, action, msg):\n",
    "        msg = self.message_proj(msg)\n",
    "        act = self.action_proj(action)\n",
    "        z = self.obs_proj(z)\n",
    "\n",
    "        out = self.fuse(torch.cat([z, act, msg], dim= -1))\n",
    "        out = self.wm(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "z = torch.randn(4, 32)\n",
    "action = torch.randn(4, 1)\n",
    "msg = torch.randn(4, 256)\n",
    "model = WorldModel(obs_dim=32, msg_dim=256, action_dim=1, output_dim=32, \n",
    "           model_info={ 'layers': 3,'node_size': 128,'activation': nn.ReLU,'dist': None})\n",
    "out = model(z, action, msg)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RewardModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        obs_dim: int,\n",
    "        msg_dim: int,\n",
    "        action_dim: int,\n",
    "        output_dim: int,\n",
    "        model_info:dict= {'layers': 3,'node_size': 128,'activation': nn.ReLU,'dist': None}\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.message_proj = nn.Linear(msg_dim, model_info['node_size'], bias=True) #[B, D]\n",
    "        self.action_proj = nn.Linear(action_dim, model_info['node_size'], bias=True) # [B, D]\n",
    "        self.obs_proj = nn.Linear(obs_dim, model_info['node_size'], bias=True) # [B, D]\n",
    "\n",
    "        self.fuse = nn.Linear(model_info['node_size'] * 3, model_info['node_size']) # [B, D]\n",
    "        self.rm = DenseModel(output_shape= (output_dim,), input_size=model_info['node_size'], info= model_info) # [B, 1]\n",
    "\n",
    "    def forward(self, z, action, msg):\n",
    "        msg = self.message_proj(msg)\n",
    "        act = self.action_proj(action)\n",
    "        z = self.obs_proj(z)\n",
    "\n",
    "        out = self.fuse(torch.cat([z, act, msg], dim= -1))\n",
    "        out = self.rm(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "z = torch.randn(4, 32)\n",
    "action = torch.randn(4, 1)\n",
    "msg = torch.randn(4, 256)\n",
    "model = RewardModel(obs_dim=32, msg_dim=256, action_dim=1, output_dim=1, \n",
    "           model_info={ 'layers': 3,'node_size': 128,'activation': nn.ReLU,'dist': 'binary'})\n",
    "out = model(z, action, msg)\n",
    "out.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
