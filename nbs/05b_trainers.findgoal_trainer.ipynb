{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fb656fc",
   "metadata": {},
   "source": [
    "# World Model trainer\n",
    "\n",
    "> This module implements LeJepa training procedure with three predictors and two input modalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbb56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp trainers.findgoal_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd36cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore import *\n",
    "from fastcore.utils import *\n",
    "from torchvision.utils import save_image\n",
    "import torch\n",
    "import os\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb85e38",
   "metadata": {},
   "source": [
    "## WorldModel Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17b4240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from mawm.models.utils import save_checkpoint\n",
    "from mawm.loggers.base import AverageMeter\n",
    "from mawm.losses.sigreg import SIGReg\n",
    "from mawm.losses.idm import IDMLoss    \n",
    "from mawm.models.utils import flatten_conv_output\n",
    "from einops import rearrange\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "\n",
    "class WMTrainer:\n",
    "    def __init__(self, cfg, model, train_loader, sampler,\n",
    "                 optimizer=None, device=None,earlystopping=None, \n",
    "                 scheduler=None, writer= None, verbose= None, logger= None):\n",
    "        \n",
    "        self.cfg = cfg\n",
    "        self.device = device\n",
    "\n",
    "        self.train_loader = train_loader\n",
    "        self.sampler = sampler\n",
    "\n",
    "        self.jepa = model['rec']['jepa']\n",
    "        self.obs_enc = model[\"send\"][\"obs_enc\"]\n",
    "        self.msg_enc = model[\"send\"][\"msg_enc\"]\n",
    "        self.proj = model[\"send\"][\"proj\"]\n",
    "        self.comm_module = model[\"send\"][\"comm_module\"]\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "        self.earlystopping = earlystopping\n",
    "        self.scheduler = scheduler\n",
    "\n",
    "        self.writer = writer\n",
    "        self.verbose = verbose\n",
    "        self.logger = logger\n",
    "\n",
    "        self.sigreg = SIGReg().to(self.device)\n",
    "\n",
    "        self.idm = IDMLoss(cfg.loss.idm, (32, 15, 15), device= self.device)\n",
    "        if self.cfg.distributed:\n",
    "            self.idm.action_predictor = DistributedDataParallel(self.idm.action_predictor, device_ids = [self.device], find_unused_parameters=True)\n",
    "        \n",
    "        else:\n",
    "            self.idm.action_predictor = self.idm.action_predictor.to(self.device)\n",
    "        \n",
    "        new_opt_group = {'params': self.idm.action_predictor.parameters(), 'lr': 0.001, 'weight_decay': 1e-4}\n",
    "        self.optimizer.add_param_group(new_opt_group)\n",
    "\n",
    "        # self.lambda_ = self.cfg.loss.lambda_\n",
    "        self.schedule_start_epoch = 5  # Start mixing at epoch 5\n",
    "        self.schedule_end_epoch = 20    # Fully use predictions by epoch 20\n",
    "    \n",
    "        self.agents = [f\"agent_{i}\" for i in range(len(self.cfg.env.agents))]\n",
    "\n",
    "        self.dmpc_dir = os.path.join(self.cfg.log_dir, self.cfg.log_subdir, self.cfg.now)\n",
    "        if not os.path.exists(self.dmpc_dir):\n",
    "            os.makedirs(self.dmpc_dir , exist_ok=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b035480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([136, 5, 7, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.9662)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "logits = torch.randn(8, 17, 5, 7, 7)\n",
    "targets = torch.randint(0, 5, (8, 17, 7, 7))\n",
    "print(logits.flatten(0,1).shape)\n",
    "F.cross_entropy(logits.flatten(0,1), targets.flatten(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c89df6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def criterion(self: WMTrainer, global_step, z0, z, actions, msg_target, msg_hat, proj_h, proj_z, mask_t):\n",
    "\n",
    "    # RECEIVER LOSSES\n",
    "    flat_encodings = flatten_conv_output(z0) # [T, B, c`, h`, w`] => [T, B, D]\n",
    "    sigreg_img =self.sigreg(flat_encodings, global_step= global_step, across_dim= (0, 1), distributed= self.cfg.distributed)\n",
    "    sigreg_time = self.sigreg(flat_encodings, global_step= global_step, across_dim= 0, distributed= self.cfg.distributed)\n",
    "\n",
    "    transition_mask = mask_t[1:] * mask_t[:-1]\n",
    "    diff = (z0[1:] - z[1:]).pow(2).mean(dim=(2, 3, 4)) # (T-1, B)\n",
    "    sim_loss = (diff * transition_mask).sum() / transition_mask.sum().clamp(min=1)\n",
    "    \n",
    "    idm_loss = self.idm(embeddings= z0, predictions= z, actions= actions)\n",
    "    \n",
    "    # SENDER LOSSES\n",
    "    sigreg_msg = self.sigreg(proj_h, global_step= global_step, across_dim= (0, 1), distributed= self.cfg.distributed)\n",
    "    sigreg_obs = self.sigreg(proj_z, global_step= global_step, across_dim= (0, 1), distributed= self.cfg.distributed)\n",
    "\n",
    "    inv_loss_sender = (proj_z - proj_h).square().mean()\n",
    "\n",
    "    msg_pred_loss = self.cross_entropy(msg_hat.flatten(0,1), msg_target.flatten(0,1)) #msg_hat: [B*T, 5, 7, 7], targe: [B*T, 7, 7] with long() dtype.\n",
    "\n",
    "    return {\n",
    "        'sigreg_img': sigreg_img,\n",
    "        'sigreg_msg': sigreg_msg,\n",
    "        'sigreg_obs': sigreg_obs,\n",
    "        'sigreg_time': sigreg_time,\n",
    "        'sim_loss_dynamics': sim_loss,\n",
    "        # 'sim_loss_t': sim_loss_t,\n",
    "        'inv_loss_sender': inv_loss_sender,\n",
    "        'msg_pred_loss': msg_pred_loss,\n",
    "        'idm_loss': idm_loss\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08159b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_sampling_prob(self: WMTrainer, epoch):\n",
    "    if epoch < self.schedule_start_epoch:\n",
    "        return 0.0  # Always use ground truth\n",
    "    elif epoch >= self.schedule_end_epoch:\n",
    "        return 1.0  # Always use predictions\n",
    "    else:\n",
    "        # Linear interpolation\n",
    "        progress = (epoch - self.schedule_start_epoch) / (self.schedule_end_epoch - self.schedule_start_epoch)\n",
    "        return progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3759b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def sender_jepa(self: WMTrainer, data, sampling_prob, step):\n",
    "\n",
    "    obs_sender, pos_sender, msg, msg_target, _,_, _ = data\n",
    "    obs_sender = obs_sender.to(self.device)\n",
    "    pos_sender = pos_sender.to(self.device)\n",
    "    msg = msg.to(self.device)\n",
    "    msg_target = msg_target.to(self.device)\n",
    "\n",
    "    g = torch.Generator().manual_seed(step) \n",
    "    decision_rand = torch.rand(1, generator=g).item()\n",
    "    \n",
    "    self.logger.info(f\"device used for other agent data: {obs_sender.device}, {msg.device}\")\n",
    "\n",
    "    z = self.obs_enc(obs_sender, position = pos_sender)  #[B, T, c, h, w] => [B, T, c`, h`, w`]\n",
    "    h_target = self.msg_enc(msg)  # [B, T, C, H, W] => [B, T, dim=32]\n",
    "    proj_z, proj_h = self.proj(z, h_target) # True JEPA alignment\n",
    "\n",
    "    msg_hat = self.comm_module(z.detach())  # [B, T, c`, h`, w`] => [B, T, C=5, H=7, W=7]\n",
    "    if decision_rand < sampling_prob:\n",
    "        sample = F.one_hot(msg_hat.argmax(dim=2), num_classes=5)  # [B, T, 7, 7, 5]\n",
    "        sample = rearrange(sample, 'b t h w c -> b t c h w')# [B, T, 5, 7, 7]\n",
    "        probs = F.softmax(msg_hat, dim=2)  # [B, T, 5, 7, 7]\n",
    "        msg_used = sample + probs - probs.detach() # [B, T, C, H, W] `one-hot with straight-through`\n",
    "        h_for_receiver = self.msg_enc(msg_used.to(probs.dtype)) # [B, T, C, H, W] => [B, T, dim=32]\n",
    "\n",
    "    else:\n",
    "        msg_used = msg  # [B, T, C, H, W]\n",
    "    h_for_receiver = h_target  # Use target encoding when not sampling\n",
    "\n",
    "    return msg_hat, msg_target, h_for_receiver, proj_z, proj_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d831911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def rec_jepa(self: WMTrainer, data, h):\n",
    "    obs, pos, _, _, act, _, dones = data\n",
    "    mask = (~dones.bool()).float().to(self.device).clone() # [B, T, d=1]\n",
    "    mask = rearrange(mask, 'b t d-> b (t d)', d=1)\n",
    "    mask_t = rearrange(mask, 'b t -> t b')\n",
    "\n",
    "    if mask.sum() == 0:\n",
    "        return  \n",
    " \n",
    "    obs = obs.to(self.device)\n",
    "    pos = pos.to(self.device)\n",
    "    act = act.to(self.device)\n",
    "\n",
    "    self.logger.info(f\"device used for main agent data: {mask_t.device} {obs.device}, {act.device}\")\n",
    "    \n",
    "    z0, z = self.jepa(x= obs, #[B, T, c, h, w] =>  [T, B, c, h, w]\n",
    "                      pos= pos,\n",
    "                      actions= act,\n",
    "                      msgs= h,\n",
    "                      T= act.size(1)-1)\n",
    "    \n",
    "    return z0, z, act, mask_t, mask, len(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047571df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch  \n",
    "def train_epoch(self: WMTrainer, epoch):\n",
    "    self.logger.info(f\"Inside train_epoch: Starting epoch {epoch}\")\n",
    "    total_running_loss = 0.0\n",
    "    total_valid_steps = 0\n",
    "    num_pairs = len(self.agents) * (len(self.agents) - 1)\n",
    "\n",
    "    if self.sampler:\n",
    "        self.logger.info(f\"Setting epoch {epoch} for sampler\")\n",
    "        self.sampler.set_epoch(epoch) if epoch > 0 else None\n",
    "        \n",
    "    sampling_prob = self.get_sampling_prob(epoch)\n",
    "\n",
    "    self.logger.info(f\"Sampling probability for epoch {epoch}: {sampling_prob:.4f}\")\n",
    "    for batch_idx, data in enumerate(self.train_loader):\n",
    "        self.logger.info(f\"Starting batch {batch_idx} of epoch {epoch}\")\n",
    "        global_step = epoch * len(self.train_loader) + batch_idx\n",
    "        lr = self.scheduler.adjust_learning_rate(global_step)\n",
    "\n",
    "        if self.verbose  and epoch == 1 and batch_idx == 0:\n",
    "            self.logger.info(f\"\\n=== LR DIAGNOSTIC ===\")\n",
    "            self.logger.info(f\"Epoch: {epoch}\")\n",
    "            self.logger.info(f\"Batch idx: {batch_idx}\")\n",
    "            self.logger.info(f\"Global step passed to scheduler: {global_step}\")\n",
    "            self.logger.info(f\"Total batches per epoch: {len(self.train_loader)}\")\n",
    "            self.logger.info(f\"Total epochs: {self.cfg.epochs}\")\n",
    "            self.logger.info(f\"Batch size: {self.scheduler.batch_size}\")\n",
    "            self.logger.info(f\"Base LR: {self.scheduler.base_lr}\")\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        batch_log_accumulator = {}\n",
    "        if self.verbose:\n",
    "            if batch_idx == 0:\n",
    "                obs, pos, msg, msg_target, act, _, dones = data[self.agents[0]].values()\n",
    "                self.logger.info(f\"Input data stats:\")\n",
    "                self.logger.info(f\"  obs: min={obs.min():.3f}, max={obs.max():.3f}, mean={obs.mean():.3f}, std={obs.std():.3f}\")\n",
    "                self.logger.info(f\"  msg: min={msg.min():.3f}, max={msg.max():.3f}, mean={msg.mean():.3f}\")\n",
    "            \n",
    "        for rec in self.agents:\n",
    "            for sender in self.agents:\n",
    "                if sender == rec: continue\n",
    "                \n",
    "                msg_hat, msg_target, h, proj_z, proj_h = self.sender_jepa(\n",
    "                    data[sender].values(), sampling_prob, epoch + batch_idx\n",
    "                )\n",
    "                \n",
    "                z0, z, act, mask_t, mask, len_obs = self.rec_jepa(\n",
    "                    data[rec].values(), h\n",
    "                )\n",
    "\n",
    "                if self.verbose:\n",
    "                    if torch.isnan(z0).any():\n",
    "                        self.logger.error(f\"NaN detected in z0!\")\n",
    "                    if torch.isnan(z).any():\n",
    "                        self.logger.error(f\"NaN detected in z!\")\n",
    "                    \n",
    "                losses = self.criterion(global_step, z0, z, act, msg_target, msg_hat, proj_h, proj_z, mask_t)\n",
    "                \n",
    "                s_jepa = self.cfg.loss.sigreg.msg * (losses['sigreg_obs'] + losses['sigreg_msg']) + self.cfg.loss.inv_loss.coeff * losses['inv_loss_sender']\n",
    "                \n",
    "                r_jepa = self.cfg.loss.sigreg.img * losses['sigreg_img'] + losses['sim_loss_dynamics']\n",
    "\n",
    "                collapse_loss = (self.cfg.loss.msg_pred.coeff * losses['msg_pred_loss'] + \n",
    "                                self.cfg.loss.sigreg.time * losses['sigreg_time'] +\n",
    "                                self.cfg.loss.idm.coeff * losses['idm_loss'])\n",
    "\n",
    "                pair_loss = s_jepa + r_jepa + collapse_loss\n",
    "\n",
    "                if self.verbose:\n",
    "                    if batch_idx % 5 == 0:\n",
    "                        self.logger.info(f\"\\nBatch {batch_idx}, Pair {sender}->{rec}:\")\n",
    "                        self.logger.info(f\"  Individual losses:\")\n",
    "                        for k, v in losses.items():\n",
    "                            self.logger.info(f\"    {k}: {v.item():.4f}\")\n",
    "                        self.logger.info(f\"  Combined losses:\")\n",
    "                        self.logger.info(f\"    s_jepa: {s_jepa.item():.4f}\")\n",
    "                        self.logger.info(f\"    r_jepa: {r_jepa.item():.4f}\")\n",
    "                        self.logger.info(f\"    collapse_loss: {collapse_loss.item():.4f}\")\n",
    "                        self.logger.info(f\"    TOTAL pair_loss: {pair_loss.item():.4f}\")\n",
    "\n",
    "                scaled_loss = pair_loss / num_pairs\n",
    "                scaled_loss.backward()\n",
    "                \n",
    "                num_valid = mask.sum().item()\n",
    "                total_running_loss += pair_loss.item() * num_valid\n",
    "                total_valid_steps += num_valid\n",
    "\n",
    "                if self.verbose:\n",
    "                    for k, v in losses.items():\n",
    "                        batch_log_accumulator[f'pair_{sender}_to_{rec}/{k}'] = v.item()\n",
    "    \n",
    "        self.optimizer.step()\n",
    "\n",
    "        if self.verbose:\n",
    "            self.writer.write(batch_log_accumulator)\n",
    "            \n",
    "            processed_samples = batch_idx * len_obs \n",
    "            self.logger.info(f'Train Epoch: {epoch} [{processed_samples}/{len(self.train_loader.dataset)} '\n",
    "                             f'({100. * batch_idx / len(self.train_loader):.0f}%)]\\t')\n",
    "\n",
    "    final_epoch_loss = (total_running_loss / total_valid_steps) if total_valid_steps > 0 else 0.0\n",
    "    return final_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0041e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import wandb\n",
    "CHECKPOINT_FREQ = 1\n",
    "@patch\n",
    "def fit(self: WMTrainer):\n",
    "    self.jepa.train()\n",
    "    self.obs_enc.train()\n",
    "    self.msg_enc.train()\n",
    "    self.comm_module.train()\n",
    "    self.proj.train()\n",
    "\n",
    "    latest_file = \"latest.pt\"\n",
    "    folder = self.dmpc_dir\n",
    "    latest_path = os.path.join(folder, latest_file)\n",
    "    \n",
    "    loss_meter = AverageMeter()\n",
    "    lst_dfs = []\n",
    "\n",
    "    for epoch in range(1, self.cfg.epochs + 1):\n",
    "        self.logger.info(\"Epoch %d\" % (epoch))        \n",
    "        train_loss = self.train_epoch(epoch)\n",
    "        loss_meter.update(train_loss)\n",
    "        \n",
    "        def save_checkpoint(epoch, path):\n",
    "            if not self.verbose:\n",
    "                return\n",
    "            \n",
    "            def get_state(m):\n",
    "                return m.module.state_dict() if hasattr(m, 'module') else m.state_dict()\n",
    "            \n",
    "            save_dict = {\n",
    "                'epoch': epoch,\n",
    "                'jepa': get_state(self.jepa),\n",
    "                'obs_enc': get_state(self.obs_enc),\n",
    "                'msg_enc': get_state(self.msg_enc),\n",
    "                'comm_module': get_state(self.comm_module),\n",
    "                'proj': get_state(self.proj),\n",
    "                'train_loss': train_loss,\n",
    "                'optimizer': self.optimizer.state_dict(),\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                torch.save(save_dict, path)\n",
    "                self.logger.info(f\"Successfully saved checkpoint to {path}\")\n",
    "            except Exception as e:\n",
    "                self.logger.info(f\"Encountered exception when saving checkpoint: {e}\")\n",
    "        \n",
    "        self.logger.info(\"avg. loss %.3f\" % loss_meter.avg)\n",
    "\n",
    "        df = pd.DataFrame.from_records([{\"epoch\": epoch ,\"train_loss\": train_loss}], index= \"epoch\")\n",
    "        lst_dfs.append(df)\n",
    "\n",
    "        if epoch % CHECKPOINT_FREQ == 0 or epoch == (self.cfg.epochs - 1):\n",
    "            save_checkpoint(epoch + 1, latest_path)\n",
    "            if self.cfg.save_every_freq > 0 and epoch % self.cfg.save_every_freq == 0:\n",
    "                save_every_file = f\"e{epoch}.pt\"\n",
    "                save_every_path = os.path.join(folder, save_every_file)\n",
    "                save_checkpoint(epoch + 1, save_every_path)\n",
    "\n",
    "        to_log = {\n",
    "            \"train_loss\": train_loss, \n",
    "        }\n",
    "\n",
    "        if self.verbose:\n",
    "            self.writer.write(to_log)\n",
    "\n",
    "    df_res = pd.concat(lst_dfs)\n",
    "    df_reset = df_res.reset_index()\n",
    "    if self.verbose:\n",
    "        self.writer.write({'Train Loss Table': wandb.Table(dataframe= df_reset)})\n",
    "        self.writer.finish()\n",
    "    return df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69feff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marlgrid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
