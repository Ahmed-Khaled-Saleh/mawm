{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIGReg\n",
    "\n",
    "> Single and Multi-GPU implementations of SIGReg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp losses.sigreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore import *\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-GPU Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "class SIGRegSingle(torch.nn.Module):\n",
    "    def __init__(self, knots=17, num_slices=256):\n",
    "        super().__init__()\n",
    "        self.num_slices = num_slices\n",
    "        t = torch.linspace(0, 3, knots, dtype=torch.float32)\n",
    "        dt = 3 / (knots - 1)\n",
    "        weights = torch.full((knots,), 2 * dt, dtype=torch.float32)\n",
    "        weights[[0, -1]] = dt\n",
    "        window = torch.exp(-t.square() / 2.0)\n",
    "        self.register_buffer(\"t\", t)\n",
    "        self.register_buffer(\"phi\", window)\n",
    "        self.register_buffer(\"weights\", weights * window)\n",
    "\n",
    "    def forward(self, proj, global_step= None, across_dim= 0):\n",
    "        \"\"\"\n",
    "        proj: Tensor of shape [T, B, D]\n",
    "        global_step: [Optional] integer for seeding random projections.\n",
    "        across_dim: Int or Tuple of Ints determining the dimensions to compute the loss across.\n",
    "        Returns:\n",
    "            statistic: Scalar tensor representing the SIGReg loss across the dimension determined by `across_time`.\n",
    "        \"\"\"\n",
    "        T, B, D = proj.shape\n",
    "\n",
    "        sample_size = T if across_dim == 0 else B\n",
    "        sample_size = T * B if isinstance(across_dim, tuple) and set(across_dim) == {0, 1} else sample_size\n",
    "        print(\"Sample Size:\", sample_size)\n",
    "        if global_step:\n",
    "            g = torch.Generator(device= proj.device).manual_seed(int(global_step))\n",
    "            A = torch.randn(D, self.num_slices, generator= g, device= proj.device)\n",
    "        else: \n",
    "            A = torch.randn(D, self.num_slices, device= proj.device)\n",
    "        \n",
    "        A = A / A.norm(p=2, dim=0).clamp(min= 1e-8)\n",
    "        x_t = (proj @ A).unsqueeze(-1) * self.t # [B, T, num_slices, knots]\n",
    "        mean_cos = x_t.cos().mean(dim=across_dim) \n",
    "        mean_sin = x_t.sin().mean(dim=across_dim)\n",
    "        err = (mean_cos - self.phi).square() + mean_sin.square()\n",
    "        statistic = (err @ self.weights) * sample_size\n",
    "        return statistic.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Size: 91\n",
      "tensor(1.0511)\n",
      "Sample Size: 32\n",
      "tensor(1.0590)\n",
      "Sample Size: 2912\n",
      "tensor(1.0073)\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "import torch\n",
    "B = 32\n",
    "T = 91\n",
    "D = 32*15*15\n",
    "z = torch.randn(T, B, D)\n",
    "sigreg = SIGRegSingle()\n",
    "loss = sigreg(z, global_step= 42, across_dim= 0)\n",
    "print(loss)\n",
    "loss = sigreg(z, global_step= 42, across_dim= 1)\n",
    "print(loss)\n",
    "loss = sigreg(z, global_step= 42, across_dim= (0,1))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Implementation of SIGReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "from torch.distributed.nn import ReduceOp\n",
    "from torch.distributed.nn import all_reduce as functional_all_reduce\n",
    "\n",
    "def all_reduce_differentiable(x, op=\"AVG\"):\n",
    "    if dist.is_available() and dist.is_initialized():\n",
    "        x_new = x.clone()\n",
    "        op_type = ReduceOp.__dict__[op.upper()]\n",
    "        return functional_all_reduce(x_new, op_type)\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "class SIGReg(torch.nn.Module):\n",
    "    def __init__(self, knots=17, num_slices=256):\n",
    "        super().__init__()\n",
    "        self.num_slices = num_slices\n",
    "        t = torch.linspace(0, 3, knots, dtype=torch.float32)\n",
    "        dt = 3 / (knots - 1)\n",
    "        weights = torch.full((knots,), 2 * dt, dtype=torch.float32)\n",
    "        weights[[0, -1]] = dt\n",
    "        window = torch.exp(-t.square() / 2.0)\n",
    "        self.register_buffer(\"t\", t)\n",
    "        self.register_buffer(\"phi\", window)\n",
    "        self.register_buffer(\"weights\", weights * window)\n",
    "\n",
    "    def forward(self, proj, global_step=None, across_dim=0, distributed=False):\n",
    "        \"\"\"\n",
    "        proj: [T, B, D]\n",
    "        global_step: [Optional] integer for seeding random projections.\n",
    "        across_dim: [Optional] `Int` or `Tuple` of Ints determining the dimensions to compute the loss across.\n",
    "        distributed: [Optional] `Bool` Set to True to compute statistics across all GPUs.\n",
    "        Returns:\n",
    "            statistic: Scalar tensor representing the SIGReg loss across the dimension determined by `across_time`.\n",
    "        \"\"\"\n",
    "        T, B, D = proj.shape\n",
    "        device = proj.device\n",
    "\n",
    "        if isinstance(across_dim, tuple):\n",
    "            local_sample_size = 1\n",
    "            for d in across_dim:\n",
    "                local_sample_size *= proj.shape[d]\n",
    "        else:\n",
    "            local_sample_size = proj.shape[across_dim]\n",
    "\n",
    "        world_size = dist.get_world_size() if (distributed and dist.is_initialized()) else 1\n",
    "        global_sample_size = local_sample_size * world_size\n",
    "\n",
    "        if global_step is not None:\n",
    "            g = torch.Generator(device=device).manual_seed(int(global_step))\n",
    "            A = torch.randn(D, self.num_slices, generator= g, device= device)\n",
    "        else:\n",
    "            A = torch.randn(D, self.num_slices, device=device)\n",
    "        \n",
    "        A = A / A.norm(p= 2, dim= 0).clamp(min= 1e-8) # [D, num_slices]\n",
    "        x_t = (proj @ A).unsqueeze(-1) * self.t # [T, B, num_slices, knots]\n",
    "        \n",
    "        mean_cos = x_t.cos().mean(dim=across_dim) \n",
    "        mean_sin = x_t.sin().mean(dim=across_dim)\n",
    "\n",
    "        if distributed and dist.is_initialized():\n",
    "            mean_cos = all_reduce_differentiable(mean_cos, op= \"AVG\")\n",
    "            mean_sin = all_reduce_differentiable(mean_sin, op= \"AVG\")\n",
    "\n",
    "        err = (mean_cos - self.phi).square() + mean_sin.square()\n",
    "        statistic = (err @ self.weights) * global_sample_size\n",
    "        \n",
    "        return statistic.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0511)\n",
      "tensor(1.0590)\n",
      "tensor(1.0073)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "sigreg = SIGReg()\n",
    "loss = sigreg(z, global_step= 42, across_dim= 0)\n",
    "print(loss)\n",
    "loss = sigreg(z, global_step= 42, across_dim= 1)\n",
    "print(loss)\n",
    "loss = sigreg(z, global_step= 42, across_dim= (0,1))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "from torch.distributed.nn import ReduceOp\n",
    "from torch.distributed.nn import all_reduce as functional_all_reduce\n",
    "\n",
    "def all_reduce_differentiable(x, op=\"AVG\"):\n",
    "    if dist.is_available() and dist.is_initialized():\n",
    "        x_new = x.clone()\n",
    "        op_type = ReduceOp.__dict__[op.upper()]\n",
    "        return functional_all_reduce(x_new, op_type)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "class SIGRegFunctional(torch.nn.Module):\n",
    "    def __init__(self, knots=17, num_slices=256, scale_factor=1.0):\n",
    "        super().__init__()\n",
    "        self.num_slices = num_slices\n",
    "        self.scale_factor = scale_factor\n",
    "        \n",
    "        t = torch.linspace(0, 3, knots, dtype=torch.float32)\n",
    "        dt = 3 / (knots - 1)\n",
    "        weights = torch.full((knots,), 2 * dt, dtype=torch.float32)\n",
    "        weights[[0, -1]] = dt\n",
    "        window = torch.exp(-t.square() / 2.0)\n",
    "        self.register_buffer(\"t\", t)\n",
    "        self.register_buffer(\"phi\", window)\n",
    "        self.register_buffer(\"weights\", weights * window)\n",
    "\n",
    "    def forward(self, proj, global_step, mask):\n",
    "        \"\"\"\n",
    "        proj: Tensor of shape [T, B, d]\n",
    "        mask: [T, B] (1 for valid, 0 for padding)\n",
    "        \"\"\"\n",
    "        T_dim, B_dim, d_dim = proj.shape\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            g = torch.Generator(device=proj.device).manual_seed(int(global_step))\n",
    "            A = torch.randn(d_dim, self.num_slices, generator=g, device=proj.device)\n",
    "            A = A / A.norm(p=2, dim=0).clamp(min=1e-8)\n",
    "\n",
    "        projections = proj @ A # [T, B, Slices]\n",
    "        x_t = projections.unsqueeze(-1) * self.t \n",
    "        \n",
    "        # Apply Mask & Compute Local Sums\n",
    "        # Expand mask to [T, B, 1, 1] to broadcast across Slices and Knots\n",
    "        m = mask.view(T_dim, B_dim, 1, 1)\n",
    "        \n",
    "        local_sum_real = (x_t.cos() * m).sum(dim=1) # [T, Slices, Knots]\n",
    "        local_sum_imag = (x_t.sin() * m).sum(dim=1)\n",
    "        local_count = m.sum(dim=1) # [T, 1, 1]\n",
    "        \n",
    "        # Global Differentiable Sync (SUM instead of AVG)\n",
    "        # We sum all numerators and all denominators across GPUs\n",
    "        global_sum_real = all_reduce_differentiable(local_sum_real.clone(), op=\"SUM\")\n",
    "        global_sum_imag = all_reduce_differentiable(local_sum_imag.clone(), op=\"SUM\")\n",
    "        global_count = all_reduce_differentiable(local_count.clone(), op=\"SUM\")\n",
    "        \n",
    "        # 5. Global Weighted Mean\n",
    "        # Avoid division by zero with clamp\n",
    "        global_count_safe = global_count.clone()\n",
    "        ecf_real = global_sum_real / global_count_safe.clamp(min=1e-6)\n",
    "        ecf_imag = global_sum_imag / global_count_safe.clamp(min=1e-6)\n",
    "\n",
    "        # 6. Loss Calculation\n",
    "        err = (ecf_real - self.phi).square() + ecf_imag.square()\n",
    "        \n",
    "        # Scale by Global N (The total number of valid samples across all GPUs)\n",
    "        # statistic shape: [T, Slices]\n",
    "        statistic = (err @ self.weights) * global_count.squeeze(-1)\n",
    "        \n",
    "        # Average over Time and Slices\n",
    "        return statistic.mean() * self.scale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "tensor(1.0431)\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "T = 8\n",
    "B = 16\n",
    "d = 512\n",
    "global_step = 100\n",
    "z_proj = torch.randn(T, B, d)\n",
    "c_proj = torch.randn(T, B, d)\n",
    "mask = torch.ones(T, B)\n",
    "dist.init_process_group(backend=\"gloo\", init_method=\"tcp://localhost:12345\", rank=0, world_size=1)\n",
    "loss = SIGRegFunctional()\n",
    "print(loss(z_proj, 0, mask))\n",
    "dist.destroy_process_group()\n",
    "# loss = SIGReg()\n",
    "# print(loss(z_proj, 0, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-version of SIGReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TemporalSIGReg(torch.nn.Module):\n",
    "    def __init__(self, knots=17, num_slices=256):\n",
    "        super().__init__()\n",
    "        # Standard integration setup (matching your aligned SIGReg)\n",
    "        t = torch.linspace(0, 3, knots, dtype=torch.float32)\n",
    "        dt = 3 / (knots - 1)\n",
    "        weights = torch.full((knots,), 2 * dt, dtype=torch.float32)\n",
    "        weights[[0, -1]] = dt\n",
    "        phi = torch.exp(-t.square() / 2.0)\n",
    "        \n",
    "        self.register_buffer(\"t\", t)\n",
    "        self.register_buffer(\"phi\", phi)\n",
    "        self.register_buffer(\"weights\", weights * phi)\n",
    "        self.num_slices = num_slices\n",
    "\n",
    "    def forward(self, x, global_step, mask):\n",
    "        \"\"\"\n",
    "        x: [T, B, d] -> Time, Batch, Dim\n",
    "        mask: [T, B] -> 1 for valid, 0 for padding\n",
    "        \"\"\"\n",
    "        T_dim, B_dim, d_dim = x.shape\n",
    "        \n",
    "        # 1. Deterministic Projection\n",
    "        with torch.no_grad():\n",
    "            g = torch.Generator(device=x.device).manual_seed(int(global_step))\n",
    "            A = torch.randn(d_dim, self.num_slices, generator=g, device=x.device)\n",
    "            A = A / A.norm(p=2, dim=0).clamp(min=1e-8)\n",
    "\n",
    "        # 2. Project & Prepare grid\n",
    "        projections = x @ A # [T, B, Slices]\n",
    "        x_t = projections.unsqueeze(-1) * self.t # [T, B, Slices, Knots]\n",
    "        \n",
    "        # 3. Apply Mask & Compute Sums across TIME (dim 0)\n",
    "        # This replaces the Batch reduction with Time reduction\n",
    "        m = mask.view(T_dim, B_dim, 1, 1)\n",
    "        \n",
    "        # We reduce over dim=0 to check the distribution of a sequence's life-cycle\n",
    "        local_sum_real = (x_t.cos() * m).sum(dim=0) # [B, Slices, Knots]\n",
    "        local_sum_imag = (x_t.sin() * m).sum(dim=0)\n",
    "        local_count = m.sum(dim=0) # [B, 1, 1]\n",
    "        \n",
    "        # 4. Global ECF per Batch Sample\n",
    "        # No all_reduce needed! Each GPU has the full time-sequence for its samples.\n",
    "        ecf_real = local_sum_real / local_count.clamp(min=1e-6)\n",
    "        ecf_imag = local_sum_imag / local_count.clamp(min=1e-6)\n",
    "\n",
    "        # 5. Loss Calculation\n",
    "        err = (ecf_real - self.phi).square() + ecf_imag.square()\n",
    "        \n",
    "        # Scale by Local sequence length (matching the VC loss logic)\n",
    "        statistic = (err @ self.weights) * local_count.squeeze(-1)\n",
    "        \n",
    "        # Average over Batch and Slices\n",
    "        return statistic.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 256, 17])\n",
      "tensor(1.0589)\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "T = 8\n",
    "B = 16\n",
    "d = 512\n",
    "global_step = 100\n",
    "z_proj = torch.randn(T, B, d)\n",
    "c_proj = torch.randn(T, B, d)\n",
    "mask = torch.ones(T, B)\n",
    "loss = TemporalSIGReg()\n",
    "print(loss(z_proj, 0, mask))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:JEPA Parameters: 98560\n",
      "INFO:root:CommModule Parameters: 56005\n",
      "INFO:root:MSgEncoder Parameters: 32608\n",
      "INFO:root:Projector Parameters: 2241536\n",
      "INFO:root:--------------------------------------------------\n",
      "INFO:root:Total Parameters: 2462245\n"
     ]
    }
   ],
   "source": [
    "# #| hide\n",
    "# from mawm.models import init_models\n",
    "# from omegaconf import OmegaConf\n",
    "# cfg = OmegaConf.load(\"../cfgs/findgoal/mawm/ablations/datasize/mawm_ds_200k.yaml\")\n",
    "# cfg.distributed = False\n",
    "# model = init_models(cfg, device= \"cpu\", distributed= cfg.distributed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| hide\n",
    "# import torch\n",
    "# ckpt = torch.load(\"./models/good.pt\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jepa = model['rec']['jepa']\n",
    "# jepa.load_state_dict(ckpt[\"jepa\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path found for hostname: local\n",
      "Using all 10 rollouts in dataset.\n"
     ]
    }
   ],
   "source": [
    "# from mawm.data.utils import init_data\n",
    "# cfg = OmegaConf.load(\"../cfgs/findgoal/mawm/ablations/datasize/mawm_ds_200k.yaml\")\n",
    "# cfg.distributed = False\n",
    "# cfg.data.data_size = 0\n",
    "# cfg.data.batch_size = 10\n",
    "# dl, _ = init_data(cfg, distributed= cfg.distributed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['agent_0', 'agent_1'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch = next(iter(dl))\n",
    "# batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['obs', 'pos', 'msg', 'msg_target', 'act', 'next_obs', 'done'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch['agent_0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 40, 3, 42, 42])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch['agent_0']['obs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     z = jepa.backbone(batch['agent_0']['obs'].to(\"cpu\"), batch['agent_0']['pos'].to(\"cpu\"))\n",
    "#     z2 = jepa.backbone(batch['agent_1']['obs'].to(\"cpu\"), batch['agent_1']['pos'].to(\"cpu\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 40, 32, 15, 15]), torch.Size([10, 40, 32, 15, 15]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z.shape, z2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 7200])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectors = z.flatten(0, 1).view(-1, 32*15*15)\n",
    "# vectors.shape\n",
    "\n",
    "# vectors2 = z2.flatten(0, 1).view(-1, 32*15*15)\n",
    "# vectors2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7200])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v = vectors[0]\n",
    "# v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7200, 7200])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B = vectors.shape[0]\n",
    "# vectors = vectors - vectors.mean(dim=0, keepdim=True)\n",
    "# cov_mat = (vectors.T @ vectors) / (B - 1)\n",
    "# cov_mat.shape\n",
    "# cov_mat2 = torch.cov(vectors2.T)\n",
    "# cov_mat2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
