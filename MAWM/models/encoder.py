"""a ConvNet module for percpetion."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/02aa_models.encoder.ipynb.

# %% auto 0
__all__ = ['VisionEncoder', 'ResidualBlock', 'ResNet18', 'ResNet18_32']

# %% ../../nbs/02aa_models.encoder.ipynb 3
from fastcore import *
from fastcore.utils import *

# %% ../../nbs/02aa_models.encoder.ipynb 4
import torch
import torch.nn as nn
import torch.nn.functional as F

class VisionEncoder(nn.Module):
    def __init__(self, in_channels=3, latent_dim=128):
        super().__init__()

        self.latent_dim = latent_dim
        hidden_dims = [32, 64, 128, 256] 

        # -----------------------
        #        Encoder
        # -----------------------
        # Path: 42x42 -> 21x21 -> 11x11 -> 6x6 -> 3x3
        modules = []
        for h_dim in hidden_dims:
            modules.append(
                nn.Sequential(
                    nn.Conv2d(in_channels, h_dim, kernel_size=3,
                              stride=2, padding=1),
                    nn.BatchNorm2d(h_dim),
                    nn.LeakyReLU()
                )
            )
            in_channels = h_dim

        self.encoder = nn.Sequential(*modules)

        # Final shape is 256 * 3 * 3 = 2304
        self.flattened_dim = hidden_dims[-1] * 3 * 3 

        self.proj  = nn.Linear(self.flattened_dim, latent_dim)
        # self.fc_var = nn.Linear(self.flattened_dim, latent_dim)

    def forward(self, x):
        N, V = x.shape[:2]
        x = self.encoder(x.flatten(0, 1))
        x = torch.flatten(x, start_dim=1)
        proj = self.proj(x)
        return proj.reshape(N, V, -1).transpose(0, 1)


# %% ../../nbs/02aa_models.encoder.ipynb 15
import torch
import torch.nn as nn
import torch.nn.functional as F

class ResidualBlock(nn.Module):
    def __init__(self, in_len, out_len, stride=1):
        super(ResidualBlock, self).__init__()
        
        self.conv1 = nn.Conv2d(in_len, out_len, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_len)
        self.conv2 = nn.Conv2d(out_len, out_len, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_len)
        
        layers = []
        if stride != 1 or in_len != out_len:
            layers.append(nn.Conv2d(in_len, out_len, kernel_size=1, stride=stride, bias=False))
            layers.append(nn.BatchNorm2d(out_len))
            self.shortcut = nn.Sequential(*layers)

        else:
            self.shortcut = nn.Sequential()
        

    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out)) # Conv then BN
        out += self.shortcut(x)
        out = F.relu(out)
        return out

# %% ../../nbs/02aa_models.encoder.ipynb 16
class ResNet18(nn.Module):
    def __init__(self):
        super(ResNet18, self).__init__()
        
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
                
        self.layer1 = nn.Sequential(
            ResidualBlock(64, 64, stride=1),
            ResidualBlock(64, 64, stride=1)
        )
        self.layer2 = nn.Sequential(
            ResidualBlock(64, 128, stride=2),
            ResidualBlock(128, 128, stride=1)
        )
        self.layer3 = nn.Sequential(
            ResidualBlock(128, 256, stride=2),
            ResidualBlock(256, 256, stride=1)
        )
        self.layer4 = nn.Sequential(
            ResidualBlock(256, 512, stride=2),
            ResidualBlock(512, 512, stride=1)
        )
        
        # Use Adaptive Pooling to handle the 6x6 -> 1x1 transition automatically
        self.adaptive_pool = nn.AdaptiveAvgPool2d((3, 3)) 
        self.linear = nn.Linear(512 * 3 * 3, 256) # 4608 inputs

    def get_feature_space(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.layer1(out)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
        
        # Changed: use adaptive_pool instead of F.avg_pool2d(out, 4)
        out = self.adaptive_pool(out) 
        out = out.view(out.size(0), -1)
        return out

    def forward(self, x):
        N, V = x.shape[:2]
        out = self.get_feature_space(x.flatten(0, 1))
        proj = self.linear(out)
        return proj.reshape(N, V, -1).transpose(0, 1)

# %% ../../nbs/02aa_models.encoder.ipynb 18
class ResNet18_32(nn.Module):
    def __init__(self):
        super(ResNet18_32, self).__init__()
        
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
                
        self.layer1 = nn.Sequential(
            ResidualBlock(64, 64, stride=1),
            ResidualBlock(64, 64, stride=1)
        )
        self.layer2 = nn.Sequential(
            ResidualBlock(64, 128, stride=2),
            ResidualBlock(128, 128, stride=1)
        )
        self.layer3 = nn.Sequential(
            ResidualBlock(128, 256, stride=2),
            ResidualBlock(256, 256, stride=1)
        )
        self.layer4 = nn.Sequential(
            ResidualBlock(256, 512, stride=2),
            ResidualBlock(512, 512, stride=1)
        )
        
        # Use Adaptive Pooling to handle the 6x6 -> 1x1 transition automatically
        # Option: Keep the full 4x4 resolution
        self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4)) 
        self.linear = nn.Linear(512 * 4 * 4, 512)

    def get_feature_space(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.layer1(out)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
        
        # Changed: use adaptive_pool instead of F.avg_pool2d(out, 4)
        out = self.adaptive_pool(out) 
        out = out.view(out.size(0), -1)
        return out

    def forward(self, x):
        N, V = x.shape[:2]
        out = self.get_feature_space(x.flatten(0, 1))
        print(out.shape)
        proj = self.linear(out)
        return proj.reshape(N, V, -1).transpose(0, 1)
